# 3.1.1 Design URL Shortener (TinyURL/Bitly)

## 1. Requirements and Scale Estimation

### Functional Requirements (FRs)

1. **URL Redirection:** Given a short URL, the system must redirect the user to the original long URL.
2. **URL Shortening:** Given a long URL, the system must generate a unique, short URL (alias).
3. **Custom Alias:** Users should be able to specify a custom short alias (if available).
4. **Expiry:** Links should optionally expire after a set time.

### Non-Functional Requirements (NFRs)

1. **High Availability ($\text{HA}$):** The redirection service must be highly available ($99.99\%+$). Downtime is
   unacceptable.
2. **Low Latency (Redirect):** Redirection must be fast ($\sim 50$ $\text{ms}$).
3. **High Read Capacity:** Read traffic (redirects) is significantly higher than Write traffic (creation).

### Scale Estimation

| Metric                | Assumption                                                                       | Calculation                                               | Result                                      |
|-----------------------|----------------------------------------------------------------------------------|-----------------------------------------------------------|---------------------------------------------|
| Total Users           | 500 Million ($\text{MAU}$)                                                       | -                                                         | -                                           |
| URL Creates (Writes)  | 1 Million per day ($\text{QPS}_{w}$)                                             | $\frac{1 \text{M}}{24 \text{h} \times 3600 \text{s/h}}$   | $\sim 12$ Writes per second ($\text{QPS}$)  |
| URL Redirects (Reads) | 100 Million per day ($\text{QPS}_{r}$)                                           | $\frac{100 \text{M}}{24 \text{h} \times 3600 \text{s/h}}$ | $\sim 1157$ Reads per second ($\text{QPS}$) |
| Storage (5 Years)     | $1 \text{M} \text{URLs}/\text{day} \times 365 \times 5 = 1.825 \text{B}$ records | $1.825 \text{B} \times 1 \text{kB}/\text{record}$         | $\sim 1.8 \text{TB}$ total storage          |

---

## 2. High-Level Design (HLD)

The system is split into two primary flows: the **Write Path** (creation) and the **Read Path** (redirection).

### Components

1. **API Gateway / Load Balancer:** Routes traffic, enforces Rate Limits (for the Write Path), and performs
   authentication checks.
2. **Shortening Service (Write Path):** Generates the unique alias and stores the mapping in the database.
3. **Redirection Service (Read Path):** The high-speed component that retrieves the long URL from the Cache or DB.
4. **Cache (Redis):** Stores the most frequently accessed short_url $\rightarrow$ long_url mappings to ensure low
   redirection latency.
5. **Database (Sharded PostgreSQL):** The persistent, authoritative store for all URL mappings.

---

## 3. Detailed Component Design

### 3.1 Data Model and Storage

Since we require **ACID** properties (we cannot afford to lose the mapping or have conflicting keys) and the total data
volume is manageable ($\sim 1.8 \text{TB}$), we start with a **Relational Database (PostgreSQL)**.

#### Schema ($\text{URLs}$ Table)

| Field           | Data Type                     | Notes                                                     |
|-----------------|-------------------------------|-----------------------------------------------------------|
| **short_alias** | $\text{VARCHAR}(\text{8})$    | Primary Key (Clustered Index), unique.                    |
| **long_url**    | $\text{VARCHAR}(\text{2048})$ | The destination URL.                                      |
| **created_at**  | $\text{TIMESTAMP}$            | Record creation time.                                     |
| **user_id**     | $\text{BIGINT}$               | Foreign key to the User service (for custom links/stats). |
| **expires_at**  | $\text{TIMESTAMP}$            | Optional expiration time.                                 |
| **status**      | $\text{ENUM}$                 | $\text{ACTIVE}$, $\text{EXPIRED}$, $\text{BLOCKED}$.      |

#### Database Scaling (Sharding)

The table must be **sharded** horizontally by the `short_alias` to distribute the read/write load across multiple
database instances. This is because lookups are based on the primary key, making lookups efficient across shards.

### 3.2 Alias Generation Strategy (The Heart of the Write Path)

The alias must be short (e.g., 7-8 characters) and unique.

| Architectural Choice    | Decision Made                                                                                                          | Why This Over That (Tradeoffs)                                                                                                                                                                                                                                                                                                        |
|-------------------------|------------------------------------------------------------------------------------------------------------------------|---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| **Alias Generation**    | **Base62 Encoding (or similar)**                                                                                       | **Why Base62 over MD5/Hashing?** Hashing ($\text{MD5}$, $\text{SHA}$) is fast but leads to collisions, which requires complex resolution logic and multiple database checks. **Base62** (using letters $\text{A-Z}$, $\text{a-z}$, and numbers $\text{0-9}$) is a deterministic encoding of a sequential ID, guaranteeing uniqueness. |
| **Source of Unique ID** | Dedicated $\text{ID}$ $\text{Generator}$ $\text{Service}$ ($\text{e.g.}$, Snowflake, or $\text{RDBMS}$ Auto-Increment) | **Why a dedicated service?** $\text{RDBMS}$ auto-increment IDs are centralized and become a **Single Point of Failure** and write bottleneck at high scale. A distributed $\text{ID}$ service guarantees globally unique, highly available sequential $\text{IDs}$. **Tradeoff**: Adds complexity and another service to maintain.    |

#### Write Path Flow (High-Level Steps)

1. Client submits $\text{Long}$ $\text{URL}$.
2. $\text{Shortening}$ $\text{Service}$ asks $\text{ID}$ $\text{Generator}$ $\text{Service}$ for the next
   unique $\text{BIGINT}$ $\text{ID}$.
3. $\text{Service}$ converts the $\text{BIGINT}$ $\text{ID}$ into a
   short, $7$-$\text{character}$ $\text{Base62}$ $\text{Alias}$.
4. $\text{Service}$ writes the `short_alias` $\rightarrow$ `long_url` mapping to
   the $\text{Sharded}$ $\text{PostgreSQL}$ DB.
5. **IMPORTANT:** The mapping is immediately written to the **Cache (Redis)** with a $\text{TTL}$.

### 3.3 Redirection Strategy (The Read Path)

The Read Path must prioritize speed and offload the database.

| Architectural Choice  | Decision Made                            | Why This Over That (Tradeoffs)                                                                                                                                                                                                                                                       |
|-----------------------|------------------------------------------|--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| **Database**          | Sharded **PostgreSQL** (Source of Truth) | **Why PostgreSQL over NoSQL** (like Cassandra)? The core data is highly relational (User $\rightarrow$ URL $\rightarrow$ Stats) and requires $\text{ACID}$ consistency for the crucial `short_alias` $\text{Primary}$ $\text{Key}$ constraint. **Tradeoff**: Harder to scale writes. |
| **Caching Strategy**  | **Cache-Aside** with a $\text{TTL}$      | **Why Cache-Aside over Write-Through?** The redirection path is extremely read-heavy (100:1 read-to-write ratio). We prioritize low write latency and accept that a new link might have a tiny risk of a $\text{Cache}$ $\text{Miss}$ on the first few reads.                        |
| **Redirection Logic** | **HTTP 301/302**                         | **Why 301/302?** Using standard $\text{HTTP}$ redirects is the fastest way to offload the process to the client's browser.                                                                                                                                                           |

#### Read Path Flow (High-Level Steps)

1. Client sends request for `tinyl.co/abcXYZ`.
2. $\text{Redirection}$ $\text{Service}$ extracts `abcXYZ`.
3. **Cache Check ($\text{Redis}$):** Look up `abcXYZ` in $\text{Redis}$.
4. **Cache Hit:** Redirect client to $\text{Long}$ $\text{URL}$ ($\text{HTTP}$ $301$/$302$). $\sim 5$ $\text{ms}$.
5. **Cache Miss:** Look up abcXYZ in $\text{Sharded}$ $\text{PostgreSQL}$.
6. **DB Hit**: Store mapping in $\text{Redis}$ (Cache-Aside) and redirect the client. $\sim 50$ $\text{ms}$.

---

## 4. Bottlenecks and Future Scaling

1. **SPOF in Cache:** If the Redis Cluster fails, all traffic hits the $\text{DB}$, causing a
   potential $\text{Cache}$ $\text{Stampede}$ and $\text{DB}$ overload.
    - **Mitigation**: Implement a multi-master/active-active $\text{Redis}$ setup with automatic failover. Use
      a $\text{Circuit}$ $\text{Breaker}$ on the $\text{DB}$ calls in the $\text{Redirection}$ $\text{Service}$ to drop
      excess traffic gracefully.
2. **Write Scaling:** If the daily link creation rate grows beyond $\sim 100$ $\text{QPS}$, the $\text{RDBMS}$ will
   struggle with contention even with sharding.
    - **Future Scaling:** Decouple the creation process using a **Message Queue (Kafka).** The user gets a confirmation
      immediately, and the $\text{URL}$ $\text{Shortening}$ $\text{Service}$ processes the actual $\text{DB}$ write
      asynchronously.
3. **Rate Limiting:** Abusive users could $\text{DDoS}$ the $\text{Write}$ $\text{Path}$ by repeatedly submitting new
   URLs.
    - **Mitigation**: Enforce $\text{Rate}$ $\text{Limiting}$ at the $\text{API}$ $\text{Gateway}$ using the **Token
      Bucket Algorithm** (2.5.1), limited by $\text{User}$ $\text{ID}$ or $\text{IP}$ $\text{Address}$.
