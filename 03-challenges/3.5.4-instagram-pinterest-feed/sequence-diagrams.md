# Instagram/Pinterest Feed - Sequence Diagrams

## Table of Contents

1. [Media Upload Flow (Happy Path)](#1-media-upload-flow-happy-path)
2. [Feed Generation Flow](#2-feed-generation-flow)
3. [Like Post Flow (Real-Time Engagement)](#3-like-post-flow-real-time-engagement)
4. [Fanout-on-Write Flow](#4-fanout-on-write-flow)
5. [Fanout-on-Read Flow (Celebrity)](#5-fanout-on-read-flow-celebrity)
6. [Visual Search Flow](#6-visual-search-flow)
7. [Cache Invalidation Flow](#7-cache-invalidation-flow)
8. [Post Deletion Flow](#8-post-deletion-flow)
9. [Recommendation Engine Query Flow](#9-recommendation-engine-query-flow)
10. [Multi-Region Write Flow](#10-multi-region-write-flow)
11. [CDN Cache Miss Flow](#11-cdn-cache-miss-flow)
12. [Failed Upload Retry Flow](#12-failed-upload-retry-flow)
13. [Hot Key Mitigation Flow](#13-hot-key-mitigation-flow)
14. [Redis Cache Failure Fallback](#14-redis-cache-failure-fallback)

---

## 1. Media Upload Flow (Happy Path)

**Flow:**

This sequence shows the complete end-to-end flow of a user uploading an image, from initial request to fanout
completion.

**Steps:**

1. **Client Request** (0ms): User clicks "Upload" and selects image in mobile app
2. **Upload Service** (10ms): Generates pre-signed S3 URL with 15-minute expiry
3. **S3 Direct Upload** (2000ms): Client uploads 10MB image directly to S3 (bypasses server)
4. **S3 Event Trigger** (5ms): S3 triggers event notification to Kafka
5. **Kafka Queue** (10ms): Message enqueued in `media.uploaded` topic
6. **Worker Pick-up** (50ms): Media worker consumes job from queue
7. **Image Processing** (3000ms): Generate 8 versions (thumbnails, WebP, AVIF, etc.)
8. **Feature Extraction** (500ms): CNN model extracts visual embeddings
9. **Database Write** (50ms): Save post metadata to PostgreSQL
10. **Fanout Trigger** (20ms): Publish `post.created` event to Kafka
11. **Fanout Workers** (5000ms): Update followers' Redis timelines (async)
12. **Client Notification** (100ms): Push notification sent to followers

**Performance:**

- **User Response Time**: 2 seconds (receives success after S3 upload)
- **Total Processing Time**: ~10 seconds (background, user doesn't wait)
- **Throughput**: 5,780 uploads/sec sustained, 17k peak

**Edge Cases:**

- Upload failure → Retry with exponential backoff
- Processing failure → Job re-queued, max 3 attempts
- Fanout failure → Eventually consistent, retry later

```mermaid
sequenceDiagram
    actor User
    participant App as Mobile App
    participant UploadAPI as Upload Service
    participant S3 as S3 Bucket
    participant Kafka as Kafka Queue
    participant Worker as Media Worker
    participant ImageProc as Image Processor
    participant CNN as CNN Model
    participant Postgres as PostgreSQL
    participant FanoutWorker as Fanout Worker
    participant Redis as Redis Timeline
    User ->> App: Click "Upload" + Select Image
    App ->> UploadAPI: POST /upload/request (metadata)
    UploadAPI ->> UploadAPI: Validate auth & quota
    UploadAPI ->> S3: Generate pre-signed URL (15 min TTL)
    UploadAPI -->> App: Return pre-signed URL
    Note over App, S3: Direct upload (bypasses server)
    App ->> S3: PUT image (10MB)
    S3 -->> App: 200 OK (2 seconds)
    App -->> User: "Upload Successful!"
    Note over S3, Kafka: Async processing begins
    S3 ->> Kafka: Trigger event (media.uploaded)
    Kafka ->> Worker: Consumer picks up job
    Worker ->> S3: Download original image
    Worker ->> ImageProc: Process image (resize, compress)
    ImageProc ->> S3: Upload 8 versions
    Worker ->> CNN: Extract visual features
    CNN -->> Worker: 2048-dim embedding
    Worker ->> Postgres: INSERT INTO posts (metadata, URLs)
    Postgres -->> Worker: post_id = 12345
    Worker ->> Kafka: Publish (post.created, post_id=12345)
    Kafka ->> FanoutWorker: Fanout to followers
    FanoutWorker ->> Postgres: Get follower list
    FanoutWorker ->> Redis: ZADD timeline:{follower_id} {timestamp} {post_id}
    Note over User: Followers see post in feed within 5 seconds
```

---

## 2. Feed Generation Flow

**Flow:**

This sequence demonstrates how a personalized feed is generated by combining multiple data sources in parallel and
applying ML ranking.

**Steps:**

1. **User Request** (0ms): User opens app, requests feed
2. **API Gateway** (5ms): Authenticates JWT token, checks rate limit
3. **Feed Service** (10ms): Initiates parallel fetch from 4 sources
4. **Parallel Fetch** (starts at 10ms, completes by 35ms):
    - **Redis Timeline** (15ms): Fetch 50 follower post IDs from pre-computed timeline
    - **PostgreSQL** (25ms): Fetch 20 celebrity post IDs (fanout-on-read)
    - **Recommendation Engine** (30ms): Fetch 50 recommended post IDs from ML model
    - **Ad Service** (20ms): Fetch 10 targeted ads
5. **Feed Stitcher** (40ms): Merges all sources with 60/30/10 ratio
6. **Deduplication** (45ms): Remove posts user has already seen (Bloom filter check)
7. **Final Ranking** (60ms): Apply LightGBM model for personalized ordering
8. **Hydration** (75ms): Fetch full post details from Redis cache (batch HGETALL)
9. **Response** (80ms): Return top 50 posts to client

**Performance:**

- **Total Latency**: 80-120ms (p50), 150ms (p95)
- **Cache Hit Rate**: 85% for timeline, 70% for post details
- **Throughput**: 347k requests/sec peak

**Optimization:**

- Parallel fetching reduces latency by 3x (vs sequential)
- Redis pipelining for hydration (50 posts in 1 round trip)

```mermaid
sequenceDiagram
    actor User
    participant App as Mobile App
    participant Gateway as API Gateway
    participant FeedSvc as Feed Service
    participant RedisTimeline as Redis Timeline Cache
    participant Postgres as PostgreSQL (Celebrity)
    participant RecoEngine as Recommendation Engine
    participant AdSvc as Ad Service
    participant Stitcher as Feed Stitcher
    participant Ranker as Ranking Model
    participant RedisPost as Redis Post Cache
    User ->> App: Open app / Pull to refresh
    App ->> Gateway: GET /feed (user_id=12345)
    Gateway ->> Gateway: Validate JWT & Rate limit
    Gateway ->> FeedSvc: Forward request
    Note over FeedSvc: Parallel fetch (4 async calls)

    par Parallel Fetch
        FeedSvc ->> RedisTimeline: ZREVRANGE timeline:12345 0 49
        RedisTimeline -->> FeedSvc: [50 post IDs]
    and
        FeedSvc ->> Postgres: SELECT post_ids FROM celebrity_posts WHERE follower_id=12345
        Postgres -->> FeedSvc: [20 post IDs]
    and
        FeedSvc ->> RecoEngine: GET /recommend?user_id=12345&limit=50
        RecoEngine -->> FeedSvc: [50 post IDs]
    and
        FeedSvc ->> AdSvc: GET /ads?user_id=12345&limit=10
        AdSvc -->> FeedSvc: [10 ad IDs]
    end

    Note over FeedSvc: All fetches complete (~35ms)
    FeedSvc ->> Stitcher: Merge (60% follower, 30% reco, 10% ads)
    Stitcher ->> Stitcher: Deduplication (Bloom filter)
    Stitcher ->> Ranker: Rank merged list
    Ranker -->> Stitcher: Ranked post IDs [top 50]
    Stitcher ->> RedisPost: HMGET post:* (batch fetch 50 posts)
    RedisPost -->> Stitcher: Post metadata (user, caption, media URLs, likes)
    Stitcher -->> FeedSvc: Hydrated feed
    FeedSvc -->> Gateway: 200 OK (JSON response)
    Gateway -->> App: Feed data
    App -->> User: Display feed
    Note over User: Total: ~80-120ms
```

---

## 3. Like Post Flow (Real-Time Engagement)

**Flow:**

This sequence shows the multi-layer write path for handling a like action with immediate user feedback and eventual
durability.

**Steps:**

1. **User Action** (0ms): User double-taps image to like
2. **Optimistic UI Update** (0ms): Client immediately shows heart animation
3. **API Request** (10ms): POST /like sent to API gateway
4. **Rate Limit Check** (15ms): Verify user hasn't exceeded 100 likes/minute
5. **Engagement Service** (20ms): Validate user hasn't already liked this post
6. **Layer 1 - Redis Counter** (22ms): Atomic INCR on `post:likes:{post_id}` (immediate)
7. **Layer 1 - Redis HLL** (23ms): PFADD on `post:likers:{post_id}` (track unique users)
8. **Response** (25ms): Return 200 OK to client (user sees confirmation)
9. **Layer 2 - Cassandra** (50ms): Async write to likes table (durable storage)
10. **Layer 3 - Kafka Event** (60ms): Publish `like.created` event
11. **Layer 3 - Batch Worker** (300,000ms): Every 5 minutes, aggregate Redis → PostgreSQL

**Performance:**

- **User-Perceived Latency**: 25ms (from click to confirmation)
- **Write Throughput**: 578k likes/sec sustained
- **Durability**: Cassandra write completes within 50ms

**Failure Handling:**

- Redis down → Write to Cassandra directly (slower, 100ms)
- Cassandra down → Queue write, retry exponentially
- Batch worker down → PostgreSQL count may be stale (acceptable)

```mermaid
sequenceDiagram
    actor User
    participant App as Mobile App
    participant Gateway as API Gateway
    participant EngageSvc as Engagement Service
    participant RateLimiter as Rate Limiter
    participant Redis as Redis Counters
    participant Cassandra as Cassandra (Durable)
    participant Kafka as Kafka Events
    participant BatchWorker as Batch Worker
    participant Postgres as PostgreSQL
    User ->> App: Double-tap image (Like)
    App ->> App: Optimistic UI: Show heart ❤️
    App ->> Gateway: POST /like (user_id=123, post_id=789)
    Gateway ->> RateLimiter: Check limit (100 likes/min)
    RateLimiter -->> Gateway: OK (within limit)
    Gateway ->> EngageSvc: Forward request
    EngageSvc ->> Redis: SISMEMBER post:789:likers 123 (check duplicate)
    Redis -->> EngageSvc: false (not already liked)
    Note over EngageSvc: Multi-layer write

    par Layer 1: Immediate Response (Redis)
        EngageSvc ->> Redis: INCR post:likes:789
        Redis -->> EngageSvc: 1,234 (new count)
        EngageSvc ->> Redis: PFADD post:likers:789 123
        EngageSvc ->> Redis: SADD post:789:likers 123
    end

    EngageSvc -->> Gateway: 200 OK (like_count=1234)
    Gateway -->> App: Success response
    App -->> User: Update UI: 1,234 likes
    Note over User: User sees confirmation in 25ms

    par Layer 2: Durable Write (Async)
        EngageSvc ->> Cassandra: INSERT INTO likes (post_id, user_id, timestamp)
        Cassandra -->> EngageSvc: ACK (async)
    end

    par Layer 3: Event Stream
        EngageSvc ->> Kafka: Publish (like.created, post_id=789)
        Kafka ->> BatchWorker: Consumer receives event
    end

    Note over BatchWorker: Every 5 minutes, batch aggregation
    BatchWorker ->> Redis: GET all post:likes:* keys
    BatchWorker ->> Postgres: UPDATE posts SET like_count = ? WHERE post_id = ?
    Postgres -->> BatchWorker: Rows updated
```

---

## 4. Fanout-on-Write Flow

**Flow:**

This sequence illustrates the fanout-on-write strategy for regular users (< 10K followers), where new posts are
pre-computed into followers' timelines.

**Steps:**

1. **Post Created** (0ms): User publishes new post
2. **PostgreSQL Write** (50ms): Insert post metadata
3. **Kafka Event** (60ms): Publish `post.created` event
4. **Fanout Service** (70ms): Consumer picks up event
5. **Get Followers** (90ms): Query `follows` table for follower list (e.g., 5,000 followers)
6. **Partition Followers** (100ms): Split into batches of 100
7. **Parallel Redis Writes** (150-5000ms): 50 workers write to Redis timelines
    - Each worker: `ZADD timeline:{follower_id} {timestamp} {post_id}`
8. **Completion** (5000ms): All 5,000 followers' timelines updated

**Performance:**

- **Fanout Time**: 5 seconds for 5,000 followers
- **Write Amplification**: 1 post → 5,000 Redis writes
- **Worker Pool**: 50 workers × 100 followers/batch

**Scalability:**

- Users with > 10K followers → Skip fanout-on-write, use fanout-on-read instead
- Prevents celebrity write storms (1 post → 100M writes)

```mermaid
sequenceDiagram
    actor User
    participant App as Mobile App
    participant PostAPI as Post Service
    participant Postgres as PostgreSQL
    participant Kafka as Kafka (post.created)
    participant FanoutSvc as Fanout Service
    participant FollowDB as Follows Table
    participant WorkerPool as Worker Pool (50 workers)
    participant Redis as Redis Timeline Cache
    participant Follower as Follower's App
    User ->> App: Create post (caption + image)
    App ->> PostAPI: POST /posts (user_id=123, caption, media_url)
    PostAPI ->> Postgres: INSERT INTO posts (user_id, caption, media_urls)
    Postgres -->> PostAPI: post_id = 789
    PostAPI -->> App: 200 OK (post_id=789)
    App -->> User: "Post published!"
    Note over User: User sees confirmation immediately
    PostAPI ->> Kafka: Publish (post.created, post_id=789, user_id=123)
    Kafka ->> FanoutSvc: Consumer picks up event
    FanoutSvc ->> Postgres: SELECT follower_id FROM follows WHERE followee_id=123
    Postgres -->> FanoutSvc: [5,000 follower IDs]
    FanoutSvc ->> FanoutSvc: Partition into 50 batches (100 each)
    Note over FanoutSvc, Redis: Parallel fanout to 5,000 followers

    loop For each batch (50 parallel workers)
        FanoutSvc ->> WorkerPool: Process batch [follower_ids]
        WorkerPool ->> Redis: ZADD timeline:follower1 timestamp post_id
        WorkerPool ->> Redis: ZADD timeline:follower2 timestamp post_id
        WorkerPool ->> Redis: ... (100 writes per worker)
        Redis -->> WorkerPool: OK
    end

    Note over Redis: All 5,000 timelines updated in ~5 seconds
    Redis ->> Follower: New post available in feed
    Follower ->> Follower: Next feed refresh shows new post
    Note over Follower: Followers see post within 5-10 seconds
```

---

## 5. Fanout-on-Read Flow (Celebrity)

**Flow:**

This sequence shows the fanout-on-read strategy for celebrities (> 10K followers), where posts are fetched at read time
instead of pre-computed.

**Steps:**

1. **Celebrity Posts** (0ms): Celebrity publishes new post
2. **PostgreSQL Write** (50ms): Insert post metadata only (no fanout)
3. **User Feed Request** (1000ms): Follower opens app and requests feed
4. **Check Celebrity Following** (1010ms): Feed service detects user follows 3 celebrities
5. **Fanout-on-Read Query** (1030ms): Query PostgreSQL for recent posts from those 3 celebrities
6. **Merge with Pre-Computed** (1040ms): Combine celebrity posts with regular timeline
7. **Return Feed** (1050ms): Send merged feed to user

**Performance:**

- **Write Savings**: 1 post → 1 database write (vs 100M timeline writes)
- **Read Overhead**: +20ms per feed request (celebrity query)
- **Trade-off**: Slightly slower feed generation, but massive write savings

**When to Use:**

- User has > 10K followers (celebrity threshold)
- Prevents fanout write amplification
- Acceptable for users with high follower counts (read latency still < 150ms)

```mermaid
sequenceDiagram
    actor Celebrity
    participant CelebApp as Celebrity's App
    participant PostAPI as Post Service
    participant Postgres as PostgreSQL
    participant Kafka as Kafka (post.created)
    actor Follower
    participant FollowerApp as Follower's App
    participant FeedSvc as Feed Service
    participant RedisTimeline as Redis Timeline
    participant CelebQuery as Celebrity Query
    Celebrity ->> CelebApp: Create post
    CelebApp ->> PostAPI: POST /posts (user_id=999, followers=10M)
    PostAPI ->> PostAPI: Check follower_count > 10K → Skip fanout-on-write
    PostAPI ->> Postgres: INSERT INTO posts (user_id=999, caption, media)
    Postgres -->> PostAPI: post_id = 456
    PostAPI ->> Kafka: Publish (post.created, celebrity=true)
    Note over Kafka: No fanout workers triggered
    PostAPI -->> CelebApp: 200 OK
    CelebApp -->> Celebrity: "Post published!"
    Note over Follower: Later, follower opens app
    Follower ->> FollowerApp: Open app
    FollowerApp ->> FeedSvc: GET /feed (user_id=777)
    FeedSvc ->> FeedSvc: Check if user follows any celebrities
    FeedSvc ->> Postgres: SELECT followee_id FROM follows WHERE follower_id=777 AND followee.follower_count > 10K
    Postgres -->> FeedSvc: [Celebrity IDs: 999, 888, 777]

    par Parallel Fetch
        FeedSvc ->> RedisTimeline: ZREVRANGE timeline:777 0 49
        RedisTimeline -->> FeedSvc: [Regular posts: 30 IDs]
    and
        FeedSvc ->> CelebQuery: SELECT post_id FROM posts WHERE user_id IN (999, 888, 777) ORDER BY created_at DESC LIMIT 20
        CelebQuery -->> FeedSvc: [Celebrity posts: 20 IDs]
    end

    FeedSvc ->> FeedSvc: Merge regular + celebrity posts (60/40 ratio)
    FeedSvc ->> FeedSvc: Rank by timestamp
    FeedSvc -->> FollowerApp: Top 50 posts (merged)
    FollowerApp -->> Follower: Display feed
    Note over Follower: Total latency: ~120ms (acceptable)
```

---

## 6. Visual Search Flow

**Flow:**

This sequence demonstrates the visual similarity search feature, where users can find images similar to a given image
using CNN embeddings and vector search.

**Steps:**

1. **User Action** (0ms): User clicks "Find Similar" on an image
2. **API Request** (10ms): GET /visual-search?post_id=789
3. **Fetch Embedding** (20ms): Retrieve pre-computed 2048-dim vector from vector DB
4. **ANN Search** (50ms): Run approximate nearest neighbor search using HNSW algorithm
5. **Retrieve Candidates** (70ms): Get top 100 similar post IDs
6. **Filter** (80ms): Remove posts user has already seen (Bloom filter)
7. **Personalization** (100ms): Apply user's preference model to re-rank
8. **Hydration** (120ms): Fetch post metadata from Redis/PostgreSQL
9. **Response** (130ms): Return top 50 similar posts

**Performance:**

- **Search Latency**: <50ms for 100 nearest neighbors
- **Index Size**: 10B images × 2048 dims = 80 TB
- **Accuracy**: 95% recall@100 (finds 95 of top 100 truly similar images)

**Index Update:**

- New images indexed every hour (batch process)
- Eventual consistency acceptable for discovery feature

```mermaid
sequenceDiagram
    actor User
    participant App as Mobile App
    participant Gateway as API Gateway
    participant SearchSvc as Visual Search Service
    participant VectorDB as Vector Database (FAISS)
    participant Filter as Bloom Filter
    participant PersonalRank as Personalization Model
    participant RedisCache as Redis Post Cache
    participant Postgres as PostgreSQL
    User ->> App: Click "Find Similar" on image
    App ->> Gateway: GET /visual-search?post_id=789
    Gateway ->> SearchSvc: Forward request
    SearchSvc ->> VectorDB: GET embedding for post_id=789
    VectorDB -->> SearchSvc: [2048-dim vector]
    SearchSvc ->> VectorDB: ANN search (k=100, HNSW)
    Note over VectorDB: HNSW algorithm traverses graph index
    VectorDB -->> SearchSvc: [100 similar post IDs with scores]
    SearchSvc ->> Filter: Check if user has seen posts (user_id=123)
    Filter -->> SearchSvc: Remove 15 already-seen posts
    SearchSvc ->> PersonalRank: Re-rank remaining 85 posts (user_id=123)
    PersonalRank ->> PersonalRank: Apply user preference model
    PersonalRank -->> SearchSvc: [Ranked 85 post IDs]
    SearchSvc ->> SearchSvc: Take top 50

    par Hydrate Post Details
        SearchSvc ->> RedisCache: HMGET post:* (batch 50 posts)
        RedisCache -->> SearchSvc: [40 cache hits]
    and
        SearchSvc ->> Postgres: SELECT * FROM posts WHERE post_id IN (10 misses)
        Postgres -->> SearchSvc: [10 post metadata]
    end

    SearchSvc ->> SearchSvc: Combine hydrated data
    SearchSvc -->> Gateway: 200 OK (50 similar posts)
    Gateway -->> App: JSON response
    App -->> User: Display similar images grid
    Note over User: Total: ~130ms
```

---

## 7. Cache Invalidation Flow

**Flow:**

This sequence shows the cache invalidation workflow when a user edits or deletes a post, ensuring all caches are updated
across multiple layers.

**Steps:**

1. **User Action** (0ms): User edits post caption or deletes post
2. **API Request** (10ms): PUT /posts/789 or DELETE /posts/789
3. **PostgreSQL Update** (30ms): Update or soft-delete post in database (source of truth)
4. **Kafka Event** (40ms): Publish `post.updated` or `post.deleted` event
5. **Cache Invalidation Worker** (50ms): Consumer picks up event
6. **Layer 1 - Redis Post Cache** (60ms): DELETE `post:789` key
7. **Layer 2 - Redis Timeline Cache** (80ms): ZREM from all affected timelines
8. **Layer 3 - CDN Purge** (200ms): Send purge request to Cloudflare API
9. **CDN Propagation** (60,000ms): Purge propagates to 200+ edge locations in ~1 minute

**Performance:**

- **Database Consistency**: Immediate (strong consistency)
- **Redis Consistency**: <100ms (eventual)
- **CDN Consistency**: ~1 minute (eventual)

**Trade-offs:**

- **Eventual Consistency**: Users may see stale content for up to 1 minute
- **Acceptable**: Post edits are rare compared to reads (1:10,000 ratio)

```mermaid
sequenceDiagram
    actor User
    participant App as Mobile App
    participant PostAPI as Post Service
    participant Postgres as PostgreSQL
    participant Kafka as Kafka (post.updated)
    participant InvalidWorker as Invalidation Worker
    participant RedisPost as Redis Post Cache
    participant RedisTimeline as Redis Timeline Cache
    participant CDN_API as CDN Purge API
    participant CDN as Cloudflare Edge (200+ PoPs)
    participant Follower as Follower's Device
    User ->> App: Edit post caption
    App ->> PostAPI: PUT /posts/789 (new_caption="Updated!")
    PostAPI ->> Postgres: UPDATE posts SET caption='Updated!' WHERE post_id=789
    Postgres -->> PostAPI: 1 row updated
    PostAPI -->> App: 200 OK
    App -->> User: "Post updated"
    Note over User: User sees confirmation immediately
    PostAPI ->> Kafka: Publish (post.updated, post_id=789)
    Kafka ->> InvalidWorker: Consumer picks up event

    par Layer 1: Redis Post Cache
        InvalidWorker ->> RedisPost: DEL post:789
        RedisPost -->> InvalidWorker: OK (cache cleared)
    end

    par Layer 2: Redis Timeline Cache
        InvalidWorker ->> Postgres: SELECT follower_id FROM follows WHERE followee_id=user_789
        Postgres -->> InvalidWorker: [5,000 follower IDs]

        loop For each follower
            InvalidWorker ->> RedisTimeline: ZREM timeline:follower_id post_id_789
        end

        Note over RedisTimeline: All timelines updated in ~1 second
    end

    par Layer 3: CDN Purge
        InvalidWorker ->> CDN_API: POST /purge (url=/image/789.jpg)
        CDN_API ->> CDN: Propagate purge to all PoPs
        Note over CDN: Purge completes in ~1 minute
    end

    Note over Follower: Followers see updated post on next refresh
    Follower ->> CDN: GET /image/789.jpg
    CDN ->> CDN: Cache miss (purged)
    CDN ->> Postgres: Fetch fresh content
    Postgres -->> CDN: New caption "Updated!"
    CDN -->> Follower: Fresh content
```

---

## 8. Post Deletion Flow

**Flow:**

This sequence shows the comprehensive post deletion workflow, ensuring the post is removed from all storage layers and
timelines.

**Steps:**

1. **User Action** (0ms): User deletes post
2. **Soft Delete** (30ms): Mark post as deleted in PostgreSQL (don't physically delete)
3. **Kafka Event** (40ms): Publish `post.deleted` event
4. **Timeline Cleanup** (1000ms): Remove from all followers' timelines
5. **Cache Cleanup** (50ms): Delete from Redis caches
6. **CDN Cleanup** (60,000ms): Purge media files from CDN
7. **Object Storage** (background): Archive media files (move to glacier after 90 days)

**Performance:**

- **User Confirmation**: <100ms (after soft delete)
- **Timeline Cleanup**: ~1 second for 5,000 followers
- **Full Cleanup**: ~1 minute (CDN propagation)

**Data Retention:**

- **Soft Delete**: Allows recovery within 30 days (user can undo)
- **Hard Delete**: After 30 days, permanently delete from object storage
- **Compliance**: GDPR right to deletion (expedited process)

```mermaid
sequenceDiagram
    actor User
    participant App as Mobile App
    participant PostAPI as Post Service
    participant Postgres as PostgreSQL
    participant Kafka as Kafka (post.deleted)
    participant CleanupWorker as Cleanup Worker
    participant RedisTimeline as Redis Timeline
    participant RedisPost as Redis Post Cache
    participant CDN as CDN Purge
    participant S3 as S3 Bucket
    User ->> App: Delete post
    App ->> App: Confirm "Are you sure?"
    User ->> App: Confirm deletion
    App ->> PostAPI: DELETE /posts/789
    PostAPI ->> Postgres: UPDATE posts SET deleted_at=NOW() WHERE post_id=789
    Note over Postgres: Soft delete (not physical delete)
    Postgres -->> PostAPI: 1 row updated
    PostAPI -->> App: 200 OK
    App ->> App: Remove post from local cache
    App -->> User: "Post deleted"
    Note over User: User sees confirmation <100ms
    PostAPI ->> Kafka: Publish (post.deleted, post_id=789, user_id=123)
    Kafka ->> CleanupWorker: Consumer picks up event
    CleanupWorker ->> Postgres: SELECT follower_id FROM follows WHERE followee_id=123
    Postgres -->> CleanupWorker: [5,000 follower IDs]

    par Timeline Cleanup
        loop For each follower
            CleanupWorker ->> RedisTimeline: ZREM timeline:follower_id 789
        end
        Note over RedisTimeline: 5,000 timelines cleaned in ~1 second
    end

    par Cache Cleanup
        CleanupWorker ->> RedisPost: DEL post:789
        CleanupWorker ->> RedisPost: DEL post:likes:789
        CleanupWorker ->> RedisPost: DEL post:comments:789
    end

    par CDN Cleanup
        CleanupWorker ->> CDN: POST /purge (post_789_*.jpg, post_789_*.mp4)
        Note over CDN: Purge propagates to 200+ PoPs in ~1 min
    end

    par Object Storage Cleanup (Background)
        CleanupWorker ->> S3: Tag objects for deletion (30-day retention)
        Note over S3: After 30 days, lifecycle policy moves to Glacier
    end

    Note over User: Post disappears from all feeds within 1 minute
```

---

## 9. Recommendation Engine Query Flow

**Flow:**

This sequence shows the online serving flow of the recommendation engine, fetching personalized content recommendations
using ML models.

**Steps:**

1. **Feed Request** (0ms): User opens app, feed service needs recommendations
2. **Candidate Generation** (20ms): Fetch 1000 candidate posts from multiple sources
    - Popular posts (last 24 hours)
    - Posts from similar users
    - Trending hashtags
    - Visual similarity
3. **Feature Extraction** (30ms): Fetch user features, post features from Redis
4. **Batch Inference** (60ms): Run LightGBM model to score all 1000 candidates
5. **Re-ranking** (70ms): Apply business rules (diversity, freshness, novelty)
6. **Return Top-K** (75ms): Return top 50 posts

**Performance:**

- **Total Latency**: <80ms for 1000 candidates
- **Throughput**: 347k requests/sec (recommendation requests)
- **Model Size**: 500 MB (deployed in memory)

**Model Serving:**

- **Deployment**: TensorFlow Serving or custom REST API
- **Replicas**: 100 instances for high availability
- **Load Balancing**: Round-robin with health checks

```mermaid
sequenceDiagram
    participant FeedSvc as Feed Service
    participant RecoAPI as Recommendation API
    participant CandidateGen as Candidate Generator
    participant PopularCache as Popular Posts Cache
    participant SimilarUsers as Similar Users DB
    participant TrendingHash as Trending Hashtags
    participant FeatureStore as Feature Store (Redis)
    participant MLModel as ML Model (LightGBM)
    participant Reranker as Re-ranker
    FeedSvc ->> RecoAPI: GET /recommend?user_id=123&limit=50
    RecoAPI ->> CandidateGen: Generate candidates (target=1000)

    par Candidate Sources
        CandidateGen ->> PopularCache: Get top 400 popular posts (last 24h)
        PopularCache -->> CandidateGen: [400 post IDs]
    and
        CandidateGen ->> SimilarUsers: Get posts from users similar to 123
        SimilarUsers -->> CandidateGen: [300 post IDs]
    and
        CandidateGen ->> TrendingHash: Get posts from user's favorite hashtags
        TrendingHash -->> CandidateGen: [200 post IDs]
    and
        CandidateGen ->> FeatureStore: Get posts visually similar to user's past likes
        FeatureStore -->> CandidateGen: [100 post IDs]
    end

    CandidateGen -->> RecoAPI: [1000 candidate post IDs]
    RecoAPI ->> FeatureStore: Batch fetch features (user + posts)
    FeatureStore -->> RecoAPI: User features: [past_likes, saves, follows, demographics]
    FeatureStore -->> RecoAPI: Post features: [engagement_rate, freshness, author]
    RecoAPI ->> MLModel: Batch inference (1000 posts × features)
    Note over MLModel: LightGBM model predicts engagement probability
    MLModel -->> RecoAPI: [1000 scores: 0.01 to 0.95]
    RecoAPI ->> Reranker: Apply business rules
    Reranker ->> Reranker: Diversity: max 2 posts per author
    Reranker ->> Reranker: Freshness: boost posts < 6 hours old
    Reranker ->> Reranker: Novelty: penalize if similar to recent views
    Reranker -->> RecoAPI: [Re-ranked list]
    RecoAPI ->> RecoAPI: Select top 50
    RecoAPI -->> FeedSvc: [50 recommended post IDs]
    Note over FeedSvc: Total: ~80ms
```

---

## 10. Multi-Region Write Flow

**Flow:**

This sequence demonstrates how writes are handled in a multi-region active-active deployment, ensuring data consistency
and low latency.

**Steps:**

1. **User Post** (0ms): User in Europe creates post
2. **Geo-Routing** (10ms): Route53 routes request to EU region (nearest)
3. **Home Region Determination** (20ms): Compute user's home region by `hash(user_id) % 3`
4. **Cross-Region Write** (50ms): If home region is US, forward write to US
5. **PostgreSQL Write** (70ms): Write to primary database in home region
6. **Sync Replication** (80ms): Synchronously replicate to other 2 regions
7. **Acknowledgment** (90ms): Return success to user
8. **Async Cache** (150ms): Update Redis caches in all 3 regions

**Performance:**

- **Same-Region Write**: 50ms (no cross-region hop)
- **Cross-Region Write**: 150ms (additional 100ms for replication)
- **Data Loss**: RPO < 1 second (synchronous replication)

**Consistency:**

- **Strong Consistency**: For writes (sync replication)
- **Eventual Consistency**: For caches (async replication)

```mermaid
sequenceDiagram
    actor User as User (Europe)
    participant DNS as Route53 DNS
    participant EU_LB as EU Load Balancer
    participant EU_App as EU App Server
    participant US_App as US App Server
    participant US_PG as US PostgreSQL (Primary)
    participant EU_PG as EU PostgreSQL (Replica)
    participant AP_PG as AP PostgreSQL (Replica)
    participant Kafka as Kafka (Global)
    participant EU_Redis as EU Redis
    participant US_Redis as US Redis
    User ->> DNS: POST /posts (create post)
    DNS ->> DNS: Geo-routing: user is in Europe
    DNS -->> EU_LB: Route to EU region
    EU_LB ->> EU_App: Forward request
    EU_App ->> EU_App: Compute home region: hash(user_id) % 3 = 0 (US)
    Note over EU_App: Home region is US (not EU)
    EU_App ->> US_App: Cross-region RPC (POST /posts)
    Note over EU_App, US_App: 50ms cross-Atlantic latency
    US_App ->> US_PG: INSERT INTO posts (user_id, caption, media)

    par Synchronous Replication
        US_PG ->> EU_PG: Replicate (sync)
        US_PG ->> AP_PG: Replicate (sync)
    end

    US_PG -->> US_App: post_id=789, ACK
    US_App -->> EU_App: 200 OK (post_id=789)
    EU_App -->> EU_LB: 200 OK
    EU_LB -->> User: "Post created"
    Note over User: Total: ~150ms (cross-region)
    US_App ->> Kafka: Publish (post.created, post_id=789)

    par Async Cache Updates
        Kafka ->> EU_Redis: Update cache (async)
        Kafka ->> US_Redis: Update cache (async)
    end

    Note over EU_Redis, US_Redis: Caches consistent within 200ms
```

---

## 11. CDN Cache Miss Flow

**Flow:**

This sequence shows what happens when a user requests an image that is not cached at the CDN edge, requiring a cache
miss and origin fetch.

**Steps:**

1. **User Request** (0ms): User's device requests image URL
2. **Edge Cache Check** (5ms): Cloudflare edge checks local cache
3. **Edge Cache Miss** (5ms): Image not found in edge cache
4. **Shield Cache Check** (50ms): Request forwarded to regional shield PoP
5. **Shield Cache Miss** (50ms): Image not in shield cache either
6. **Origin Fetch** (150ms): Shield requests from S3 origin (US)
7. **S3 Response** (200ms): S3 returns image (10MB takes 1 second)
8. **Shield Cache** (1200ms): Shield caches image (7-day TTL)
9. **Edge Cache** (1250ms): Edge caches image (7-day TTL)
10. **User Response** (1300ms): Image delivered to user

**Performance:**

- **Cache Hit (Edge)**: 5-20ms (90% of requests)
- **Cache Hit (Shield)**: 50-100ms (5% of requests)
- **Cache Miss (Origin)**: 1-2 seconds (5% of requests)

**Optimization:**

- **Pre-warming**: Popular images pre-pushed to CDN after upload
- **Stale-While-Revalidate**: Serve stale content while fetching fresh version

```mermaid
sequenceDiagram
    actor User as User (Asia)
    participant Browser as Browser
    participant Edge as CDN Edge (Tokyo)
    participant Shield as CDN Shield (Asia-Pacific)
    participant S3 as S3 Origin (US-East)
    User ->> Browser: Click image thumbnail
    Browser ->> Edge: GET https://cdn.instagram.com/image/789_640x640.jpg
    Edge ->> Edge: Check local cache
    Note over Edge: Cache MISS (image not cached)
    Edge ->> Shield: Forward request to shield PoP
    Shield ->> Shield: Check shield cache
    Note over Shield: Cache MISS (image not in shield)
    Shield ->> S3: GET /images/medium/789_640x640.jpg
    Note over Shield, S3: 100ms cross-region latency + transfer time
    S3 ->> S3: Read object from storage
    S3 -->> Shield: 200 OK (100 KB image data)
    Shield ->> Shield: Cache image (TTL: 7 days)
    Note over Shield: Cache-Control: public, max-age=604800, immutable
    Shield -->> Edge: Return image data
    Edge ->> Edge: Cache image (TTL: 7 days)
    Edge -->> Browser: 200 OK (image)
    Browser ->> Browser: Render image
    Browser -->> User: Display image
    Note over User: First request: 1-2 seconds (cache miss)
    Note over Edge: Subsequent requests served from edge cache in 5-20ms
    User ->> Browser: (Later) Request same image
    Browser ->> Edge: GET https://cdn.instagram.com/image/789_640x640.jpg
    Edge ->> Edge: Check cache → HIT!
    Edge -->> Browser: 200 OK (from cache)
    Browser -->> User: Display image (instant)
    Note over User: Subsequent requests: 5-20ms (cache hit)
```

---

## 12. Failed Upload Retry Flow

**Flow:**

This sequence demonstrates the retry mechanism when an image upload fails, ensuring reliable delivery despite transient
failures.

**Steps:**

1. **Upload Attempt** (0ms): Client uploads image to S3
2. **Network Failure** (2000ms): Connection drops mid-upload
3. **Client Retry** (3000ms): Client retries with exponential backoff
4. **S3 Multipart Upload** (3100ms): Use S3 multipart upload for resumability
5. **Partial Upload** (5000ms): Upload completes partially (3/5 parts)
6. **Failure Again** (5100ms): Another network failure
7. **Resume Upload** (6000ms): Client resumes from part 4 (doesn't re-upload parts 1-3)
8. **Success** (8000ms): All parts uploaded
9. **Complete Multipart** (8100ms): Client sends complete multipart request
10. **S3 Assembly** (8500ms): S3 assembles parts into final object
11. **Trigger Event** (9000ms): S3 triggers Kafka event for processing

**Performance:**

- **Retry Backoff**: 1s, 2s, 4s, 8s (exponential)
- **Max Retries**: 5 attempts before giving up
- **Success Rate**: 99.9% after retries

**User Experience:**

- **Progress Bar**: Shows upload progress (resumable)
- **Background Upload**: Continues even if app is closed (iOS/Android background task)

```mermaid
sequenceDiagram
    actor User
    participant App as Mobile App
    participant RetryLogic as Retry Logic
    participant S3 as S3 Bucket
    participant Kafka as Kafka Queue
    User ->> App: Upload image (10MB)
    App ->> RetryLogic: Initiate upload
    Note over RetryLogic: Attempt 1
    RetryLogic ->> S3: PUT /upload (multipart upload ID)
    S3 -->> RetryLogic: Upload ID: abc123
    RetryLogic ->> S3: Upload part 1 (2MB)
    S3 -->> RetryLogic: Part 1 ETag
    RetryLogic ->> S3: Upload part 2 (2MB)
    S3 -->> RetryLogic: Part 2 ETag
    RetryLogic ->> S3: Upload part 3 (2MB)
    S3 -x RetryLogic: Network error (connection dropped)
    Note over RetryLogic: Retry attempt 1 failed at part 3
    RetryLogic ->> RetryLogic: Wait 1 second (exponential backoff)
    Note over RetryLogic: Attempt 2 (resume from part 3)
    RetryLogic ->> S3: Upload part 3 (2MB) - retry
    S3 -->> RetryLogic: Part 3 ETag
    RetryLogic ->> S3: Upload part 4 (2MB)
    S3 -x RetryLogic: Network error (connection dropped again)
    Note over RetryLogic: Retry attempt 2 failed at part 4
    RetryLogic ->> RetryLogic: Wait 2 seconds (exponential backoff)
    App -->> User: "Retrying upload... (3/5 parts done)"
    Note over RetryLogic: Attempt 3 (resume from part 4)
    RetryLogic ->> S3: Upload part 4 (2MB) - retry
    S3 -->> RetryLogic: Part 4 ETag
    RetryLogic ->> S3: Upload part 5 (2MB)
    S3 -->> RetryLogic: Part 5 ETag
    Note over RetryLogic: All parts uploaded successfully
    RetryLogic ->> S3: Complete multipart upload (parts 1-5)
    S3 ->> S3: Assemble parts into final object
    S3 -->> RetryLogic: 200 OK (final object: image/789.jpg)
    RetryLogic -->> App: Upload successful
    App -->> User: "Upload complete!"
    S3 ->> Kafka: Trigger event (media.uploaded, object_key=image/789.jpg)
    Note over Kafka: Processing pipeline begins (see diagram 1)
```

---

## 13. Hot Key Mitigation Flow

**Flow:**

This sequence shows how the system mitigates the hot key problem when a viral post receives millions of likes per
minute, using distributed counters.

**Steps:**

1. **Viral Post** (0ms): Celebrity post goes viral, receiving 100k likes/second
2. **Shard Counter** (1ms): Each like is routed to one of 100 counter shards
3. **Hash User ID** (1ms): `shard = hash(user_id) % 100`
4. **Distributed INCR** (2ms): Increment specific shard counter
5. **Read Aggregation** (when reading): SUM all 100 shards to get total count
6. **Async Flush** (every 100ms): Flush local buffer to Redis

**Performance:**

- **Write Distribution**: 100k likes/sec distributed across 100 shards = 1k/sec per shard
- **Redis Capacity**: Each shard handles 1k writes/sec easily (vs 100k would overwhelm single key)
- **Read Overhead**: Reading requires SUM of 100 keys (~10ms vs 1ms for single key)

**Trade-offs:**

- **Write Scalability**: Can handle 10M+ likes/sec
- **Read Latency**: 10ms vs 1ms (acceptable for rare reads)
- **Complexity**: More complex counter logic

```mermaid
sequenceDiagram
    participant User1 as User 1
    participant User2 as User 2
    participant UserN as User N
    participant LB as Load Balancer
    participant App1 as App Server 1
    participant App2 as App Server 2
    participant AppN as App Server N
    participant Redis0 as Redis Shard 0<br/>post:likes:789:0
    participant Redis1 as Redis Shard 1<br/>post:likes:789:1
    participant Redis99 as Redis Shard 99<br/>post:likes:789:99
    Note over User1, UserN: 100,000 users like post in 1 second
    User1 ->> LB: POST /like (user_id=100, post_id=789)
    User2 ->> LB: POST /like (user_id=200, post_id=789)
    UserN ->> LB: POST /like (user_id=N, post_id=789)
    LB ->> App1: Route request
    LB ->> App2: Route request
    LB ->> AppN: Route request
    App1 ->> App1: shard = hash(100) % 100 = 23
    App2 ->> App2: shard = hash(200) % 100 = 47
    AppN ->> AppN: shard = hash(N) % 100 = 5
    App1 ->> Redis0: INCR post:likes:789:23
    App2 ->> Redis1: INCR post:likes:789:47
    AppN ->> Redis99: INCR post:likes:789:5
    Redis0 -->> App1: 1,234 (shard count)
    Redis1 -->> App2: 987 (shard count)
    Redis99 -->> AppN: 1,567 (shard count)
    App1 -->> User1: 200 OK (liked)
    App2 -->> User2: 200 OK (liked)
    AppN -->> UserN: 200 OK (liked)
    Note over Redis0, Redis99: 100k writes distributed across 100 shards = 1k/sec per shard
    Note over App1: Later, when reading total likes
    actor Reader as Reader User
    Reader ->> App1: GET /post/789 (fetch like count)

    par Aggregate Shards
        App1 ->> Redis0: GET post:likes:789:0
        App1 ->> Redis1: GET post:likes:789:1
        App1 ->> Redis99: GET post:likes:789:99
    end

    Redis0 -->> App1: 12,340
    Redis1 -->> App1: 13,567
    Redis99 -->> App1: 11,234
    App1 ->> App1: total_likes = SUM(all shards) = 1,234,567
    App1 -->> Reader: like_count: 1,234,567
    Note over Reader: Read aggregation takes ~10ms (pipeline 100 keys)
```

---

## 14. Redis Cache Failure Fallback

**Flow:**

This sequence demonstrates the circuit breaker pattern when Redis timeline cache fails, falling back to PostgreSQL with
graceful degradation.

**Steps:**

1. **Feed Request** (0ms): User requests feed
2. **Redis Query** (10ms): Attempt to fetch timeline from Redis
3. **Redis Failure** (20ms): Redis cluster is down (timeout after 10ms)
4. **Circuit Breaker Open** (20ms): After 50% failure rate, open circuit breaker
5. **Skip Redis** (25ms): Stop calling Redis for next 30 seconds
6. **Fallback to PostgreSQL** (100ms): Query PostgreSQL directly
7. **Rebuild Timeline** (150ms): Generate timeline from database
8. **Return Feed** (200ms): Return feed to user (slower, but functional)
9. **Background: Retry Redis** (30,000ms): Every 30 seconds, test if Redis is back
10. **Circuit Breaker Close** (30,100ms): If Redis responds, close circuit breaker

**Performance:**

- **Normal Latency**: 80ms (with Redis)
- **Degraded Latency**: 200ms (fallback to PostgreSQL)
- **User Impact**: Acceptable (still sub-300ms)

**Benefits:**

- **Graceful Degradation**: System remains operational
- **Self-Healing**: Automatically recovers when Redis is back

```mermaid
sequenceDiagram
    actor User
    participant App as Mobile App
    participant FeedSvc as Feed Service
    participant CircuitBreaker as Circuit Breaker
    participant Redis as Redis Timeline Cache
    participant Postgres as PostgreSQL
    participant Fallback as Fallback Builder
    User ->> App: Open app (request feed)
    App ->> FeedSvc: GET /feed (user_id=123)
    FeedSvc ->> CircuitBreaker: Check Redis circuit state
    CircuitBreaker -->> FeedSvc: CLOSED (Redis healthy)
    FeedSvc ->> Redis: ZREVRANGE timeline:123 0 49
    Note over Redis: Redis cluster is down!
    Redis -x FeedSvc: Timeout (10ms elapsed)
    Note over FeedSvc: Request failed
    FeedSvc ->> CircuitBreaker: Record failure
    CircuitBreaker ->> CircuitBreaker: Failure rate: 55% (> 50% threshold)
    CircuitBreaker ->> CircuitBreaker: OPEN circuit (stop calling Redis)
    Note over CircuitBreaker: Circuit breaker OPEN for 30 seconds
    FeedSvc ->> Fallback: Build timeline from PostgreSQL
    Fallback ->> Postgres: SELECT post_id FROM posts WHERE user_id IN (followers) ORDER BY created_at DESC LIMIT 50
    Postgres -->> Fallback: [50 post IDs]
    Fallback -->> FeedSvc: Timeline built
    FeedSvc -->> App: 200 OK (feed data)
    App -->> User: Display feed
    Note over User: Slower (200ms vs 80ms), but functional
    Note over CircuitBreaker: 30 seconds later, try half-open
    actor User2 as Another User
    User2 ->> App: Request feed
    App ->> FeedSvc: GET /feed (user_id=456)
    FeedSvc ->> CircuitBreaker: Check Redis circuit state
    CircuitBreaker -->> FeedSvc: HALF-OPEN (testing)
    FeedSvc ->> Redis: ZREVRANGE timeline:456 0 49 (test request)
    Note over Redis: Redis is back online!
    Redis -->> FeedSvc: [50 post IDs]
    FeedSvc ->> CircuitBreaker: Record success
    CircuitBreaker ->> CircuitBreaker: Success! Close circuit
    CircuitBreaker -->> FeedSvc: CLOSED (Redis healthy again)
    FeedSvc -->> App: 200 OK (feed data)
    App -->> User2: Display feed (fast again!)
    Note over User2: System recovered! Back to 80ms latency
```