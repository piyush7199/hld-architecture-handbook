# 2.3.5 Batch vs Stream Processing: Data at Rest vs. Data in Motion

## Intuitive Explanation

This concept dictates how a system handles data depending on the required speed:

- **Batch Processing (The Nightly Report):** Data is collected over a long period ($\text{hours}$ or $\text{days}$) and
  then processed all at once in a large batch. It provides accurate, complete results but with high latency.
- **Stream Processing (The Live Ticker):** Data is processed continuously as soon as it arrives. It provides results
  with extremely low latency ($\text{milliseconds}$) but is inherently more complex and deals with continuous, real-time
  windows of data.

## In-Depth Analysis

### 1. Batch Processing

Batch systems are designed for high throughput over large volumes of data, where latency is not a critical constraint.

- **Data State:** Data at Rest. Data is first written to storage (like a data warehouse or $\text{HDFS}$) and then
  computed.
- **Latency:** High (minutes to hours).
- **Completeness:** High. The system processes all known data for a specific window, ensuring accurate, full results (
  e.g., calculating the total sales for the last $24$ hours).
- **Tools:** $\text{Apache}$ $\text{Hadoop}$, $\text{Spark}$ $\text{Batch}$.
- **Use Cases:** End-of-day financial reconciliation, monthly reporting, generating machine learning models.

### 2. Stream Processing

Stream systems are designed for low latency and continuous computation on unbounded, never-ending streams of data.

- **Data State:** Data in Motion. Data is processed as events pass through the system.
- **Latency:** Low (milliseconds to seconds).
- **Completeness:** Eventual or approximate. Calculations are often window-based (e.g., "sales in the last 5 minutes"),
  and complex event ordering/deduplication is required.
- **Tools**: Apache $\text{Kafka}$ $\text{Streams}$, $\text{Apache}$ $\text{Flink}$, $\text{Spark}$ $\text{Streaming}$.
- **Use Cases:** Real-time fraud detection, live stock tickers, monitoring dashboard updates, $\text{IoT}$ processing.

### 3. Architectural Patterns

| Pattern             | Description                                                                                                                                                                                                       | Strategy                                                                                                                            |
|---------------------|-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|-------------------------------------------------------------------------------------------------------------------------------------|
| Lambda Architecture | Combines both $\text{Batch}$ and $\text{Stream}$ layers to get the best of both worlds. The $\text{Stream}$ layer provides fast, approximate views; the $\text{Batch}$ layer provides slow, accurate corrections. | Complexity. You have two codebases to maintain for the same logic.                                                                  |
| Kappa Architecture  | Simplification of Lambda. It processes all data as a stream (including historical data, which is treated as a stream replay). Batch layer is eliminated.                                                          | Simplicity and Unified Codebase. Requires a powerful stream processing engine (like $\text{Kafka}$) and excellent state management. |

### Key Concepts / Tradeoffs

| Feature     | Batch Processing                                                   | Stream Processing                                                   |
|-------------|--------------------------------------------------------------------|---------------------------------------------------------------------|
| Data Source | Bounded (finite set of records)                                    | Unbounded (infinite flow of events)                                 |
| Processing  | $\text{High}$ $\text{Throughput}$, $\text{CPU}$-$\text{intensive}$ | $\text{Low}$ $\text{Latency}$, $\text{Event}$-$\text{Driven}$       |
| Latency     | High (Minutes to Hours)                                            | Low (Milliseconds to Seconds)                                       |
| Example     | Calculating $\text{DAU}$ for yesterday at $3 \text{ AM}$.          | Updating a user's $\text{read}$ $\text{count}$ on a page instantly. |

---

## ‚úèÔ∏è Design Challenge

### Problem

You are building a system to track user behavior on your e-commerce site. Explain where you would use Batch Processing
and where you would use **Stream Processing** in this system.

- **Stream:** (Example: Updating the "currently viewing this product" counter.)
- **Batch:** (Example: Calculating personalized recommendations based on the last 30 days of click history.)

### Solution

#### üß© 1. Stream Processing

**Goal:** Process user actions in **real-time** for immediate insights or updates.

##### Use Cases:

| Stream Processing Use Case         | Description                                                                         | Example                                          |
|------------------------------------|-------------------------------------------------------------------------------------|--------------------------------------------------|
| **Live product activity counters** | Continuously update ‚ÄúX users currently viewing this product‚Äù                        | Use Kafka + Flink to increment counters in Redis |
| **Real-time alerts**               | Trigger ‚ÄúItem price dropped‚Äù or ‚ÄúFlash sale started‚Äù notifications instantly        | Low-latency event pipelines                      |
| **Fraud detection**                | Detect suspicious user actions as they happen (e.g., too many purchases per minute) | Stream joins & windowed aggregates               |
| **Session analytics**              | Track active sessions, bounce rates, or cart abandonment live                       | Stream windowing per session                     |
| **Operational dashboards**         | Show live site usage metrics and engagement graphs                                  | Flink/Kinesis ‚Üí Elasticsearch or Prometheus      |

##### ‚úÖ Why Stream Here?

- Requires low latency (milliseconds to seconds).
- Data changes continuously and drives real-time user experience (like counters or alerts).
- Stream systems like Apache Kafka + Flink / Spark Streaming are ideal.

#### üß© 2. Batch Processing

**Goal:** Perform **heavy, historical, or aggregated computations** periodically (hourly, daily, weekly).

##### Use Cases:

| Batch Processing Use Case            | Description                                                    | Example                                           |
|--------------------------------------|----------------------------------------------------------------|---------------------------------------------------|
| **Personalized recommendations**     | Train ML models on the past 30 days of click & purchase data   | Spark batch job aggregates user-item interactions |
| **Behavior analytics reports**       | Compute metrics like daily active users, top searched products | Nightly ETL job ‚Üí Data Warehouse                  |
| **Retention & churn prediction**     | Build predictive models using large-scale historical logs      | Offline ML pipelines                              |
| **Revenue and conversion reporting** | Aggregate sales across regions and campaigns                   | Daily rollup into BI dashboards                   |

##### ‚úÖ Why Batch Here?

- Computation is resource-intensive, but not time-sensitive.
- Results are needed every few hours or daily, not instantly.
- Batch tools like Apache Spark / Hadoop / BigQuery handle large historical data efficiently.

#### üß† Final Summary

| Processing Type       | Purpose              | Example                                                 | Tooling                 | Latency |
|-----------------------|----------------------|---------------------------------------------------------|-------------------------|---------|
| **Stream Processing** | Real-time updates    | ‚Äú500 users currently viewing this item‚Äù                 | Kafka + Flink / Kinesis | Seconds |
| **Batch Processing**  | Historical analytics | ‚ÄúRecommend similar items based on 30-day click history‚Äù | Spark / BigQuery        | Hours   |
