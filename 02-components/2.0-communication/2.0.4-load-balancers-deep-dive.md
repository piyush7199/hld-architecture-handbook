# 2.0.4 Load Balancers Deep Dive: Distributing Traffic for Scale and Availability

## Intuitive Explanation

Imagine a popular restaurant with only one waiter. During rush hour, that waiter becomes overwhelmed, customers wait too
long, and service breaks down.

**Load Balancers** are like having multiple waiters and a smart host who directs customers to the waiter with the
shortest queue. The host (load balancer) sits at the entrance, monitors which waiter (server) is least busy, and routes
each customer (request) to the best waiter.

**In distributed systems:**

- **Load Balancer:** The traffic director that sits between clients and multiple backend servers
- **Goal:** Distribute incoming requests evenly across servers to prevent any single server from being overwhelmed
- **Benefit:** Enables horizontal scaling (add more servers) and high availability (if one server fails, others continue
  serving)

---

## In-Depth Analysis

### 1. What is a Load Balancer?

A **Load Balancer (LB)** is a reverse proxy that sits between clients and a group of backend servers, distributing
network traffic efficiently across multiple servers.

**Key Functions:**

- **Traffic Distribution:** Routes requests to healthy backend servers
- **Health Monitoring:** Continuously checks server health and removes unhealthy servers
- **Session Management:** Can maintain sticky sessions (route same client to same server)
- **SSL Termination:** Handles HTTPS encryption/decryption (offloads from backend)
- **Request Routing:** Can route based on URL path, headers, or other criteria

**Architecture:**

```
Client â†’ Load Balancer â†’ Backend Servers
                        â”œâ”€ Server 1
                        â”œâ”€ Server 2
                        â””â”€ Server 3
```

### 2. Layer 4 vs Layer 7 Load Balancing

#### Layer 4 (L4) Load Balancing (Transport Layer)

**What It Does:**

- Operates at the TCP/UDP level
- Routes based on IP address and port number
- Doesn't inspect application data (HTTP headers, URLs)

**How It Works:**

```
Client â†’ LB (sees: IP=10.0.1.5, Port=80) â†’ Routes to Server 1
Client â†’ LB (sees: IP=10.0.1.5, Port=80) â†’ Routes to Server 2
```

**Pros:**

- **Fast:** Low latency (no application-level inspection)
- **Simple:** Less CPU overhead
- **Protocol Agnostic:** Works with any TCP/UDP protocol (HTTP, gRPC, database connections)

**Cons:**

- **Limited Routing:** Can't route based on URL path or HTTP headers
- **No Content-Aware:** Can't make decisions based on request content

**Use Cases:**

- Simple HTTP load balancing
- Database connection pooling
- High-throughput scenarios where speed matters most

**Examples:**

- AWS Network Load Balancer (NLB)
- HAProxy in TCP mode
- NGINX stream module

#### Layer 7 (L7) Load Balancing (Application Layer)

**What It Does:**

- Operates at the HTTP/HTTPS level
- Inspects application data (URLs, headers, cookies)
- Can route based on request content

**How It Works:**

```
Client â†’ LB (sees: GET /api/users, Header: X-User-ID: 123)
       â†’ Routes to User Service (based on /api/users path)

Client â†’ LB (sees: GET /api/orders, Header: X-User-ID: 123)
       â†’ Routes to Order Service (based on /api/orders path)
```

**Pros:**

- **Content-Aware Routing:** Route based on URL path, headers, cookies
- **Microservices Support:** Route to different services based on path
- **Advanced Features:** SSL termination, request/response manipulation
- **Better Security:** Can inspect and filter malicious requests

**Cons:**

- **Slower:** Higher latency (application-level inspection)
- **More CPU:** Requires more processing power
- **HTTP Only:** Limited to HTTP/HTTPS protocols

**Use Cases:**

- Microservices architectures (route /users â†’ User Service, /orders â†’ Order Service)
- A/B testing (route based on user ID or headers)
- Blue-green deployments (route based on headers)

**Examples:**

- AWS Application Load Balancer (ALB)
- NGINX (HTTP mode)
- HAProxy (HTTP mode)
- Traefik

### 3. Load Balancing Algorithms

#### Round Robin

**How It Works:**

- Distributes requests sequentially to each server in rotation
- Server 1 â†’ Server 2 â†’ Server 3 â†’ Server 1 (repeat)

**Example:**

```
Request 1 â†’ Server 1
Request 2 â†’ Server 2
Request 3 â†’ Server 3
Request 4 â†’ Server 1
Request 5 â†’ Server 2
```

**Pros:**

- Simple and fair distribution
- Works well when servers have similar capacity

**Cons:**

- Doesn't consider server load or response time
- Uneven distribution if servers have different capacities

**Use Case:**

- Servers with similar capacity and load

#### Least Connections

**How It Works:**

- Routes request to server with fewest active connections
- Tracks active connections per server

**Example:**

```
Server 1: 10 active connections
Server 2: 5 active connections
Server 3: 8 active connections
â†’ New request â†’ Server 2 (least connections)
```

**Pros:**

- Better for long-lived connections (WebSockets, database connections)
- Adapts to server load automatically

**Cons:**

- Requires tracking connection state
- May not account for server capacity differences

**Use Case:**

- Long-lived connections (WebSockets, gRPC)
- Servers with varying processing times

#### IP Hash (Sticky Sessions)

**How It Works:**

- Hashes client IP address to determine server
- Same client IP always routes to same server

**Example:**

```
hash(192.168.1.100) % 3 = 1 â†’ Server 1
hash(192.168.1.101) % 3 = 2 â†’ Server 2
hash(192.168.1.102) % 3 = 0 â†’ Server 3
```

**Pros:**

- Maintains session affinity (sticky sessions)
- Predictable routing

**Cons:**

- Uneven distribution if IPs are clustered (e.g., corporate networks)
- Doesn't adapt to server load

**Use Case:**

- When session state is stored on server (not in shared cache)
- When you need consistent routing per client

#### Weighted Round Robin

**How It Works:**

- Similar to round robin, but servers have weights
- Servers with higher weights receive more requests

**Example:**

```
Server 1: Weight 3 (receives 3 requests)
Server 2: Weight 2 (receives 2 requests)
Server 3: Weight 1 (receives 1 request)
```

**Pros:**

- Accounts for server capacity differences
- Flexible configuration

**Cons:**

- Requires manual weight configuration
- Doesn't adapt to real-time load

**Use Case:**

- Servers with different capacities (e.g., 2x CPU, 4x CPU)

#### Least Response Time

**How It Works:**

- Routes to server with lowest average response time
- Tracks response times per server

**Pros:**

- Adapts to server performance
- Routes to fastest server

**Cons:**

- Requires response time tracking
- May cause oscillation (fast server gets overloaded)

**Use Case:**

- When response time varies significantly between servers

### 4. Health Checks

**Purpose:** Automatically detect and remove unhealthy servers from the pool

**Types:**

**A. Active Health Checks:**

- Load balancer periodically sends health check requests to servers
- Server responds with health status
- If health check fails, server removed from pool

**B. Passive Health Checks:**

- Monitor actual request/response patterns
- If server returns errors or timeouts, mark as unhealthy

**Health Check Configuration:**

```
Interval: 30 seconds (how often to check)
Timeout: 5 seconds (max wait for response)
Healthy Threshold: 2 (consecutive successes to mark healthy)
Unhealthy Threshold: 3 (consecutive failures to mark unhealthy)
Path: /health (endpoint to check)
```

**Example:**

```
LB â†’ Server 1: GET /health â†’ 200 OK (healthy)
LB â†’ Server 2: GET /health â†’ 500 Error (unhealthy, remove)
LB â†’ Server 3: GET /health â†’ Timeout (unhealthy, remove)
```

### 5. Sticky Sessions (Session Affinity)

**Problem:** User logs in, session stored on Server 1. Next request goes to Server 2, which doesn't have session â†’ user
logged out.

**Solution:** Sticky Sessions (route same user to same server)

**Implementation:**

**A. Cookie-Based:**

```
LB sets cookie: SERVER_ID=server1
Client sends cookie with requests
LB routes to Server 1 based on cookie
```

**B. IP Hash:**

```
hash(client_ip) % num_servers = server_index
Same IP always routes to same server
```

**Trade-offs:**

- âœ… Maintains session state
- âŒ Uneven load distribution (some servers may be overloaded)
- âŒ Server failure loses sessions (unless session replicated)

**Best Practice:**

- Use shared session store (Redis) instead of sticky sessions
- Allows any server to handle any request

### 6. SSL Termination

**What It Is:**

- Load balancer handles SSL/TLS encryption/decryption
- Backend servers receive unencrypted HTTP traffic

**Flow:**

```
Client â†’ LB (HTTPS) â†’ Decrypt â†’ Backend (HTTP)
Client â† LB (HTTPS) â† Encrypt â† Backend (HTTP)
```

**Pros:**

- **Offloads CPU:** Backend servers don't handle SSL
- **Centralized Certificates:** Manage certificates in one place
- **Performance:** SSL hardware acceleration on LB

**Cons:**

- **Security:** Traffic unencrypted between LB and backend (use private network)
- **Certificate Management:** Must manage certificates on LB

**Alternative: SSL Passthrough**

- LB forwards encrypted traffic to backend
- Backend handles SSL termination
- More secure but higher backend CPU usage

### 7. Load Balancer Types

#### Hardware Load Balancers

**Examples:** F5 BIG-IP, Citrix ADC

**Pros:**

- High performance (dedicated hardware)
- Advanced features (WAF, DDoS protection)
- Reliable (enterprise-grade)

**Cons:**

- Expensive
- Less flexible (hardware upgrades)
- Vendor lock-in

#### Software Load Balancers

**Examples:** NGINX, HAProxy, Traefik

**Pros:**

- Cost-effective (runs on commodity hardware)
- Flexible (easy to configure and update)
- Open source options available

**Cons:**

- Lower performance than hardware (but usually sufficient)
- Requires server management

#### Cloud Load Balancers

**Examples:** AWS ELB/ALB/NLB, GCP Load Balancer, Azure Load Balancer

**Pros:**

- Managed service (no infrastructure management)
- Auto-scaling
- Integrated with cloud services
- Pay-as-you-go pricing

**Cons:**

- Vendor lock-in
- Less control over configuration
- Can be expensive at scale

---

## When to Use Load Balancers

### âœ… Use Load Balancers When:

1. **Horizontal Scaling:** You have multiple backend servers and need to distribute load
2. **High Availability:** Need to handle server failures gracefully
3. **SSL Termination:** Want to offload SSL processing from backend servers
4. **Microservices:** Need to route requests to different services based on path/headers
5. **Geographic Distribution:** Need to route users to nearest data center
6. **A/B Testing:** Need to route traffic to different versions of application

### âŒ Don't Use Load Balancers When:

1. **Single Server:** Only one backend server (adds unnecessary latency)
2. **Low Traffic:** Traffic doesn't justify additional infrastructure
3. **Client-Side Load Balancing:** Using service mesh or client-side discovery (may be redundant)

---

## Real-World Examples

### AWS Application Load Balancer (ALB)

**Use Case:** Microservices architecture

**Features:**

- Layer 7 load balancing
- Path-based routing (/api/users â†’ User Service)
- Host-based routing (api.example.com â†’ API Service)
- Integrated with AWS services (Auto Scaling, ECS)

**Example:**

```
/api/users â†’ User Service (3 instances)
/api/orders â†’ Order Service (5 instances)
/api/payments â†’ Payment Service (2 instances)
```

### NGINX

**Use Case:** High-performance web applications

**Features:**

- Both L4 and L7 load balancing
- Reverse proxy and web server
- Highly configurable
- Open source

**Example Configuration:**

```nginx
upstream backend {
    least_conn;
    server 10.0.1.5:8080;
    server 10.0.1.6:8080;
    server 10.0.1.7:8080;
}

server {
    listen 80;
    location / {
        proxy_pass http://backend;
    }
}
```

### HAProxy

**Use Case:** High-availability database clusters

**Features:**

- Excellent for TCP load balancing
- Advanced health checks
- Statistics dashboard
- Open source

**Example:**

```
MySQL Read Replicas:
- Master: 10.0.1.10:3306 (writes)
- Replica 1: 10.0.1.11:3306 (reads)
- Replica 2: 10.0.1.12:3306 (reads)

HAProxy routes reads to replicas, writes to master
```

---

## Load Balancers vs. Other Components

| Component         | Purpose                                       | When to Use                                      |
|-------------------|-----------------------------------------------|--------------------------------------------------|
| **Load Balancer** | Distribute traffic across servers             | Multiple backend servers, need high availability |
| **API Gateway**   | API management, authentication, rate limiting | Microservices, need API-level features           |
| **Reverse Proxy** | Forward requests to backend, SSL termination  | Single backend or simple routing                 |
| **Service Mesh**  | Service-to-service communication              | Microservices, need advanced traffic management  |

**Note:** Load balancers are often part of API Gateway or Service Mesh solutions.

---

## Common Anti-Patterns

### âŒ **1. Single Load Balancer (No Redundancy)**

**Problem:** Load balancer becomes single point of failure

**Solution:** Use multiple load balancers (active-passive or active-active)

```
âŒ Bad:
Client â†’ Single LB â†’ Backend Servers
(If LB fails, entire system down)

âœ… Good:
Client â†’ DNS â†’ Multiple LBs (active-active)
              â”œâ”€ LB 1
              â””â”€ LB 2
```

### âŒ **2. No Health Checks**

**Problem:** Unhealthy servers continue receiving traffic

**Solution:** Implement health checks

```
âŒ Bad:
Server 1 (crashed) â†’ Still receives requests â†’ All requests fail

âœ… Good:
LB â†’ Health Check â†’ Server 1 (unhealthy) â†’ Removed from pool
```

### âŒ **3. Sticky Sessions Without Session Replication**

**Problem:** Server failure loses all user sessions

**Solution:** Use shared session store (Redis) instead

```
âŒ Bad:
User â†’ Server 1 (session stored locally)
Server 1 crashes â†’ User logged out

âœ… Good:
User â†’ Any Server â†’ Session in Redis â†’ Survives server failure
```

### âŒ **4. Load Balancer as Bottleneck**

**Problem:** Single load balancer can't handle traffic

**Solution:** Scale load balancers horizontally or use cloud-managed LB

```
âŒ Bad:
100k requests/sec â†’ Single LB (max 10k req/sec) â†’ Overloaded

âœ… Good:
100k requests/sec â†’ Cloud LB (auto-scales) â†’ Handles load
```

---

## Trade-offs Summary

| Aspect                     | What You Gain                                | What You Sacrifice                            |
|----------------------------|----------------------------------------------|-----------------------------------------------|
| **Layer 7 Load Balancing** | Content-aware routing, microservices support | Higher latency, more CPU usage                |
| **Layer 4 Load Balancing** | Low latency, high throughput                 | Limited routing options                       |
| **Sticky Sessions**        | Session state on server                      | Uneven load, server failure loses sessions    |
| **Health Checks**          | Automatic failure detection                  | Additional overhead, configuration complexity |
| **SSL Termination**        | Offloads CPU from backend                    | Traffic unencrypted between LB and backend    |

---

## References

- **AWS ELB Documentation:
  ** [https://docs.aws.amazon.com/elasticloadbalancing/](https://docs.aws.amazon.com/elasticloadbalancing/)
- **NGINX Load Balancing:
  ** [https://nginx.org/en/docs/http/load_balancing.html](https://nginx.org/en/docs/http/load_balancing.html)
- **HAProxy Documentation:** [http://www.haproxy.org/#docs](http://www.haproxy.org/#docs)
- **Related Chapters:**
    - [1.2.2 Networking Components](../01-principles/1.2.2-networking-components.md) - DNS, Load Balancers, CDNs
    - [1.1.3 Availability and Reliability](../01-principles/1.1.3-availability-reliability.md) - High availability
      patterns

---

## âœï¸ Design Challenge

### Problem

You are designing a high-traffic e-commerce platform that must handle 1 million requests per second during peak hours (
Black Friday). The platform consists of:

1. **API Gateway** (handles authentication, rate limiting)
2. **User Service** (10 instances)
3. **Product Service** (20 instances)
4. **Order Service** (15 instances)
5. **Payment Service** (5 instances)

**Requirements:**

1. Distribute traffic evenly across service instances
2. Handle server failures gracefully (automatic failover)
3. Support sticky sessions for shopping cart (cart stored on server)
4. SSL termination at load balancer
5. Route requests to correct service based on URL path (/api/users â†’ User Service)

**Constraints:**

- Each service instance can handle 10,000 requests/sec
- Server failures occur ~1% of the time
- Shopping cart sessions last 30 minutes
- Must support WebSocket connections for real-time updates

Design a load balancing strategy that:

- Handles 1M requests/sec
- Routes to correct service
- Maintains session affinity for cart
- Handles failures automatically
- Supports WebSocket connections

### Solution

#### ðŸ§© Scenario

- **Traffic:** 1 million requests/sec
- **Services:** 4 microservices with 50 total instances
- **Session Affinity:** Required for shopping cart
- **WebSocket:** Required for real-time updates
- **SSL:** Termination at load balancer

**Calculations:**

- **Total Capacity:** 50 instances Ã— 10k req/sec = 500k req/sec (need 2x for redundancy)
- **Load Balancers Needed:** 1M req/sec Ã· 100k req/sec per LB = 10 LBs minimum

#### âœ… Step 1: Load Balancer Architecture

**Choice: AWS Application Load Balancer (ALB) with Multiple Target Groups**

**Why:**

- **Layer 7:** Supports path-based routing (/api/users â†’ User Service)
- **Target Groups:** Separate target group per service
- **Auto-Scaling:** Automatically scales with traffic
- **Health Checks:** Built-in health monitoring
- **WebSocket Support:** Native WebSocket support

**Architecture:**

```
Internet â†’ Route 53 (DNS) â†’ Multiple ALBs (active-active)
                              â”œâ”€ ALB 1 (50% traffic)
                              â””â”€ ALB 2 (50% traffic)

Each ALB:
  â”œâ”€ Target Group: User Service (10 instances)
  â”œâ”€ Target Group: Product Service (20 instances)
  â”œâ”€ Target Group: Order Service (15 instances)
  â””â”€ Target Group: Payment Service (5 instances)
```

#### âœ… Step 2: Path-Based Routing

**ALB Listener Rules:**

```
Rule 1: /api/users/* â†’ User Service Target Group
Rule 2: /api/products/* â†’ Product Service Target Group
Rule 3: /api/orders/* â†’ Order Service Target Group
Rule 4: /api/payments/* â†’ Payment Service Target Group
Rule 5: Default â†’ 404 Not Found
```

**Implementation:**

```
Request: GET /api/users/123
â†’ ALB matches Rule 1
â†’ Routes to User Service Target Group
â†’ Least Connections algorithm selects instance
â†’ Response: User data
```

#### âœ… Step 3: Load Balancing Algorithm

**Choice: Least Connections for All Services**

**Why:**

- **WebSocket Support:** Long-lived connections (Least Connections handles better than Round Robin)
- **Varying Request Times:** Different services have different processing times
- **Adaptive:** Automatically routes to least loaded server

**Configuration:**

```
All Target Groups:
  Algorithm: Least Connections
  Health Check: /health (every 30 seconds)
  Healthy Threshold: 2
  Unhealthy Threshold: 3
```

#### âœ… Step 4: Sticky Sessions for Shopping Cart

**Problem:** Cart stored on server, need session affinity

**Solution: Cookie-Based Sticky Sessions**

**Configuration:**

```
Target Group: Order Service
  Stickiness: Enabled
  Duration: 1800 seconds (30 minutes)
  Cookie Name: AWSALB
```

**Flow:**

```
1. User adds item to cart â†’ Request to Order Service
2. ALB routes to Order Service Instance 1
3. ALB sets cookie: AWSALB=instance1_hash
4. User adds another item â†’ Cookie sent with request
5. ALB reads cookie â†’ Routes to Instance 1 (same server)
6. Cart retrieved from Instance 1
```

**Trade-off:**

- âœ… Maintains session state
- âŒ Uneven load (some instances may be overloaded)
- âŒ Instance failure loses cart (mitigated by session replication)

**Better Alternative: Shared Session Store**

```
Cart stored in Redis (not on server)
â†’ Any instance can handle any request
â†’ No sticky sessions needed
â†’ Survives instance failures
```

#### âœ… Step 5: Health Checks and Failover

**Health Check Configuration:**

```
Path: /health
Protocol: HTTP
Port: 8080
Interval: 30 seconds
Timeout: 5 seconds
Healthy Threshold: 2 consecutive successes
Unhealthy Threshold: 3 consecutive failures
```

**Failover Flow:**

```
1. ALB sends health check to Instance 1
2. Instance 1 responds: 200 OK (healthy)
3. Instance 1 crashes
4. ALB sends health check â†’ Timeout
5. ALB marks Instance 1 as unhealthy (after 3 failures)
6. ALB removes Instance 1 from target group
7. Traffic routes to remaining healthy instances
8. Auto Scaling Group launches new instance
9. New instance passes health checks â†’ Added to target group
```

#### âœ… Step 6: SSL Termination

**Configuration:**

```
ALB Listener:
  Port: 443 (HTTPS)
  Certificate: ACM (AWS Certificate Manager)
  SSL Policy: ELBSecurityPolicy-TLS-1-2-2017-01

Backend:
  Protocol: HTTP (unencrypted between ALB and backend)
  Security: Private VPC (traffic not exposed to internet)
```

**Flow:**

```
Client â†’ ALB (HTTPS, encrypted)
      â†’ ALB decrypts
      â†’ Backend (HTTP, unencrypted, private network)
      â†’ ALB encrypts response
      â†’ Client (HTTPS, encrypted)
```

#### âœ… Step 7: WebSocket Support

**Configuration:**

```
ALB Listener:
  Protocol: HTTPS
  WebSocket: Enabled (default in ALB)

Target Group:
  Protocol: HTTP
  Health Check: HTTP (not WebSocket)
```

**Flow:**

```
1. Client â†’ ALB: WebSocket upgrade request
2. ALB â†’ Backend: WebSocket upgrade request
3. Backend â†’ ALB: WebSocket upgrade response
4. ALB â†’ Client: WebSocket upgrade response
5. Connection established (sticky session maintained)
6. ALB forwards WebSocket frames bidirectionally
```

**Sticky Sessions for WebSocket:**

- ALB maintains connection affinity
- Same client always routes to same instance
- Required for stateful WebSocket connections

#### âœ… Step 8: Scaling Strategy

**Auto Scaling Configuration:**

```
User Service:
  Min: 10 instances
  Max: 50 instances
  Target: 70% CPU utilization
  Scale Up: Add instance when CPU > 70%
  Scale Down: Remove instance when CPU < 30%

Product Service:
  Min: 20 instances
  Max: 100 instances
  Target: 70% CPU utilization
```

**Load Balancer Scaling:**

- ALB automatically scales (managed service)
- No manual configuration needed
- Handles traffic spikes automatically

#### âœ… Complete Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Internet                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
                       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Route 53 (DNS)                              â”‚
â”‚         (Round-robin to ALBs)                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚              â”‚              â”‚
        â–¼              â–¼              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   ALB 1      â”‚ â”‚   ALB 2  â”‚ â”‚   ALB 3      â”‚
â”‚ (33% traffic)â”‚ â”‚(33% trf) â”‚ â”‚ (34% traffic)â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚               â”‚              â”‚
       â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚              â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚      Path-Based Routing Rules      â”‚
    â”‚  /api/users â†’ User Service TG      â”‚
    â”‚  /api/products â†’ Product Service TG â”‚
    â”‚  /api/orders â†’ Order Service TG     â”‚
    â”‚  /api/payments â†’ Payment Service TG â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚      Target Groups                  â”‚
    â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
    â”‚  â”‚ User Service (10-50 inst)    â”‚  â”‚
    â”‚  â”‚ Product Service (20-100 inst) â”‚  â”‚
    â”‚  â”‚ Order Service (15-75 inst)    â”‚  â”‚
    â”‚  â”‚ Payment Service (5-25 inst)   â”‚  â”‚
    â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Request Flow:**

```
1. Client â†’ Route 53: Resolve api.example.com
2. Route 53 â†’ Returns ALB IP (round-robin)
3. Client â†’ ALB: HTTPS request to /api/users/123
4. ALB: SSL termination (decrypts)
5. ALB: Matches routing rule (/api/users â†’ User Service)
6. ALB: Least Connections algorithm selects instance
7. ALB â†’ User Service Instance: HTTP request
8. User Service â†’ ALB: HTTP response
9. ALB: SSL termination (encrypts)
10. ALB â†’ Client: HTTPS response
```

#### âš–ï¸ Trade-offs Summary

| Decision              | What We Gain                      | What We Sacrifice               |
|-----------------------|-----------------------------------|---------------------------------|
| **ALB (Layer 7)**     | Path-based routing, microservices | Higher latency than Layer 4     |
| **Least Connections** | WebSocket support, adaptive load  | Requires connection tracking    |
| **Sticky Sessions**   | Cart state on server              | Uneven load, failure loses cart |
| **SSL Termination**   | Offloads CPU from backend         | Traffic unencrypted in VPC      |
| **Multiple ALBs**     | High availability, no SPOF        | Higher cost, DNS complexity     |

#### âœ… Final Summary

**Load Balancing Strategy:**

- **Type:** AWS Application Load Balancer (Layer 7)
- **Routing:** Path-based routing to microservices
- **Algorithm:** Least Connections (WebSocket support)
- **Sessions:** Cookie-based sticky sessions (30 min)
- **SSL:** Termination at ALB
- **Scaling:** Auto-scaling target groups + managed ALB scaling

**Performance:**

- **Throughput:** 1M requests/sec (3 ALBs Ã— 333k req/sec each)
- **Latency:** <10ms added by load balancer
- **Availability:** 99.99% (multiple ALBs, auto-scaling, health checks)

**Result:**

- âœ… Handles 1M requests/sec
- âœ… Routes to correct service (path-based)
- âœ… Maintains session affinity (sticky sessions)
- âœ… Handles failures (health checks, auto-scaling)
- âœ… Supports WebSocket (ALB native support)

