# 2.6.1 Kubernetes and Docker Deep Dive: Container Orchestration at Scale

## Intuitive Explanation

Imagine you're running a restaurant. Instead of hiring one chef who can only cook one dish at a time, you hire multiple
chefs (containers) who can each cook different dishes simultaneously. But you need a manager (Kubernetes) to:

- Assign orders to available chefs
- Replace chefs who get sick
- Scale up during rush hour (hire more chefs)
- Ensure ingredients are available (storage)
- Coordinate between chefs (networking)

**Docker** is like the standardized kitchen setup that ensures every chef works in the same environment. **Kubernetes**
is the manager that orchestrates hundreds of chefs (containers) across multiple restaurants (servers), ensuring your
restaurant (application) runs smoothly 24/7.

**Key Concepts:**

- **Container:** Isolated environment running an application (like a lightweight VM)
- **Kubernetes:** Orchestrates containers across multiple servers (automated management)
- **Pod:** Smallest deployable unit (one or more containers)
- **Service:** Stable network endpoint to access pods (load balancing)

---

## In-Depth Analysis

### 1. What is Docker?

**Docker** is a platform for developing, shipping, and running applications in containers.

**Container vs Virtual Machine:**

```
Virtual Machine:
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚   Guest OS (Ubuntu)      â”‚  â† Full OS (GBs)
  â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
  â”‚   â”‚   Application   â”‚   â”‚
  â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
  Hypervisor
  Host OS
  Hardware

Container:
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚   Container Runtime      â”‚
  â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
  â”‚   â”‚   Application   â”‚   â”‚  â† Just app + dependencies (MBs)
  â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
  Docker Engine
  Host OS (shared)
  Hardware
```

**Benefits:**

- **Lightweight:** Containers share host OS (smaller than VMs)
- **Fast Startup:** Seconds (vs minutes for VMs)
- **Consistent:** Same environment (dev, staging, production)
- **Isolated:** Containers don't interfere with each other

### 2. Docker Components

#### A. Docker Image

**Definition:** Read-only template for creating containers

**Example:**

```dockerfile
FROM node:18
WORKDIR /app
COPY package.json .
RUN npm install
COPY . .
CMD ["node", "server.js"]
```

**Layers:**

```
Image: my-app:latest
  â”œâ”€ Layer 1: Base image (node:18)
  â”œâ”€ Layer 2: package.json
  â”œâ”€ Layer 3: npm install (dependencies)
  â””â”€ Layer 4: Application code
```

**Benefits:**

- **Layered:** Share layers between images (storage efficient)
- **Immutable:** Image doesn't change (reproducible)
- **Versioned:** Tag images (v1.0, v1.1, latest)

#### B. Docker Container

**Definition:** Running instance of an image

**Lifecycle:**

```
Create â†’ Start â†’ Run â†’ Stop â†’ Remove
```

**Isolation:**

- **Process Isolation:** Each container has its own process tree
- **Network Isolation:** Each container has its own network namespace
- **File System Isolation:** Each container has its own file system
- **Resource Limits:** CPU, memory limits per container

#### C. Docker Compose

**Definition:** Tool for defining and running multi-container applications

**Example:**

```yaml
version: '3'
services:
  web:
    image: nginx
    ports:
      - "80:80"
  db:
    image: postgres
    environment:
      POSTGRES_PASSWORD: secret
```

**Use Case:**

- Local development
- Simple deployments
- Not for production scale

### 3. What is Kubernetes?

**Kubernetes (K8s)** is an open-source container orchestration platform that automates deployment, scaling, and
management of containerized applications.

**Key Problems It Solves:**

- **Service Discovery:** How do containers find each other?
- **Load Balancing:** How to distribute traffic across containers?
- **Scaling:** How to add/remove containers based on load?
- **Health Monitoring:** How to detect and replace failed containers?
- **Rolling Updates:** How to update application without downtime?

### 4. Kubernetes Architecture

#### Master Node (Control Plane)

**Components:**

- **API Server:** Entry point for all operations
- **etcd:** Distributed key-value store (cluster state)
- **Scheduler:** Assigns pods to nodes
- **Controller Manager:** Manages controllers (replicas, endpoints, etc.)

#### Worker Nodes

**Components:**

- **kubelet:** Agent that runs on each node
- **kube-proxy:** Network proxy (load balancing, service discovery)
- **Container Runtime:** Docker, containerd, etc.

**Architecture:**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Kubernetes Cluster                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚         Master Node (Control Plane)          â”‚  â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚  â”‚
â”‚  â”‚  â”‚ API      â”‚  â”‚ etcd     â”‚  â”‚Scheduler â”‚  â”‚  â”‚
â”‚  â”‚  â”‚ Server   â”‚  â”‚ (State)  â”‚  â”‚          â”‚  â”‚  â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”‚
â”‚  â”‚ Worker Node 1â”‚  â”‚ Worker Node 2â”‚              â”‚
â”‚  â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚  â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚              â”‚
â”‚  â”‚ â”‚ kubelet  â”‚ â”‚  â”‚ â”‚ kubelet  â”‚ â”‚              â”‚
â”‚  â”‚ â”‚ kube-proxyâ”‚ â”‚  â”‚ â”‚ kube-proxyâ”‚ â”‚              â”‚
â”‚  â”‚ â”‚ Pods     â”‚ â”‚  â”‚ â”‚ Pods     â”‚ â”‚              â”‚
â”‚  â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚  â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚              â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 5. Kubernetes Core Concepts

#### A. Pod

**Definition:** Smallest deployable unit (one or more containers)

**Characteristics:**

- Containers in pod share network and storage
- Pods are ephemeral (created/destroyed frequently)
- Each pod gets unique IP address

**Example:**

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: web-pod
spec:
  containers:
    - name: nginx
      image: nginx:latest
      ports:
        - containerPort: 80
```

#### B. Deployment

**Definition:** Manages replica set of pods

**Features:**

- **Replicas:** Maintains desired number of pods
- **Rolling Updates:** Updates pods without downtime
- **Rollback:** Revert to previous version

**Example:**

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: web-deployment
spec:
  replicas: 3
  selector:
    matchLabels:
      app: web
  template:
    metadata:
      labels:
        app: web
    spec:
      containers:
        - name: nginx
          image: nginx:1.20
```

#### C. Service

**Definition:** Stable network endpoint to access pods

**Types:**

- **ClusterIP:** Internal service (default)
- **NodePort:** Expose on node port
- **LoadBalancer:** External load balancer
- **ExternalName:** External service alias

**Example:**

```yaml
apiVersion: v1
kind: Service
metadata:
  name: web-service
spec:
  selector:
    app: web
  ports:
    - port: 80
      targetPort: 80
  type: LoadBalancer
```

#### D. ConfigMap and Secrets

**ConfigMap:** Store configuration data

```yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: app-config
data:
  database_url: "postgresql://db:5432"
```

**Secret:** Store sensitive data (encrypted)

```yaml
apiVersion: v1
kind: Secret
metadata:
  name: db-secret
type: Opaque
data:
  password: c2VjcmV0  # base64 encoded
```

### 6. Kubernetes Features

#### A. Auto-Scaling

**Horizontal Pod Autoscaler (HPA):**

```yaml
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: web-hpa
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: web-deployment
  minReplicas: 3
  maxReplicas: 10
  metrics:
    - type: Resource
      resource:
        name: cpu
        target:
          type: Utilization
          averageUtilization: 70
```

**How It Works:**

- Monitors CPU/memory usage
- Scales up when usage > 70%
- Scales down when usage < 30%

#### B. Health Checks

**Liveness Probe:** Is container alive?

```yaml
livenessProbe:
  httpGet:
    path: /health
    port: 8080
  initialDelaySeconds: 30
  periodSeconds: 10
```

**Readiness Probe:** Is container ready?

```yaml
readinessProbe:
  httpGet:
    path: /ready
    port: 8080
  initialDelaySeconds: 5
  periodSeconds: 5
```

#### C. Rolling Updates

**Strategy:**

```
Old Version (v1): 3 pods
  â†“
New Version (v2): 1 pod (new) + 2 pods (old)
  â†“
New Version (v2): 2 pods (new) + 1 pod (old)
  â†“
New Version (v2): 3 pods (all new)
```

**Benefits:**

- Zero downtime
- Automatic rollback on failure
- Gradual traffic shift

### 7. Kubernetes vs. Alternatives

| Feature            | Kubernetes                | Docker Swarm       | Nomad          |
|--------------------|---------------------------|--------------------|----------------|
| **Complexity**     | High                      | Low                | Medium         |
| **Features**       | Extensive                 | Basic              | Moderate       |
| **Ecosystem**      | Largest                   | Medium             | Small          |
| **Learning Curve** | Steep                     | Gentle             | Moderate       |
| **Best For**       | Large scale, complex apps | Simple deployments | Multi-workload |

---

## When to Use Kubernetes

### âœ… Use Kubernetes When:

1. **Microservices:** Multiple services need orchestration
2. **High Scale:** Hundreds of containers
3. **Complex Deployments:** Need rolling updates, auto-scaling
4. **Multi-Cloud:** Deploy across cloud providers
5. **CI/CD Integration:** Automated deployments

### âŒ Don't Use Kubernetes When:

1. **Simple Applications:** Single container app (use Docker Compose)
2. **Small Scale:** Few containers (overhead not worth it)
3. **Limited Resources:** Small team, no DevOps expertise
4. **Monolithic:** Single application (may be overkill)

---

## Real-World Examples

### Google (Kubernetes Creator)

**Use Case:** Orchestrating billions of containers

**Scale:**

- Millions of containers
- Thousands of services
- Global deployment

### Netflix

**Use Case:** Microservices orchestration

**Architecture:**

- Thousands of microservices
- Kubernetes for container orchestration
- Spinnaker for deployments

### Spotify

**Use Case:** Music streaming platform

**Architecture:**

- Microservices architecture
- Kubernetes for orchestration
- Multi-region deployment

---

## Common Anti-Patterns

### âŒ **1. Running Everything in Kubernetes**

**Problem:** Running databases, message queues in Kubernetes

**Why It's Wrong:**

- Stateful services need persistent storage (complex in K8s)
- Managed services (RDS, ElastiCache) are easier
- K8s adds unnecessary complexity

**Solution:** Use Kubernetes for stateless services, managed services for stateful

### âŒ **2. No Resource Limits**

**Problem:** Containers consume unlimited CPU/memory

**Solution:** Set resource limits

```yaml
resources:
  requests:
    cpu: 100m
    memory: 128Mi
  limits:
    cpu: 500m
    memory: 512Mi
```

### âŒ **3. Single Replica**

**Problem:** No redundancy (pod failure = service down)

**Solution:** Always use multiple replicas

```yaml
replicas: 3  # Minimum for high availability
```

---

## Trade-offs Summary

| Aspect          | What You Gain                  | What You Sacrifice                |
|-----------------|--------------------------------|-----------------------------------|
| **Automation**  | Auto-scaling, self-healing     | Complexity, learning curve        |
| **Portability** | Run anywhere (cloud, on-prem)  | Abstraction overhead              |
| **Scalability** | Handle thousands of containers | Resource overhead (control plane) |
| **Flexibility** | Extensive features             | Configuration complexity          |

---

## References

- **Kubernetes Documentation:** [https://kubernetes.io/docs/](https://kubernetes.io/docs/)
- **Docker Documentation:** [https://docs.docker.com/](https://docs.docker.com/)
- **Related Chapters:**
    - [1.2.5 Service Discovery](../../01-principles/1.2.5-service-discovery.md) - Kubernetes service discovery
    - [2.0.4 Load Balancers](../2.0-communication/2.0.4-load-balancers-deep-dive.md) - Kubernetes load balancing

---

## âœï¸ Design Challenge

### Problem

You are deploying a microservices application with 20 services to Kubernetes. The application must:

1. **Handle 1 million requests per second** (distributed across services)
2. **Auto-scale** based on CPU/memory usage
3. **Zero-downtime deployments** (rolling updates)
4. **High availability** (survive node failures)
5. **Service discovery** (services find each other automatically)

**Constraints:**

- Each service: 3-10 instances
- Node capacity: 100 pods per node
- Services communicate via HTTP/gRPC
- Need persistent storage for some services

Design a Kubernetes deployment strategy that:

- Handles traffic scale
- Auto-scales services
- Supports zero-downtime deployments
- Ensures high availability
- Implements service discovery

### Solution

#### ğŸ§© Scenario

- **Services:** 20 microservices
- **Instances:** 3-10 per service (100-200 total pods)
- **Traffic:** 1M requests/sec
- **Requirements:** Auto-scaling, zero-downtime, HA

#### âœ… Step 1: Cluster Architecture

**Choice: Multi-AZ Kubernetes Cluster**

**Configuration:**

```
Cluster: 3 Availability Zones
  â”œâ”€ AZ-1: 10 worker nodes
  â”œâ”€ AZ-2: 10 worker nodes
  â””â”€ AZ-3: 10 worker nodes

Master Nodes: 3 (one per AZ, high availability)
```

**Node Sizing:**

```
Worker Nodes:
  - Instance: m5.2xlarge (8 vCPU, 32 GB RAM)
  - Capacity: 100 pods/node
  - Total Capacity: 30 nodes Ã— 100 = 3,000 pods
```

#### âœ… Step 2: Deployment Strategy

**Deployment Configuration:**

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: user-service
spec:
  replicas: 5
  strategy:
    type: RollingUpdate
    rollingUpdate:
      maxSurge: 2
      maxUnavailable: 1
  selector:
    matchLabels:
      app: user-service
  template:
    metadata:
      labels:
        app: user-service
    spec:
      containers:
        - name: user-service
          image: user-service:v1.0
          resources:
            requests:
              cpu: 100m
              memory: 256Mi
            limits:
              cpu: 1000m
              memory: 1Gi
          livenessProbe:
            httpGet:
              path: /health
              port: 8080
          readinessProbe:
            httpGet:
              path: /ready
              port: 8080
```

**Pod Distribution:**

```
Each service: 5 replicas
Distribution: Spread across AZs
  - AZ-1: 2 pods
  - AZ-2: 2 pods
  - AZ-3: 1 pod
```

#### âœ… Step 3: Auto-Scaling

**Horizontal Pod Autoscaler:**

```yaml
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: user-service-hpa
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: user-service
  minReplicas: 3
  maxReplicas: 10
  metrics:
    - type: Resource
      resource:
        name: cpu
        target:
          type: Utilization
          averageUtilization: 70
    - type: Resource
      resource:
        name: memory
        target:
          type: Utilization
          averageUtilization: 80
```

**Scaling Behavior:**

```
CPU > 70% â†’ Scale up (add pods)
CPU < 30% â†’ Scale down (remove pods)
Memory > 80% â†’ Scale up
```

#### âœ… Step 4: Service Discovery

**Service Configuration:**

```yaml
apiVersion: v1
kind: Service
metadata:
  name: user-service
spec:
  selector:
    app: user-service
  ports:
    - port: 80
      targetPort: 8080
  type: ClusterIP
```

**DNS-Based Discovery:**

```
Service accessible via DNS:
  user-service.default.svc.cluster.local

Services call each other:
  http://user-service/api/users
  â†’ Kubernetes DNS resolves to service IP
  â†’ kube-proxy load balances to pods
```

#### âœ… Step 5: Load Balancing

**kube-proxy Configuration:**

```
Mode: IPVS (better performance than iptables)
Algorithm: Round-robin
Health Checks: Automatic (removes unhealthy pods)
```

**External Load Balancer:**

```yaml
apiVersion: v1
kind: Service
metadata:
  name: api-gateway
spec:
  type: LoadBalancer
  selector:
    app: api-gateway
  ports:
    - port: 80
      targetPort: 8080
```

#### âœ… Step 6: Zero-Downtime Deployments

**Rolling Update Strategy:**

```
Current: user-service:v1.0 (5 pods)
  â†“
Update: user-service:v1.1
  â†“
Step 1: Create 2 new pods (v1.1)
  - Total: 7 pods (5 old + 2 new)
  â†“
Step 2: Remove 1 old pod
  - Total: 6 pods (4 old + 2 new)
  â†“
Step 3: Create 2 new pods
  - Total: 8 pods (4 old + 4 new)
  â†“
Step 4: Remove 2 old pods
  - Total: 6 pods (2 old + 4 new)
  â†“
Step 5: Create 1 new pod, remove 1 old
  - Total: 6 pods (1 old + 5 new)
  â†“
Step 6: Remove last old pod
  - Total: 5 pods (all v1.1)
```

**Result:** Zero downtime (always pods serving traffic)

#### âœ… Step 7: High Availability

**Pod Anti-Affinity:**

```yaml
spec:
  affinity:
    podAntiAffinity:
      preferredDuringSchedulingIgnoredDuringExecution:
        - weight: 100
          podAffinityTerm:
            labelSelector:
              matchExpressions:
                - key: app
                  operator: In
                  values:
                    - user-service
            topologyKey: kubernetes.io/hostname
```

**Effect:**

- Pods spread across nodes
- Node failure affects max 1 pod per service
- Other pods continue serving traffic

#### âœ… Complete Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Internet (1M req/sec)                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚   Load Balancer (ALB)       â”‚
        â”‚   (External)                â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚   Kubernetes Cluster        â”‚
        â”‚   (3 AZs, 30 nodes)        â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚                  â”‚                  â”‚
    â–¼                  â–¼                  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ AZ-1    â”‚      â”‚ AZ-2    â”‚      â”‚ AZ-3    â”‚
â”‚ 10 nodesâ”‚      â”‚ 10 nodesâ”‚      â”‚ 10 nodesâ”‚
â”‚         â”‚      â”‚         â”‚      â”‚         â”‚
â”‚ Servicesâ”‚      â”‚ Servicesâ”‚      â”‚ Servicesâ”‚
â”‚ (pods)  â”‚      â”‚ (pods)  â”‚      â”‚ (pods)  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Service Discovery:**

```
Service A â†’ DNS: service-b â†’ Service B
Service B â†’ DNS: service-c â†’ Service C
â†’ Kubernetes DNS resolves
â†’ kube-proxy load balances
```

#### âš–ï¸ Trade-offs Summary

| Decision                | What We Gain           | What We Sacrifice                 |
|-------------------------|------------------------|-----------------------------------|
| **Multi-AZ Deployment** | High availability      | Higher latency (cross-AZ)         |
| **Auto-Scaling**        | Handles traffic spikes | Resource overhead, complexity     |
| **Rolling Updates**     | Zero downtime          | Slower deployments                |
| **Pod Anti-Affinity**   | Fault tolerance        | May waste resources (spread pods) |

#### âœ… Final Summary

**Kubernetes Deployment Strategy:**

- **Cluster:** 3 AZs, 30 worker nodes, 3 master nodes
- **Deployments:** 20 services, 3-10 replicas each (HPA)
- **Service Discovery:** DNS-based (Kubernetes Services)
- **Load Balancing:** kube-proxy (IPVS mode)
- **High Availability:** Pod anti-affinity, multi-AZ

**Performance:**

- **Throughput:** 1M requests/sec (distributed across services)
- **Scaling:** Auto-scales 3-10 replicas per service
- **Availability:** 99.99% (multi-AZ, pod anti-affinity)
- **Deployments:** Zero downtime (rolling updates)

**Result:**

- âœ… Handles 1M requests/sec
- âœ… Auto-scales based on CPU/memory
- âœ… Zero-downtime deployments
- âœ… High availability (survives node failures)
- âœ… Service discovery (DNS-based)

