# 2.1.13 DynamoDB Deep Dive: AWS's Serverless NoSQL Database

## Intuitive Explanation

Amazon DynamoDB is a **fully managed, serverless NoSQL database** that scales automatically without any operational overhead. Unlike self-hosted databases (MySQL, MongoDB, Cassandra), DynamoDB requires **zero server management** — no provisioning, patching, backups, or scaling decisions. You simply create tables, and AWS handles everything else. It's designed for applications that need **predictable single-digit millisecond latency** at any scale.

- **Fully Managed:** No servers to manage, automatic backups, patching, scaling.
- **Key-Value + Document:** Stores JSON-like documents with primary key access.
- **Predictable Performance:** Single-digit millisecond latency at any scale (millions of requests/sec).
- **Use Cases:** Gaming leaderboards, IoT data, session storage, serverless apps (Lambda), mobile backends.

---

## In-Depth Analysis

### 1. Architecture: Distributed Hash Table

DynamoDB is built on a **distributed hash table** (similar to Cassandra):

```
┌─────────────────────────────────────────────────────┐
│              DynamoDB Architecture                   │
├─────────────────────────────────────────────────────┤
│                                                      │
│  Application                                         │
│      │                                               │
│      ▼                                               │
│  ┌─────────────────────────────────────┐            │
│  │     DynamoDB API (HTTPS)            │            │
│  └─────────────────────────────────────┘            │
│      │                                               │
│      ▼                                               │
│  ┌─────────────────────────────────────┐            │
│  │  Request Router (Partition Key)     │            │
│  │  Hash(partition_key) → Node         │            │
│  └─────────────────────────────────────┘            │
│      │                                               │
│      ▼                                               │
│  ┌─────────┬─────────┬─────────┬─────────┐         │
│  │ Node 1  │ Node 2  │ Node 3  │ Node N  │         │
│  │ (AZ-1)  │ (AZ-2)  │ (AZ-3)  │         │         │
│  └─────────┴─────────┴─────────┴─────────┘         │
│  Each node stores 10GB partition                    │
│  Replicated across 3 Availability Zones             │
└─────────────────────────────────────────────────────┘
```

**Key Concepts:**

| Concept | Explanation |
|---------|-------------|
| **Partition** | 10GB unit of storage (auto-created by DynamoDB) |
| **Partition Key** | Determines which partition stores the data (hash-based) |
| **Replication** | 3 copies across 3 Availability Zones (11 9s durability) |
| **Consistent Hashing** | Distributes data evenly across nodes |

---

### 2. Data Model: Primary Keys

DynamoDB uses two types of primary keys:

#### **2.1 Partition Key (Simple Primary Key)**

**Structure:** Single attribute (partition key).

```json
// Table: Users
// Primary Key: user_id (partition key)

{
  "user_id": "user123",    // Partition key
  "name": "John Doe",
  "email": "john@example.com",
  "age": 30
}
```

**Query Patterns:**

- ✅ **GetItem:** Fetch by partition key (single-digit ms latency).
- ❌ **Query:** Cannot query by other attributes (need Global Secondary Index).
- ❌ **Scan:** Full table scan (slow, expensive).

**Example:**

```python
# GetItem (fast)
response = table.get_item(Key={'user_id': 'user123'})

# Query by email (slow without index)
response = table.scan(
    FilterExpression=Attr('email').eq('john@example.com')
)  # Scans entire table!
```

#### **2.2 Composite Key (Partition Key + Sort Key)**

**Structure:** Two attributes (partition key + sort key).

```json
// Table: Orders
// Primary Key: user_id (partition key) + order_id (sort key)

{
  "user_id": "user123",    // Partition key
  "order_id": "order456",  // Sort key
  "total": 99.99,
  "created_at": "2024-01-15T10:30:00Z"
}
```

**Query Patterns:**

- ✅ **GetItem:** Fetch by partition key + sort key.
- ✅ **Query:** Fetch all items with same partition key (sorted by sort key).
- ✅ **Range Queries:** Query sort key range (e.g., orders between dates).

**Example:**

```python
# Get single order
response = table.get_item(
    Key={'user_id': 'user123', 'order_id': 'order456'}
)

# Query all orders for user
response = table.query(
    KeyConditionExpression=Key('user_id').eq('user123')
)

# Query orders in date range
response = table.query(
    KeyConditionExpression=Key('user_id').eq('user123') &
        Key('order_id').between('2024-01-01', '2024-01-31')
)
```

**Sort Key Use Cases:**

- **Time-series data:** `partition_key = device_id`, `sort_key = timestamp`.
- **Hierarchical data:** `partition_key = user_id`, `sort_key = folder/file`.
- **Versioning:** `partition_key = document_id`, `sort_key = version_number`.

---

### 3. Secondary Indexes

DynamoDB supports two types of secondary indexes:

#### **3.1 Local Secondary Index (LSI)**

**Definition:** Same partition key, different sort key.

```
Primary Key: user_id (partition) + order_id (sort)
LSI: user_id (partition) + created_at (sort)
```

**Limitations:**

- ❌ **Must be created at table creation** (cannot add later).
- ❌ **Limited to 5 LSIs per table**.
- ✅ **Strongly consistent reads** (shares same partition).

**Use Case:** Query same partition key with different sort order.

```python
# Query user's orders sorted by created_at
response = table.query(
    IndexName='created_at-index',
    KeyConditionExpression=Key('user_id').eq('user123'),
    ScanIndexForward=False  # Descending order
)
```

#### **3.2 Global Secondary Index (GSI)**

**Definition:** Different partition key and/or sort key.

```
Primary Key: user_id (partition) + order_id (sort)
GSI: status (partition) + created_at (sort)
```

**Features:**

- ✅ **Can be added anytime** (after table creation).
- ✅ **Up to 20 GSIs per table**.
- ❌ **Eventually consistent** (async replication from base table).
- ⚠️ **Separate throughput** (must provision separately).

**Use Case:** Query by non-primary key attributes.

```python
# Query all "shipped" orders
response = table.query(
    IndexName='status-index',
    KeyConditionExpression=Key('status').eq('shipped')
)
```

**GSI Best Practices:**

- ✅ **Sparse indexes:** GSI only includes items with indexed attribute (saves cost).
- ✅ **Projections:** Include only needed attributes in GSI (reduce storage).
- ❌ **Avoid hot keys:** If one GSI partition key has too many items (e.g., `status = 'active'` for millions of users), causes throttling.

**Hot Key Example:**

```
GSI: status (partition key)

Problem:
- status = 'active' → 10M items (hot partition)
- status = 'inactive' → 100 items (cold partition)

Solution: Add shard suffix
- GSI partition key: status + random(0-9)
- Distribute 'active' items across 10 partitions
```

---

### 4. Capacity Modes: On-Demand vs. Provisioned

#### **4.1 On-Demand Mode**

**Pricing:** Pay per request (no upfront capacity planning).

```
- Read: $0.25 per million requests
- Write: $1.25 per million requests
- Storage: $0.25 per GB/month
```

**Benefits:**

- ✅ **No capacity planning:** Scales automatically to any workload.
- ✅ **No throttling:** (unless you hit AWS account limits).
- ✅ **Ideal for:** Unpredictable traffic, new apps, development.

**Trade-offs:**

- ❌ **Higher cost:** 5-7x more expensive than provisioned (for steady workloads).

#### **4.2 Provisioned Mode**

**Pricing:** Pre-provision Read/Write Capacity Units (RCUs/WCUs).

```
- Read Capacity Unit (RCU): 1 strongly consistent read/sec (4KB)
- Write Capacity Unit (WCU): 1 write/sec (1KB)
- Cost: $0.00013 per RCU/hour, $0.00065 per WCU/hour
```

**Benefits:**

- ✅ **Predictable cost:** Lower cost for steady traffic.
- ✅ **Auto-scaling:** Can enable auto-scaling (min/max RCU/WCU).
- ✅ **Reserved capacity:** Save up to 76% with 1-year commitment.

**Trade-offs:**

- ❌ **Capacity planning:** Must estimate traffic.
- ❌ **Throttling:** If exceed provisioned capacity, requests are rejected (HTTP 400).

**Example:**

```python
# Create table with provisioned capacity
table = dynamodb.create_table(
    TableName='Orders',
    KeySchema=[
        {'AttributeName': 'user_id', 'KeyType': 'HASH'},
        {'AttributeName': 'order_id', 'KeyType': 'RANGE'}
    ],
    AttributeDefinitions=[
        {'AttributeName': 'user_id', 'AttributeType': 'S'},
        {'AttributeName': 'order_id', 'AttributeType': 'S'}
    ],
    ProvisionedThroughput={
        'ReadCapacityUnits': 100,   # 100 reads/sec
        'WriteCapacityUnits': 50    # 50 writes/sec
    }
)
```

**Capacity Calculation:**

```
Example: 1000 reads/sec, 4KB items, strongly consistent
- RCUs needed = (1000 reads/sec) × (4KB / 4KB) = 1000 RCUs

Example: 500 writes/sec, 2KB items
- WCUs needed = (500 writes/sec) × (2KB / 1KB) = 1000 WCUs
```

---

### 5. Consistency Models

DynamoDB offers two read consistency models:

| Model | Latency | Staleness | Use Case |
|-------|---------|-----------|----------|
| **Eventually Consistent** | Faster | May read stale data (< 1s delay) | Default, most reads |
| **Strongly Consistent** | Slower | Always reads latest | Critical reads (inventory, financial) |

**Example:**

```python
# Eventually consistent (default)
response = table.get_item(Key={'user_id': 'user123'})

# Strongly consistent
response = table.get_item(
    Key={'user_id': 'user123'},
    ConsistentRead=True
)
```

**Cost:**

- **Eventually consistent:** 1 RCU = 2 reads/sec (4KB).
- **Strongly consistent:** 1 RCU = 1 read/sec (4KB).

---

### 6. Transactions

DynamoDB supports **ACID transactions** across multiple items:

**Example: Bank Transfer**

```python
from boto3.dynamodb.conditions import Attr

try:
    response = dynamodb.transact_write_items(
        TransactItems=[
            # Deduct from sender (conditional check)
            {
                'Update': {
                    'TableName': 'Accounts',
                    'Key': {'account_id': 'account1'},
                    'UpdateExpression': 'SET balance = balance - :amount',
                    'ExpressionAttributeValues': {':amount': 100, ':zero': 0},
                    'ConditionExpression': 'balance >= :amount'  # Prevent overdraft
                }
            },
            # Add to receiver
            {
                'Update': {
                    'TableName': 'Accounts',
                    'Key': {'account_id': 'account2'},
                    'UpdateExpression': 'SET balance = balance + :amount',
                    'ExpressionAttributeValues': {':amount': 100}
                }
            }
        ]
    )
    print('Transaction successful')
except ClientError as e:
    if e.response['Error']['Code'] == 'TransactionCanceledException':
        print('Transaction failed (insufficient funds)')
```

**Limitations:**

- ❌ **Max 100 items per transaction**.
- ❌ **2x cost:** Transactions consume 2x RCU/WCU.
- ❌ **No cross-region transactions**.

---

### 7. DynamoDB Streams: Change Data Capture

**Streams** capture all changes to a table (like Kafka):

```
┌─────────────────────────────────────────────┐
│           DynamoDB Table                     │
├─────────────────────────────────────────────┤
│  Insert, Update, Delete                     │
└──────────────┬──────────────────────────────┘
               │
               ▼
┌─────────────────────────────────────────────┐
│         DynamoDB Stream                      │
│  - Captures all changes (24-hour retention) │
│  - Ordered by shard                         │
└──────────────┬──────────────────────────────┘
               │
               ▼
┌─────────────────────────────────────────────┐
│         Lambda Function                      │
│  - Process each change event                │
│  - Trigger workflows, update caches         │
└─────────────────────────────────────────────┘
```

**Use Cases:**

- ✅ **Real-time analytics:** Process events in Lambda.
- ✅ **Cache invalidation:** Clear Redis cache when DynamoDB updates.
- ✅ **Replication:** Sync to Elasticsearch, S3, or another database.
- ✅ **Audit logs:** Track all changes.

**Example:**

```python
# Enable stream on table
table = dynamodb.create_table(
    TableName='Orders',
    StreamSpecification={
        'StreamEnabled': True,
        'StreamViewType': 'NEW_AND_OLD_IMAGES'  # Include old and new values
    }
)

# Lambda function processes stream
def lambda_handler(event, context):
    for record in event['Records']:
        if record['eventName'] == 'INSERT':
            new_item = record['dynamodb']['NewImage']
            print(f'New order: {new_item}')
```

---

### 8. Global Tables: Multi-Region Replication

**Global Tables** provide **multi-active replication** across regions:

```
┌────────────────────────────────────────────┐
│         DynamoDB Global Tables             │
├────────────────────────────────────────────┤
│  US-East-1 (Primary)                       │
│    ┌──────────────┐                        │
│    │  Orders Table│◄──────────┐            │
│    └──────┬───────┘           │            │
│           │ Async replication │            │
│           ▼                   │            │
│  EU-West-1 (Replica)          │            │
│    ┌──────────────┐           │            │
│    │  Orders Table│───────────┘            │
│    └──────────────┘                        │
│  - Writes to either region replicate       │
│  - Eventual consistency (< 1 second)       │
│  - Conflict resolution: Last-writer-wins   │
└────────────────────────────────────────────┘
```

**Benefits:**

- ✅ **Low latency:** Users read from nearest region.
- ✅ **Disaster recovery:** If one region fails, use another.
- ✅ **Active-active:** Can write to any region.

**Trade-offs:**

- ❌ **Eventual consistency:** Writes to different regions may conflict.
- ❌ **Cost:** 2x storage (replicated to both regions).

---

### 9. Best Practices

#### **9.1 Data Modeling**

**Single-Table Design:**

Instead of multiple tables (like SQL), DynamoDB best practice is **one table for entire application**:

```
Table: AppData
Partition Key: PK
Sort Key: SK

// User
PK = "USER#user123"
SK = "PROFILE"
name = "John Doe"

// User's Orders
PK = "USER#user123"
SK = "ORDER#order456"
total = 99.99

// Product
PK = "PRODUCT#prod789"
SK = "METADATA"
name = "Laptop"
```

**Benefits:**

- ✅ **Atomic transactions:** All related data in one table.
- ✅ **Query efficiency:** Fetch user + orders in one query.
- ✅ **Cost:** Fewer tables = lower cost.

**Trade-offs:**

- ❌ **Complex:** Requires careful design (overloaded keys).
- ❌ **Learning curve:** Different from SQL mindset.

#### **9.2 Avoid Hot Partitions**

**Problem:** Uneven access patterns cause throttling.

```
// Bad: All users write to same partition key
PK = "GLOBAL"  // All writes go to one partition (hot)

// Good: Distribute writes across partitions
PK = "USER#user123"  // Each user = separate partition
```

**Throttling Example:**

```
Table with 1000 WCUs across 10 partitions:
- Each partition gets 100 WCUs (1000 / 10)
- If one partition receives 200 writes/sec → throttled!
```

**Solution: Write Sharding**

```python
# Add random suffix to distribute writes
import random
pk = f"STATUS#active#{random.randint(0, 9)}"
```

#### **9.3 Use Batch Operations**

```python
# ❌ Bad: 100 individual writes
for item in items:
    table.put_item(Item=item)  # 100 network calls

# ✅ Good: Batch write (up to 25 items)
with table.batch_writer() as batch:
    for item in items:
        batch.put_item(Item=item)  # Batched
```

**Batch Limits:**

- **BatchGetItem:** 100 items, 16MB.
- **BatchWriteItem:** 25 items, 16MB.

#### **9.4 Optimize Costs**

| Strategy | Savings |
|----------|---------|
| **Use on-demand for dev/test** | Pay only for actual usage |
| **Switch to provisioned for production** | 5-7x cheaper for steady traffic |
| **Enable auto-scaling** | Avoid over-provisioning |
| **Delete old data (TTL)** | Free automatic deletion |
| **Use sparse GSIs** | Only index needed items |
| **Reserved capacity** | Save 76% with 1-year commitment |

**Time-To-Live (TTL):**

```python
# Auto-delete expired items (free)
table.update_item(
    Key={'user_id': 'user123'},
    UpdateExpression='SET expiry_time = :ttl',
    ExpressionAttributeValues={
        ':ttl': int(time.time()) + 86400  # Expire in 24 hours
    }
)
```

---

### 10. When to Use DynamoDB

#### **✅ Use DynamoDB When:**

1. **Serverless applications** — Perfect for AWS Lambda (no server management).
2. **Predictable latency** — Need single-digit millisecond response times.
3. **High scale** — Millions of requests/sec.
4. **Key-value access** — Simple queries by primary key.
5. **AWS ecosystem** — Already using AWS (seamless integration with Lambda, S3, etc.).
6. **Variable traffic** — On-demand mode handles spiky workloads.

#### **❌ Don't Use DynamoDB When:**

1. **Complex queries** — Joins, aggregations (use PostgreSQL/MySQL).
2. **OLAP** — Ad-hoc analytics (use Redshift, Athena).
3. **Cost-sensitive** — Small workloads (<1M requests/month) cheaper on RDS.
4. **Relational data** — Heavy foreign keys and joins (use RDBMS).
5. **Multi-region strong consistency** — Not supported (eventual only).

---

### 11. Real-World Examples

| Company | Use Case | Why DynamoDB? |
|---------|----------|---------------|
| **Netflix** | User viewing history | Handles millions of writes/sec |
| **Amazon** | Shopping cart | Low latency, serverless |
| **Lyft** | Trip metadata | Global tables for multi-region |
| **Snapchat** | User stories | High write throughput |
| **Duolingo** | User progress | Serverless, automatic scaling |

---

### 12. DynamoDB vs. Other Databases

| Feature | DynamoDB | Cassandra | MongoDB | PostgreSQL |
|---------|----------|-----------|---------|------------|
| **Management** | Fully managed (serverless) | Self-hosted | Self-hosted or Atlas | Self-hosted or RDS |
| **Latency** | Single-digit ms | Single-digit ms | 10-50ms | 10-100ms |
| **Scaling** | Automatic | Manual (add nodes) | Manual (sharding) | Vertical |
| **Consistency** | Tunable (eventual/strong) | Tunable | Eventual | Strong (ACID) |
| **Queries** | Key-value only | CQL (limited) | Rich query language | Full SQL |
| **Cost** | Pay per request | Infrastructure | Infrastructure | Infrastructure |

---

### 13. Common Anti-Patterns

#### ❌ **1. Treating DynamoDB Like SQL**

**Problem:**

```python
# Scanning entire table (slow, expensive)
response = table.scan(
    FilterExpression=Attr('status').eq('active')
)
```

**Solution:**

```python
# Use GSI with status as partition key
response = table.query(
    IndexName='status-index',
    KeyConditionExpression=Key('status').eq('active')
)
```

#### ❌ **2. Not Using Batch Operations**

**Problem:** Individual writes are slow and expensive.

**Solution:** Use `batch_write_item`.

#### ❌ **3. Hot Partitions**

**Problem:** All writes go to one partition.

**Solution:** Use sharding or better partition key design.

---

### 14. Trade-offs Summary

| What You Gain | What You Sacrifice |
|---------------|-------------------|
| ✅ Zero server management (serverless) | ❌ No complex queries (no joins, aggregations) |
| ✅ Predictable single-digit ms latency | ❌ Eventual consistency (in global tables) |
| ✅ Automatic scaling (millions of req/sec) | ❌ Higher cost (for small workloads) |
| ✅ Built-in backups, replication | ❌ Vendor lock-in (AWS only) |
| ✅ Seamless AWS integration | ❌ Learning curve (single-table design) |

---

### 15. References

- **DynamoDB Documentation:** [https://docs.aws.amazon.com/dynamodb/](https://docs.aws.amazon.com/dynamodb/)
- **DynamoDB Best Practices:** [https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/best-practices.html](https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/best-practices.html)
- **AWS re:Invent - DynamoDB Deep Dive:** [https://www.youtube.com/results?search_query=dynamodb+reinvent](https://www.youtube.com/results?search_query=dynamodb+reinvent)
- **Related Chapters:**
  - [2.1.2 NoSQL Deep Dive](./2.1.2-no-sql-deep-dive.md) — NoSQL principles
  - [2.1.8 Cassandra Deep Dive](./2.1.8-cassandra-deep-dive.md) — Similar architecture
  - [2.2.2 Consistent Hashing](./2.2.2-consistent-hashing.md) — How DynamoDB distributes data
  - [2.1.4 Database Scaling](./2.1.4-database-scaling.md) — Horizontal scaling patterns


---

## ✏️ Design Challenge

### Problem

You're designing a **serverless e-commerce shopping cart** using AWS Lambda + DynamoDB. Requirements:

1. **High availability:** 99.99% uptime (no database maintenance windows)
2. **Elastic scaling:** Handle Black Friday traffic spikes (100x normal load)
3. **Access pattern:** Add/remove items, get cart by user_id
4. **TTL:** Auto-delete abandoned carts after 30 days
5. **Cost optimization:** Minimize cost during low-traffic periods

**Question:** What partition key and sort key would you use? Would you use on-demand or provisioned capacity? How would you handle hot partitions (popular products)?

### Solution

#### 🧩 Scenario

- **System:** Serverless shopping cart (AWS Lambda + DynamoDB)
- **Traffic:** 1,000 requests/sec normal, 100,000 requests/sec during Black Friday
- **Access pattern:** Add item, remove item, get cart, checkout
- **Data:** user_id, product_id, quantity, added_at
- **TTL:** Delete carts older than 30 days

#### ✅ Goal

- Handle 100x traffic spikes without pre-provisioning
- Sub-10ms latency for cart operations
- Auto-scale without manual intervention
- Cost-effective (pay only for actual usage)
- Auto-delete abandoned carts

#### ⚙️ Solution: On-Demand Capacity + Composite Key

**Table Design:**

```python
Table: shopping_carts
Partition Key: user_id (STRING)
Sort Key: product_id (STRING)

Attributes:
- user_id: "user_12345"
- product_id: "prod_67890"
- quantity: 2
- price: 29.99
- added_at: 1706181600 (Unix timestamp)
- ttl: 1708773600 (Unix timestamp, 30 days from now)
```

**Why This Design?**

| Decision | Rationale |
|----------|-----------|
| **Partition key: user_id** | Each user's cart is isolated (single-partition queries) |
| **Sort key: product_id** | Multiple items per cart, efficient add/remove/update |
| **On-demand capacity** | Auto-scales to 100K req/sec without pre-provisioning |
| **TTL on ttl attribute** | Auto-deletes abandoned carts (no cleanup jobs) |
| **No GSI needed** | Access pattern is always by user_id |

**DynamoDB Operations:**

```python
import boto3
from datetime import datetime, timedelta

dynamodb = boto3.resource('dynamodb')
table = dynamodb.Table('shopping_carts')

# 1. Add item to cart (or update quantity)
def add_to_cart(user_id, product_id, quantity, price):
    ttl = int((datetime.now() + timedelta(days=30)).timestamp())
    
    response = table.put_item(
        Item={
            'user_id': user_id,
            'product_id': product_id,
            'quantity': quantity,
            'price': price,
            'added_at': int(datetime.now().timestamp()),
            'ttl': ttl
        }
    )
    return response

# 2. Get entire cart (single-partition query)
def get_cart(user_id):
    response = table.query(
        KeyConditionExpression='user_id = :user_id',
        ExpressionAttributeValues={
            ':user_id': user_id
        }
    )
    return response['Items']

# 3. Remove item from cart
def remove_from_cart(user_id, product_id):
    response = table.delete_item(
        Key={
            'user_id': user_id,
            'product_id': product_id
        }
    )
    return response

# 4. Update quantity
def update_quantity(user_id, product_id, new_quantity):
    response = table.update_item(
        Key={
            'user_id': user_id,
            'product_id': product_id
        },
        UpdateExpression='SET quantity = :qty',
        ExpressionAttributeValues={
            ':qty': new_quantity
        }
    )
    return response

# 5. Checkout (get cart + delete)
def checkout(user_id):
    # Get cart
    cart_items = get_cart(user_id)
    total = sum(item['price'] * item['quantity'] for item in cart_items)
    
    # Delete cart (batch delete)
    with table.batch_writer() as batch:
        for item in cart_items:
            batch.delete_item(
                Key={
                    'user_id': user_id,
                    'product_id': item['product_id']
                }
            )
    
    return {'total': total, 'items': cart_items}
```

#### ⚠️ Handling Hot Partitions (Popular Products)

**Problem:** What if millions of users add the same product (e.g., iPhone) to their carts?

**Analysis:**
- Partition key = user_id (NOT product_id)
- Each user's cart is a separate partition
- No hot partition issue! (writes distributed across millions of partitions)

**Why This Works:**
```
User A adds iPhone: Writes to partition "user_A"
User B adds iPhone: Writes to partition "user_B"
User C adds iPhone: Writes to partition "user_C"
→ No hotspot! Each write goes to different partition.
```

**If We Had Used product_id as Partition Key (BAD):**
```
User A adds iPhone: Writes to partition "iphone_15"
User B adds iPhone: Writes to partition "iphone_15"  ← HOT PARTITION!
User C adds iPhone: Writes to partition "iphone_15"  ← Throttling!
```

#### 🧠 Cost Optimization: On-Demand vs. Provisioned

**On-Demand (Recommended for This Use Case):**

**Pricing:**
- Reads: $0.25 per million requests
- Writes: $1.25 per million requests

**Cost Calculation:**

Normal traffic: 1,000 req/sec × 86,400 sec/day = 86M requests/day
- Reads (80%): 69M × $0.25/M = $17.25/day
- Writes (20%): 17M × $1.25/M = $21.25/day
- Total: ~$38.50/day = ~$1,155/month

Black Friday: 100,000 req/sec × 86,400 sec/day = 8.6B requests/day
- Total: ~$3,850/day (but only for 1-2 days)

**With Provisioned Capacity:**
- Must provision for peak (100K req/sec) year-round
- Cost: ~$50,000/month (wasted 99% of the time)

**Decision: On-Demand**
- Pay only for actual usage
- No over-provisioning
- Auto-scales instantly

#### ✅ Final Answer

| Aspect | Decision | Reason |
|--------|----------|--------|
| **Table Design** | Partition key: user_id, Sort key: product_id | Single-partition queries, no hot partitions |
| **Capacity Mode** | **On-Demand** | Auto-scales to 100K req/sec, cost-effective for spiky traffic |
| **TTL** | 30 days | Auto-delete abandoned carts (no Lambda cleanup jobs) |
| **GSI** | None needed | Access pattern is always by user_id |
| **Latency** | <5ms (p99) | DynamoDB single-digit ms latency |
| **Cost** | $1,155/month (normal), $3,850/day (Black Friday) | 50x cheaper than provisioned for spiky workloads |
| **Hot Partition** | No risk | user_id ensures even distribution |
| **Trade-off** | Eventual consistency (if using replicas) | Gain: High availability, auto-scaling |

**Performance Metrics:**
- **Add to cart:** 2-5ms (PutItem)
- **Get cart:** 5-10ms (Query, single partition)
- **Checkout:** 10-20ms (Batch delete)
- **Throughput:** Unlimited (on-demand auto-scales)
- **Availability:** 99.99% (DynamoDB SLA)

**Why NOT Other Databases:**
- ❌ PostgreSQL: Can't handle 100K req/sec, needs provisioning
- ❌ Redis: No persistence (data loss on restart), expensive for large data
- ❌ MongoDB: Requires sharding, ops overhead, not serverless

**Key Takeaway:** DynamoDB on-demand + proper partition key = perfect for serverless, spiky workloads with zero ops.

