# 2.1.9 Elasticsearch Deep Dive: The Search and Analytics Engine

## Intuitive Explanation

Elasticsearch is a **distributed search and analytics engine** built on top of Apache Lucene. Think of it as a specialized database designed for one thing: **finding needles in haystacks**. While traditional databases use indexes to find exact matches, Elasticsearch uses **inverted indexes** to find text across millions of documents in milliseconds â€” even with typos, synonyms, and fuzzy matching.

- **Full-Text Search:** Tokenizes text, handles typos, ranks relevance (unlike SQL's `LIKE '%keyword%'`).
- **Real-Time Analytics:** Aggregations (histograms, averages, percentiles) on massive datasets.
- **Distributed by Design:** Shards data across nodes, scales horizontally like Cassandra.
- **Use Cases:** Search engines (e-commerce, documentation), log analysis (ELK stack), metrics dashboards (Kibana).

**The Classic Pattern:** Use PostgreSQL/MySQL for transactional data + Elasticsearch for search.

---

## In-Depth Analysis

### 1. Architecture: Clusters, Nodes, Shards

Elasticsearch organizes data in a **distributed cluster**:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Elasticsearch Cluster                     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚   Node 1    â”‚  â”‚   Node 2    â”‚  â”‚   Node 3    â”‚  â”‚
â”‚  â”‚  (Master    â”‚  â”‚  (Data      â”‚  â”‚  (Data      â”‚  â”‚
â”‚  â”‚   Eligible) â”‚  â”‚   Node)     â”‚  â”‚   Node)     â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚         â”‚                 â”‚                 â”‚         â”‚
â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â”‚
â”‚                                                        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚            Index: "products"                   â”‚   â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤   â”‚
â”‚  â”‚  Primary Shards:     P0   P1   P2            â”‚   â”‚
â”‚  â”‚  Replica Shards:     R0   R1   R2            â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Key Concepts:**

| Concept | Explanation |
|---------|-------------|
| **Cluster** | Collection of one or more nodes (servers) |
| **Node** | Single Elasticsearch instance (one JVM process) |
| **Index** | Collection of documents (like a database table) |
| **Shard** | Subset of an index (distributed across nodes) |
| **Primary Shard** | Original shard (handles writes) |
| **Replica Shard** | Copy of primary shard (handles reads, provides HA) |
| **Document** | JSON object (like a row in SQL) |

**Node Roles:**

| Role | Purpose | Example |
|------|---------|---------|
| **Master** | Cluster coordination (create/delete index, track nodes) | 1-3 dedicated master nodes |
| **Data** | Store data, execute queries | Majority of nodes |
| **Ingest** | Pre-process documents before indexing (ETL) | Optional |
| **Coordinating** | Route requests, merge results | All nodes by default |

---

### 2. Inverted Index: The Secret Sauce

**Traditional B-Tree Index (SQL):**

```
Index on `name`:
Alice   â†’ Row 1
Bob     â†’ Row 2
Charlie â†’ Row 3

Query: WHERE name = 'Alice'  â† Fast (O(log n))
Query: WHERE name LIKE '%lice%'  â† Slow (full scan)
```

**Inverted Index (Elasticsearch):**

```
Document 1: "Elasticsearch is powerful"
Document 2: "Elasticsearch and Kibana"
Document 3: "Powerful search engine"

Inverted Index:
Term            â†’ Documents
elasticsearch   â†’ [1, 2]
powerful        â†’ [1, 3]
kibana          â†’ [2]
search          â†’ [3]
engine          â†’ [3]

Query: "powerful search"
- Lookup "powerful" â†’ [1, 3]
- Lookup "search" â†’ [3]
- Intersect â†’ [3]  (Document 3 matches both)
```

**Why Inverted Index is Fast:**

- âœ… **$\text{O}(1)$ lookup** for each term (hash table).
- âœ… **Handles partial matches** ("power" finds "powerful").
- âœ… **Relevance scoring** (TF-IDF, BM25).
- âœ… **Supports fuzzy matching** (typos, synonyms).

**Tokenization Example:**

```
Text: "Elasticsearch is the best search engine!"

After Tokenization (English analyzer):
- Lowercase: "elasticsearch is the best search engine"
- Remove stop words: "elasticsearch best search engine"
- Stem words: "elasticsearch best search engin"

Inverted index stores: ["elasticsearch", "best", "search", "engin"]
```

---

### 3. Data Model: Documents and Mappings

#### **3.1 Document Structure**

Documents are **JSON objects** stored in an index:

```json
{
  "_index": "products",
  "_id": "12345",
  "_source": {
    "name": "Wireless Mouse",
    "description": "Ergonomic wireless mouse with USB receiver",
    "price": 29.99,
    "category": "Electronics",
    "tags": ["wireless", "mouse", "ergonomic"],
    "created_at": "2024-01-15T10:30:00Z"
  }
}
```

#### **3.2 Mappings (Schema)**

Mappings define how fields are indexed:

```json
{
  "mappings": {
    "properties": {
      "name": {
        "type": "text",
        "analyzer": "english"
      },
      "description": {
        "type": "text",
        "analyzer": "english"
      },
      "price": {
        "type": "float"
      },
      "category": {
        "type": "keyword"
      },
      "tags": {
        "type": "keyword"
      },
      "created_at": {
        "type": "date"
      }
    }
  }
}
```

**Field Types:**

| Type | Use Case | Indexed? | Example |
|------|----------|----------|---------|
| **text** | Full-text search (analyzed, tokenized) | Yes (inverted index) | Product descriptions, blog posts |
| **keyword** | Exact match, filtering, aggregations | Yes (not analyzed) | Email addresses, status codes, tags |
| **long/integer** | Numeric values | Yes | User IDs, counts |
| **float/double** | Decimals | Yes | Prices, ratings |
| **date** | Timestamps | Yes | `created_at`, `published_at` |
| **boolean** | True/false | Yes | `is_active`, `is_deleted` |
| **geo_point** | Latitude/longitude | Yes (geospatial queries) | Restaurant locations |

**Critical Distinction: `text` vs. `keyword`**

| Field Type | Analyzed? | Use Case | Query |
|------------|-----------|----------|-------|
| **text** | Yes (tokenized) | Search "wireless mouse" in description | `match`, `match_phrase` |
| **keyword** | No (exact match) | Filter by exact category "Electronics" | `term`, `terms` |

**Example:**

```json
// Document
{
  "email": "user@example.com"
}

// Mapping 1: text (BAD for emails)
"email": { "type": "text" }
Search: "user@example.com" â†’ Tokenized as ["user", "example", "com"] (finds all emails)

// Mapping 2: keyword (GOOD for emails)
"email": { "type": "keyword" }
Search: "user@example.com" â†’ Exact match only
```

---

### 4. Search Queries: From Simple to Advanced

#### **4.1 Match Query (Full-Text Search)**

```json
GET /products/_search
{
  "query": {
    "match": {
      "description": "wireless mouse"
    }
  }
}
```

**How It Works:**

1. Tokenizes "wireless mouse" â†’ `["wireless", "mouse"]`.
2. Finds documents containing either term.
3. Ranks by relevance (BM25 algorithm).

#### **4.2 Match Phrase Query (Exact Phrase)**

```json
GET /products/_search
{
  "query": {
    "match_phrase": {
      "description": "wireless mouse"
    }
  }
}
```

**Difference:** Finds "wireless mouse" as an exact phrase (terms must be adjacent).

#### **4.3 Bool Query (Complex Logic)**

```json
GET /products/_search
{
  "query": {
    "bool": {
      "must": [
        { "match": { "description": "wireless" } }
      ],
      "filter": [
        { "range": { "price": { "gte": 20, "lte": 50 } } },
        { "term": { "category": "Electronics" } }
      ],
      "should": [
        { "match": { "tags": "ergonomic" } }
      ],
      "must_not": [
        { "term": { "is_deleted": true } }
      ]
    }
  }
}
```

**Bool Query Clauses:**

| Clause | Behavior | Affects Score? |
|--------|----------|----------------|
| **must** | Document MUST match (AND) | Yes |
| **filter** | Document MUST match (AND) | No (faster) |
| **should** | Document MAY match (OR, boosts score) | Yes |
| **must_not** | Document MUST NOT match (NOT) | No |

**Performance Tip:** Use `filter` instead of `must` for non-scoring queries (e.g., price range).

#### **4.4 Fuzzy Query (Typo Tolerance)**

```json
GET /products/_search
{
  "query": {
    "fuzzy": {
      "name": {
        "value": "mous",
        "fuzziness": "AUTO"
      }
    }
  }
}
```

**Fuzziness:** Allows 1-2 character edits (Levenshtein distance).

- "mous" finds "mouse".
- "wireles" finds "wireless".

#### **4.5 Multi-Match Query (Search Across Fields)**

```json
GET /products/_search
{
  "query": {
    "multi_match": {
      "query": "wireless mouse",
      "fields": ["name^2", "description"],
      "type": "best_fields"
    }
  }
}
```

**Field Boosting:** `name^2` means matches in `name` are 2x more important.

---

### 5. Aggregations: Real-Time Analytics

Aggregations are like SQL `GROUP BY` on steroids:

#### **5.1 Metric Aggregations (Averages, Sums)**

```json
GET /products/_search
{
  "size": 0,
  "aggs": {
    "avg_price": {
      "avg": { "field": "price" }
    },
    "max_price": {
      "max": { "field": "price" }
    }
  }
}
```

**Result:**

```json
{
  "aggregations": {
    "avg_price": { "value": 35.5 },
    "max_price": { "value": 99.99 }
  }
}
```

#### **5.2 Bucket Aggregations (Grouping)**

```json
GET /products/_search
{
  "size": 0,
  "aggs": {
    "products_by_category": {
      "terms": { "field": "category" }
    }
  }
}
```

**Result:**

```json
{
  "aggregations": {
    "products_by_category": {
      "buckets": [
        { "key": "Electronics", "doc_count": 120 },
        { "key": "Clothing", "doc_count": 85 },
        { "key": "Books", "doc_count": 60 }
      ]
    }
  }
}
```

#### **5.3 Nested Aggregations (Drill-Down)**

```json
GET /products/_search
{
  "size": 0,
  "aggs": {
    "categories": {
      "terms": { "field": "category" },
      "aggs": {
        "avg_price_per_category": {
          "avg": { "field": "price" }
        }
      }
    }
  }
}
```

**Result:**

```json
{
  "aggregations": {
    "categories": {
      "buckets": [
        {
          "key": "Electronics",
          "doc_count": 120,
          "avg_price_per_category": { "value": 45.2 }
        },
        {
          "key": "Clothing",
          "doc_count": 85,
          "avg_price_per_category": { "value": 25.8 }
        }
      ]
    }
  }
}
```

**Use Cases:**

- E-commerce faceted search (filters sidebar).
- Metrics dashboards (Kibana visualizations).
- Log analytics (error rate by service).

---

### 6. Elasticsearch with Relational Databases

**The Typical Pattern:**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Application Flow                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                    â”‚
â”‚  Write Path:                                       â”‚
â”‚    User creates product                           â”‚
â”‚      â”‚                                             â”‚
â”‚      â”œâ”€> PostgreSQL (source of truth)             â”‚
â”‚      â”‚      - ACID guarantees                     â”‚
â”‚      â”‚      - Relationships (foreign keys)        â”‚
â”‚      â”‚                                             â”‚
â”‚      â””â”€> Elasticsearch (async sync)               â”‚
â”‚             - Full-text search                    â”‚
â”‚             - Fast lookups                        â”‚
â”‚                                                    â”‚
â”‚  Read Path (Search):                              â”‚
â”‚    User searches "wireless mouse"                 â”‚
â”‚      â”‚                                             â”‚
â”‚      â””â”€> Elasticsearch                            â”‚
â”‚             - Returns product IDs                 â”‚
â”‚             - Sorted by relevance                 â”‚
â”‚      â”‚                                             â”‚
â”‚      â””â”€> PostgreSQL (optional)                    â”‚
â”‚             - Fetch full product details          â”‚
â”‚                                                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### **6.1 Sync Strategies**

**Strategy 1: Application-Level Dual Writes**

```
function createProduct(product):
  // 1. Write to PostgreSQL (source of truth)
  db.insert(product)
  
  // 2. Write to Elasticsearch (search index)
  elasticsearch.index(product)
```

**Pros:**

- âœ… Simple to implement.
- âœ… Real-time indexing.

**Cons:**

- âŒ Not atomic (ES might fail after DB succeeds).
- âŒ Tight coupling (application must manage sync).

**Strategy 2: Change Data Capture (CDC)**

```
PostgreSQL
    â”‚
    â”œâ”€> WAL (Write-Ahead Log)
    â”‚
    â–¼
Debezium (CDC)
    â”‚
    â–¼
Kafka
    â”‚
    â–¼
Elasticsearch Sink Connector
    â”‚
    â–¼
Elasticsearch
```

**Pros:**

- âœ… Decoupled (DB doesn't know about ES).
- âœ… Guaranteed sync (replays WAL on failure).
- âœ… Can backfill historical data.

**Cons:**

- âŒ More complex infrastructure.
- âŒ Slight delay (eventual consistency).

**Tools:**

- **Debezium:** Open-source CDC for PostgreSQL, MySQL, MongoDB.
- **Kafka Connect:** Elasticsearch sink connector.
- **AWS DMS:** Managed CDC service (AWS only).

**Strategy 3: Periodic Batch Sync**

```
Cron Job (every 5 minutes):
  - Fetch updated records from PostgreSQL (WHERE updated_at > last_sync_time)
  - Bulk insert into Elasticsearch
```

**Pros:**

- âœ… Simple to implement.

**Cons:**

- âŒ Stale data (5-minute delay).
- âŒ Not suitable for real-time search.

#### **6.2 Storing Data in Elasticsearch**

**Two Approaches:**

| Approach | Storage | Use Case |
|----------|---------|----------|
| **IDs Only** | ES stores only IDs + searchable fields | Fetch full data from DB after search |
| **Full Denormalization** | ES stores entire document | Return results directly (no DB lookup) |

**Example: IDs Only**

```json
// Elasticsearch document
{
  "_id": "12345",
  "_source": {
    "name": "Wireless Mouse",
    "description": "Ergonomic mouse",
    "price": 29.99,
    "category": "Electronics"
  }
}

// Application flow
1. Search ES: "wireless mouse" â†’ Returns [12345, 67890]
2. Fetch from DB: SELECT * FROM products WHERE id IN (12345, 67890)
```

**Example: Full Denormalization**

```json
// Elasticsearch document (includes all fields)
{
  "_id": "12345",
  "_source": {
    "name": "Wireless Mouse",
    "description": "Ergonomic mouse",
    "price": 29.99,
    "category": "Electronics",
    "brand": "Logitech",
    "stock": 50,
    "reviews": [
      { "rating": 5, "comment": "Great mouse!" }
    ]
  }
}

// Application flow
1. Search ES: "wireless mouse" â†’ Returns full documents
2. No DB lookup needed
```

**Trade-offs:**

| Aspect | IDs Only | Full Denormalization |
|--------|----------|----------------------|
| **Storage** | Low | High (duplicate data) |
| **Latency** | Higher (extra DB lookup) | Lower (single query) |
| **Consistency** | High (DB is source of truth) | Lower (ES might be stale) |
| **Complexity** | Simple | Moderate (keep ES in sync) |

---

### 7. Scaling and Performance

#### **7.1 Sharding Strategy**

**Default:** Elasticsearch auto-shards indices.

**Sharding Rules:**

| Shard Count | Use Case | Example |
|-------------|----------|---------|
| **1-3 shards** | Small index (< 10GB) | Dev environments |
| **5-10 shards** | Medium index (10GB - 100GB) | Most production apps |
| **20+ shards** | Large index (> 100GB) | Logs, time-series data |

**Formula:**

```
Shard Size = Total Index Size / Number of Shards
Ideal Shard Size: 20-50GB
```

**Example:**

```
Index size: 200GB
Target shard size: 40GB
Number of shards: 200GB / 40GB = 5 shards
```

**Over-Sharding Problem:**

- âŒ Too many shards (e.g., 100 shards for 1GB data) â†’ overhead (each shard = Lucene index).
- âœ… Rule: Use fewer, larger shards (20-50GB per shard).

#### **7.2 Replica Shards (High Availability)**

```
Index: "products" (5 primary shards, 1 replica)

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Node 1: P0, R1, R2                         â”‚
â”‚  Node 2: P1, R3, R4                         â”‚
â”‚  Node 3: P2, R0, P3                         â”‚
â”‚  Node 4: P4, R0, R3                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

P = Primary shard
R = Replica shard
```

**Benefits:**

- âœ… **High availability:** If Node 1 dies, R0 on Node 4 is promoted to primary.
- âœ… **Read scaling:** Replicas handle search queries (distribute load).

**Replica Count:**

- **0 replicas:** No HA (single point of failure).
- **1 replica:** Standard (HA for one node failure).
- **2 replicas:** High HA (tolerates two node failures).

#### **7.3 Index Lifecycle Management (ILM)**

For time-series data (logs, metrics), use **ILM** to manage storage:

```
Phase 1: Hot (< 7 days)
- Store on SSD, 5 shards, 1 replica
- High write/query throughput

Phase 2: Warm (7-30 days)
- Move to cheaper storage, merge to 1 shard
- Read-only, slower queries OK

Phase 3: Cold (30-90 days)
- Move to object storage (S3)
- Searchable snapshots (rare access)

Phase 4: Delete (> 90 days)
- Delete index
```

**Example Policy:**

```json
PUT _ilm/policy/logs_policy
{
  "policy": {
    "phases": {
      "hot": {
        "actions": {
          "rollover": {
            "max_size": "50GB",
            "max_age": "7d"
          }
        }
      },
      "warm": {
        "min_age": "7d",
        "actions": {
          "shrink": { "number_of_shards": 1 },
          "forcemerge": { "max_num_segments": 1 }
        }
      },
      "delete": {
        "min_age": "90d",
        "actions": { "delete": {} }
      }
    }
  }
}
```

---

### 8. Monitoring and Observability

#### **8.1 Key Metrics**

| Metric | What to Monitor | Threshold |
|--------|-----------------|-----------|
| **Cluster health** | Green/Yellow/Red | Should be green |
| **Indexing rate** | Docs/sec | Varies by use case |
| **Search latency** | p99 latency | < 200ms |
| **CPU usage** | JVM heap usage | < 75% |
| **Disk usage** | Free disk space | > 15% free |
| **Rejected queries** | Thread pool rejections | Should be 0 |

**Cluster Health:**

- **Green:** All primary + replica shards are active.
- **Yellow:** All primary shards active, but some replicas missing.
- **Red:** Some primary shards are missing (data loss risk).

#### **8.2 Tools**

- **Kibana:** Built-in monitoring (Monitoring tab).
- **Elastic APM:** Application performance monitoring.
- **Prometheus + Elasticsearch Exporter:** Metrics collection.
- **Grafana:** Dashboards.

**API Monitoring:**

```bash
# Cluster health
GET /_cluster/health

# Node stats
GET /_nodes/stats

# Index stats
GET /products/_stats
```

---

### 9. When to Use Elasticsearch

#### **âœ… Use Elasticsearch When:**

1. **Full-text search** â€” E-commerce product search, documentation, blogs.
2. **Typo tolerance** â€” "wireles mose" should find "wireless mouse".
3. **Faceted search** â€” Filters sidebar (category, price range, brand).
4. **Real-time analytics** â€” Dashboards (ELK stack, metrics, logs).
5. **Log aggregation** â€” Centralized logging (Logstash â†’ ES â†’ Kibana).
6. **Geospatial search** â€” "Find restaurants within 5km".
7. **Autocomplete** â€” Search-as-you-type (suggestions).

#### **âŒ Don't Use Elasticsearch When:**

1. **Transactional data** â€” Use PostgreSQL/MySQL (ACID guarantees).
2. **Primary database** â€” ES is NOT a source of truth (eventual consistency).
3. **Exact match queries** â€” SQL `WHERE id = ?` is faster.
4. **Small dataset (< 1GB)** â€” PostgreSQL FTS is simpler.
5. **Complex joins** â€” ES doesn't support joins (denormalize instead).
6. **Strict consistency** â€” ES is eventually consistent (near real-time, ~1s delay).

---

### 10. Real-World Examples

| Company | Use Case | Why Elasticsearch? |
|---------|----------|-------------------|
| **Wikipedia** | Site search | Full-text search across millions of articles |
| **GitHub** | Code search | Search code across 200M+ repositories |
| **Uber** | Logs, metrics | ELK stack for debugging (millions of logs/sec) |
| **Netflix** | Search, recommendations | Product search, content discovery |
| **Stack Overflow** | Q&A search | Full-text search with typo tolerance |
| **Shopify** | Product search | E-commerce search with filters |

---

### 11. Common Anti-Patterns

#### âŒ **1. Using Elasticsearch as Primary Database**

**Problem:** No ACID guarantees, eventual consistency.

**Solution:** Use PostgreSQL/MySQL as source of truth, sync to ES.

#### âŒ **2. Not Using `keyword` for Filters**

**Problem:** Filtering on `text` field is slow (tokenized).

**Solution:**

```json
// Bad
"category": { "type": "text" }

// Good
"category": { "type": "keyword" }
```

#### âŒ **3. Too Many Shards**

**Problem:** 100 shards for 1GB data = overhead.

**Solution:** Use 20-50GB per shard.

#### âŒ **4. Not Using Replicas in Production**

**Problem:** Single node failure = data loss.

**Solution:** Always use at least 1 replica.

#### âŒ **5. Running Heavy Aggregations on Hot Data**

**Problem:** Aggregations on real-time data can overload cluster.

**Solution:** Use separate indices for search vs. analytics.

---

### 12. Trade-offs Summary

| What You Gain | What You Sacrifice |
|---------------|-------------------|
| âœ… Lightning-fast full-text search | âŒ Not a primary database (eventual consistency) |
| âœ… Typo tolerance, fuzzy matching | âŒ More ops overhead (JVM tuning, monitoring) |
| âœ… Real-time analytics (aggregations) | âŒ Storage overhead (inverted indexes) |
| âœ… Horizontal scalability | âŒ Complex queries (no joins) |
| âœ… Rich query DSL | âŒ Must sync with primary DB (dual writes or CDC) |

---

### 13. References

- **Elasticsearch Documentation:** [https://www.elastic.co/guide/](https://www.elastic.co/guide/)
- **Elasticsearch: The Definitive Guide (Book):** By Clinton Gormley & Zachary Tong
- **Debezium (CDC):** [https://debezium.io/](https://debezium.io/)
- **Related Chapters:**
  - [2.1.7 PostgreSQL Deep Dive](./2.1.7-postgresql-deep-dive.md) â€” PostgreSQL full-text search
  - [2.1.1 RDBMS Deep Dive](./2.1.1-rdbms-deep-dive.md) â€” When to use SQL vs. ES
  - [2.3.2 Kafka Deep Dive](./2.3.2-kafka-deep-dive.md) â€” CDC pipelines
  - [2.1.4 Database Scaling](./2.1.4-database-scaling.md) â€” Horizontal scaling patterns


---

## âœï¸ Design Challenge

### Problem

You're building a **multi-tenant SaaS product search platform** serving 1000+ e-commerce clients. Each client has their own product catalog (1K-1M products). Requirements:

1. **Search:** Full-text search with typo tolerance, synonyms, and relevance tuning per client
2. **Faceted filters:** Dynamic filters (brand, category, price range) with counts
3. **Data isolation:** Each client's data must be logically isolated
4. **Real-time updates:** Products indexed within 2 seconds of creation
5. **Scale:** 100M total products, 50K search queries/sec

**Question:** How would you design the Elasticsearch index structure (single index vs. index-per-tenant), and how would you sync data from PostgreSQL while maintaining ACID guarantees for inventory?

### Solution

#### ğŸ§© Scenario

- **System:** Multi-tenant e-commerce search platform
- **Tenants:** 1,000 clients (varies from small shops to large retailers)
- **Scale:** 100M products total, 50K searches/sec
- **Data source:** PostgreSQL (source of truth for products + inventory)
- **Requirements:** Typo tolerance, facets, real-time sync, data isolation

#### âœ… Goal

- Efficient search across tenants
- Data isolation (Client A can't see Client B's products)
- Real-time sync from PostgreSQL (< 2 second delay)
- Strong consistency for inventory (prevent overselling)
- Cost-effective index structure

#### âš™ï¸ Solution: Single Index with tenant_id Filter (Recommended)

**Index Design Decision:**

| Approach | Pros | Cons | Recommendation |
|----------|------|------|----------------|
| **Single index with tenant_id** | Lower overhead, easier management | Slight query overhead (filter by tenant_id) | âœ… **Recommended for most cases** |
| **Index per tenant** | Perfect isolation, custom settings | High overhead (1000 indices), complex ops | Only for large tenants (>1M products) |
| **Hybrid** | Balance isolation and overhead | Complex routing logic | Use if 10+ tenants have >1M products |

**Recommended Mapping:**

```json
{
  "mappings": {
    "properties": {
      "tenant_id": { "type": "keyword" },
      "product_id": { "type": "keyword" },
      "name": {
        "type": "text",
        "analyzer": "english",
        "fields": {
          "keyword": { "type": "keyword" }
        }
      },
      "description": {
        "type": "text",
        "analyzer": "english"
      },
      "category": { "type": "keyword" },
      "brand": { "type": "keyword" },
      "price": { "type": "float" },
      "tags": { "type": "keyword" },
      "created_at": { "type": "date" }
    }
  }
}
```

**Search Query with Multi-Tenancy:**

```json
POST /products/_search
{
  "query": {
    "bool": {
      "must": [
        { "term": { "tenant_id": "client_123" } },
        { "multi_match": {
            "query": "wireles mous",
            "fields": ["name^2", "description"],
            "fuzziness": "AUTO"
          }
        }
      ],
      "filter": [
        { "range": { "price": { "gte": 20, "lte": 50 } } }
      ]
    }
  },
  "aggs": {
    "brands": {
      "terms": { "field": "brand", "size": 10 }
    },
    "categories": {
      "terms": { "field": "category", "size": 10 }
    }
  }
}
```

#### âš ï¸ Data Sync Strategy: PostgreSQL â†’ Elasticsearch

**Architecture:**

```
PostgreSQL (Source of Truth)
    â”‚
    â”œâ”€> Write to DB (ACID transaction)
    â”‚
    â–¼
Debezium (CDC - Change Data Capture)
    â”‚
    â”œâ”€> Captures WAL changes
    â”‚
    â–¼
Kafka (Event Stream)
    â”‚
    â”œâ”€> Topic: product-changes
    â”‚
    â–¼
Kafka Connect Elasticsearch Sink
    â”‚
    â”œâ”€> Bulk writes to Elasticsearch
    â”‚
    â–¼
Elasticsearch (Search Index)
```

**Critical: Inventory Consistency**

**Problem:** Elasticsearch is eventually consistent (1-2 second delay). What if user buys product that's out of stock?

**Solution: Two-Phase Check**

```python
# Phase 1: Search in Elasticsearch (fast)
search_results = es.search(
    index="products",
    body={"query": {"match": {"name": "wireless mouse"}}}
)
product_ids = [hit['_source']['product_id'] for hit in search_results['hits']['hits']]

# Phase 2: Check inventory in PostgreSQL (ACID)
# At checkout time, ALWAYS verify stock in PostgreSQL
def checkout(product_id, quantity):
    with db.transaction():
        # ACID transaction ensures no overselling
        product = db.query(
            "SELECT stock FROM inventory WHERE product_id = %s FOR UPDATE",
            (product_id,)
        )
        
        if product.stock >= quantity:
            db.execute(
                "UPDATE inventory SET stock = stock - %s WHERE product_id = %s",
                (quantity, product_id)
            )
            return {"success": True}
        else:
            return {"success": False, "error": "Out of stock"}
```

**Key Principle:** 
- **Search:** Elasticsearch (eventual consistency OK for discovery)
- **Inventory:** PostgreSQL (ACID guarantees at checkout)

#### ğŸ§  Handling Large Tenants (Hybrid Approach)

**Problem:** If one tenant has 10M products (e.g., Amazon), single index becomes slow.

**Solution: Shard Large Tenants to Separate Indices**

```python
def get_index_name(tenant_id, tenant_size):
    if tenant_size > 1_000_000:
        # Large tenant: dedicated index
        return f"products_{tenant_id}"
    else:
        # Small/medium tenant: shared index
        return "products_shared"

# Routing logic
def search_products(tenant_id, query):
    index = get_index_name(tenant_id, get_tenant_size(tenant_id))
    
    if index.startswith("products_"):
        # Dedicated index: no tenant_id filter needed
        body = {"query": {"match": {"name": query}}}
    else:
        # Shared index: must filter by tenant_id
        body = {
            "query": {
                "bool": {
                    "must": [
                        {"term": {"tenant_id": tenant_id}},
                        {"match": {"name": query}}
                    ]
                }
            }
        }
    
    return es.search(index=index, body=body)
```

#### âœ… Final Answer

| Aspect | Decision | Reason |
|--------|----------|--------|
| **Index Structure** | **Single index with tenant_id filter** | Lower overhead, easier ops (for 99% of tenants) |
| **Large Tenants** | Dedicated indices for tenants >1M products | Avoids performance degradation |
| **Data Sync** | **Debezium CDC â†’ Kafka â†’ Elasticsearch** | Reliable, decoupled, handles backpressure |
| **Sync Delay** | 1-2 seconds (acceptable for search) | Trade-off: eventual consistency for search speed |
| **Inventory Consistency** | **Always check PostgreSQL at checkout** | ACID guarantees prevent overselling |
| **Search Performance** | <50ms p99 (with proper sharding) | Elasticsearch strength |
| **Cost** | $2,000/month (5-node cluster, reserved instances) | vs. $10,000/month for 1000 separate indices |

**Trade-offs Accepted:**
- âœ… **Eventual consistency for search** (1-2s delay) â†’ Gain: Decoupled architecture, Elasticsearch performance
- âœ… **Extra query filter** (tenant_id) â†’ Gain: Simpler ops, lower cost
- âœ… **Two-phase check** (ES search + PG inventory) â†’ Gain: No overselling, ACID guarantees

**When to Reconsider:**
- If most tenants have >1M products â†’ Use index-per-tenant
- If sync delay >5 seconds â†’ Optimize Kafka pipeline (increase partitions, tune batching)
- If search becomes bottleneck â†’ Add more Elasticsearch nodes (horizontal scaling)

