# 2.4.5 ELK Stack & Logging Deep Dive: Centralized Log Management

## Intuitive Explanation

Imagine a hospital with 100 doctors, each keeping their own patient notes. When a patient has a complex issue spanning
multiple doctors, finding all relevant notes is nearly impossible.

**ELK Stack** is like a centralized medical records system:

- **Logstash:** Collects notes from all doctors (log collection)
- **Elasticsearch:** Stores and indexes all notes (searchable database)
- **Kibana:** Provides a search interface to find notes quickly (visualization)

**In distributed systems:**

- **ELK Stack:** Centralized log aggregation and analysis
- **Goal:** Collect, store, and search logs from all services
- **Benefit:** Troubleshoot issues across services, track user journeys, audit trails

---

## In-Depth Analysis

### 1. What is the ELK Stack?

**ELK Stack** is a collection of three open-source tools:

- **Elasticsearch:** Search and analytics engine
- **Logstash:** Log processing pipeline
- **Kibana:** Visualization and dashboarding

**Architecture:**

```
Applications â†’ Logstash â†’ Elasticsearch â†’ Kibana
              (Collect)   (Store)        (Visualize)
```

**Modern Alternative:**

- **Beats:** Lightweight data shippers (replaces Logstash for collection)
- **ELK â†’ Elastic Stack:** Elasticsearch + Logstash/Beats + Kibana

### 2. Elasticsearch for Logging

**Why Elasticsearch for Logs:**

- **Full-Text Search:** Search across all log messages
- **Structured Search:** Query by fields (timestamp, level, service)
- **Scalability:** Handles billions of log entries
- **Real-Time:** Index logs in near real-time

**Log Indexing:**

```
Log Entry:
  {
    "timestamp": "2024-01-15T10:30:00Z",
    "level": "ERROR",
    "service": "user-service",
    "message": "Database connection failed",
    "trace_id": "abc-123"
  }

Elasticsearch:
  - Indexes all fields
  - Makes searchable
  - Stores in time-based indices
```

**Index Management:**

```
Time-Based Indices:
  - logs-2024-01-15
  - logs-2024-01-16
  - logs-2024-01-17

Benefits:
  - Easy retention (delete old indices)
  - Better performance (smaller indices)
  - Index lifecycle management
```

### 3. Logstash: Log Processing Pipeline

**Logstash Pipeline:**

```
Input â†’ Filter â†’ Output

Input: Collect logs (files, syslog, Kafka, etc.)
Filter: Parse, transform, enrich logs
Output: Send to Elasticsearch, S3, etc.
```

**Input Plugins:**

```
File Input:
  - Read log files
  - Tail files (follow new lines)
  - Handle log rotation

Syslog Input:
  - Receive syslog messages
  - UDP/TCP support

Kafka Input:
  - Consume from Kafka topics
  - High throughput
```

**Filter Plugins:**

```
Grok (Pattern Matching):
  - Parse unstructured logs
  - Extract fields from log messages
  
Example:
  Input: "2024-01-15 10:30:00 ERROR Database connection failed"
  Grok: %{TIMESTAMP:timestamp} %{LOGLEVEL:level} %{GREEDYDATA:message}
  Output: {timestamp: "2024-01-15 10:30:00", level: "ERROR", message: "Database connection failed"}

JSON Filter:
  - Parse JSON logs
  - Extract nested fields

Date Filter:
  - Parse timestamps
  - Normalize time zones
```

**Output Plugins:**

```
Elasticsearch Output:
  - Send to Elasticsearch
  - Bulk indexing
  - Retry on failure

S3 Output:
  - Archive logs to S3
  - Long-term storage
```

### 4. Beats: Lightweight Data Shippers

**Beats vs. Logstash:**

```
Beats:
  - Lightweight (single-purpose)
  - Low resource usage
  - Push to Logstash or Elasticsearch

Logstash:
  - Heavyweight (full pipeline)
  - High resource usage
  - More processing capabilities
```

**Beat Types:**

```
Filebeat:
  - Ship log files
  - Tail files, handle rotation
  - Send to Logstash or Elasticsearch

Metricbeat:
  - Ship system metrics
  - CPU, memory, disk, network

Packetbeat:
  - Ship network packets
  - Protocol analysis

Winlogbeat:
  - Ship Windows event logs
```

**Architecture:**

```
Applications â†’ Filebeat â†’ Logstash â†’ Elasticsearch
              (Collect)  (Process)  (Store)
```

### 5. Kibana: Log Visualization

**Kibana Features:**

- **Discover:** Search and explore logs
- **Visualize:** Create charts and graphs
- **Dashboards:** Combine visualizations
- **Dev Tools:** Query Elasticsearch directly

**Discover (Log Search):**

```
Search Interface:
  - Free-text search
  - Field filters
  - Time range selection
  - Export results

Example Queries:
  - level:ERROR AND service:user-service
  - message:"connection failed"
  - trace_id:abc-123
```

**Visualizations:**

```
Chart Types:
  - Line charts (log volume over time)
  - Pie charts (error distribution)
  - Tables (top errors, services)
  - Maps (geographic distribution)
```

**Dashboards:**

```
Dashboard Components:
  - Log volume over time
  - Error rate by service
  - Top error messages
  - Service health status
```

### 6. Log Collection Patterns

#### A. Push Pattern

**How It Works:**

```
Application â†’ Logstash/Elasticsearch: Push logs directly
```

**Benefits:**

- Simple (application sends logs)
- Real-time (immediate indexing)

**Trade-offs:**

- Application dependency (if log system down, app affected)
- Network overhead (each app connects)

#### B. Pull Pattern

**How It Works:**

```
Filebeat â†’ Log Files: Pulls logs from files
Filebeat â†’ Logstash/Elasticsearch: Pushes to central system
```

**Benefits:**

- Decoupled (app writes to file, Filebeat reads)
- Resilient (if central system down, logs buffered)

**Trade-offs:**

- File I/O overhead
- Disk space (logs stored locally)

#### C. Message Queue Pattern

**How It Works:**

```
Application â†’ Kafka: Publishes logs
Logstash â†’ Kafka: Consumes logs
Logstash â†’ Elasticsearch: Indexes logs
```

**Benefits:**

- Decoupling (Kafka buffer)
- High throughput
- Durability (logs persisted in Kafka)

**Trade-offs:**

- Additional infrastructure (Kafka)
- Complexity

### 7. Log Parsing and Enrichment

#### A. Structured Logging

**JSON Logs:**

```json
{
  "timestamp": "2024-01-15T10:30:00Z",
  "level": "ERROR",
  "service": "user-service",
  "trace_id": "abc-123",
  "user_id": "user-456",
  "message": "Database connection failed",
  "error": {
    "type": "ConnectionException",
    "message": "Connection timeout"
  }
}
```

**Benefits:**

- Easy parsing (no Grok needed)
- Rich context (structured fields)
- Better searchability

#### B. Unstructured Log Parsing

**Grok Patterns:**

```
Apache Log:
  192.0.2.1 - - [15/Jan/2024:10:30:00 +0000] "GET /api/users HTTP/1.1" 200 1234

Grok Pattern:
  %{IP:client_ip} - - \[%{HTTPDATE:timestamp}\] "%{WORD:method} %{URIPATH:path} HTTP/%{NUMBER:http_version}" %{NUMBER:status_code} %{NUMBER:response_size}
```

**Extracted Fields:**

```json
{
  "client_ip": "192.0.2.1",
  "timestamp": "15/Jan/2024:10:30:00 +0000",
  "method": "GET",
  "path": "/api/users",
  "status_code": 200,
  "response_size": 1234
}
```

#### C. Log Enrichment

**Add Context:**

```
Original Log:
  {message: "Database connection failed"}

Enriched Log:
  {
    "message": "Database connection failed",
    "service": "user-service",
    "environment": "production",
    "region": "us-east-1",
    "host": "server-123",
    "trace_id": "abc-123"
  }
```

**Enrichment Sources:**

- Service metadata
- Infrastructure tags
- Distributed tracing (trace_id)
- User context

### 8. Log Retention and Archival

#### A. Index Lifecycle Management (ILM)

**Lifecycle Phases:**

```
Hot Phase (0-7 days):
  - Active indexing
  - Fast storage (SSD)
  - High performance

Warm Phase (7-30 days):
  - Read-only
  - Slower storage (HDD)
  - Lower cost

Cold Phase (30-90 days):
  - Rarely accessed
  - Very slow storage
  - Archive storage

Delete Phase (>90 days):
  - Delete old indices
  - Free storage
```

**ILM Policy:**

```json
{
  "policy": {
    "phases": {
      "hot": {
        "actions": {
          "rollover": {
            "max_size": "50GB",
            "max_age": "7d"
          }
        }
      },
      "warm": {
        "min_age": "7d",
        "actions": {
          "allocate": {
            "number_of_replicas": 1
          }
        }
      },
      "cold": {
        "min_age": "30d",
        "actions": {
          "allocate": {
            "number_of_replicas": 0
          }
        }
      },
      "delete": {
        "min_age": "90d"
      }
    }
  }
}
```

#### B. Log Archival

**S3 Archival:**

```
Old Logs â†’ S3:
  - Compressed (gzip)
  - Long-term storage
  - Cost-effective

Restore:
  - Re-index from S3 if needed
  - On-demand access
```

### 9. Alternative Logging Solutions

#### A. Loki (Grafana Labs)

**Architecture:**

```
Applications â†’ Promtail â†’ Loki â†’ Grafana
              (Collect)  (Store) (Visualize)
```

**Features:**

- **Label-Based Indexing:** Index by labels, not content
- **Object Storage:** S3, GCS backend
- **Grafana Integration:** Native Grafana support
- **Lower Cost:** More efficient than Elasticsearch

**Use Cases:**

- Prometheus + Grafana stack
- Cost-sensitive deployments
- Kubernetes-native

#### B. Splunk

**Features:**

- **Enterprise Logging:** Commercial solution
- **Advanced Analytics:** Machine learning, anomaly detection
- **Security:** SIEM capabilities
- **High Cost:** Expensive at scale

**Use Cases:**

- Enterprise deployments
- Security monitoring
- Compliance requirements

#### C. Datadog Logs

**Features:**

- **Managed Service:** Fully managed
- **Integration:** Metrics, traces, logs unified
- **APM:** Application performance monitoring
- **Cost:** Pay per GB ingested

**Use Cases:**

- Managed solution preferred
- Unified observability
- Cloud-native applications

### 10. Log Analysis Patterns

#### A. Error Tracking

**Pattern:**

```
1. Filter: level:ERROR
2. Group by: service, error_type
3. Count: Error frequency
4. Alert: If error rate > threshold
```

**Use Cases:**

- Monitor error rates
- Track error trends
- Alert on spikes

#### B. User Journey Tracking

**Pattern:**

```
1. Filter: trace_id:abc-123
2. Sort: timestamp
3. View: Complete request flow across services
```

**Use Cases:**

- Debug user issues
- Track request flow
- Performance analysis

#### C. Security Monitoring

**Pattern:**

```
1. Filter: status_code:401 OR status_code:403
2. Group by: client_ip, user_id
3. Alert: If suspicious pattern detected
```

**Use Cases:**

- Detect attacks
- Track failed logins
- Audit access

---

## When to Use ELK Stack

### âœ… Use ELK Stack When:

1. **Centralized Logging:** Need to aggregate logs from multiple services
2. **Full-Text Search:** Need to search across log messages
3. **Structured Analysis:** Need to query by fields
4. **Real-Time Monitoring:** Need to monitor logs in real-time
5. **Long-Term Storage:** Need to retain logs for compliance
6. **Open Source:** Prefer open-source solution

### âŒ Don't Use ELK Stack When:

1. **Simple Logging:** Single service, basic needs (use file logging)
2. **Cost Sensitive:** High log volume, cost matters (use Loki)
3. **Managed Preferred:** Want fully managed (use Datadog, Splunk)
4. **Metrics Only:** Only need metrics, not logs (use Prometheus)
5. **Low Volume:** <1GB logs/day (overhead not worth it)

---

## Real-World Examples

### Netflix (ELK Stack)

**Use Case:** Centralized logging for microservices

**Scale:**

- Thousands of microservices
- Petabytes of logs
- Real-time analysis
- Security monitoring

### Uber (ELK Stack)

**Use Case:** Log aggregation and analysis

**Scale:**

- Millions of requests per day
- Multi-region deployment
- Real-time alerting
- Incident investigation

### GitHub (ELK Stack)

**Use Case:** Application and infrastructure logs

**Scale:**

- Billions of events per day
- Full-text search
- Security monitoring
- Compliance auditing

---

## ELK Stack vs. Other Solutions

| Solution            | Best For                      | Cost               | Complexity | Features                    |
|---------------------|-------------------------------|--------------------|------------|-----------------------------|
| **ELK Stack**       | Open-source, full-featured    | Free (self-hosted) | High       | Full-text search, analytics |
| **Loki**            | Cost-sensitive, Grafana stack | Free               | Medium     | Label-based, efficient      |
| **Splunk**          | Enterprise, security          | Very High          | Medium     | Advanced analytics, SIEM    |
| **Datadog**         | Managed, unified              | High               | Low        | Metrics + logs + traces     |
| **CloudWatch Logs** | AWS-native                    | Medium             | Low        | AWS integration             |

---

## Common Anti-Patterns

### âŒ **1. Indexing Everything**

**Problem:** Indexing all logs, including debug logs

**Solution:** Filter logs before indexing

```
âŒ Bad:
Index all logs (including DEBUG)
â†’ High storage cost, slow queries

âœ… Good:
Filter: Only index INFO, WARN, ERROR
â†’ Lower storage, faster queries
```

### âŒ **2. No Log Retention Policy**

**Problem:** Logs accumulate forever

**Solution:** Implement ILM policy

```
âŒ Bad:
Logs stored forever
â†’ Storage costs grow indefinitely

âœ… Good:
ILM Policy: Delete after 90 days
â†’ Controlled storage costs
```

### âŒ **3. Unstructured Logs**

**Problem:** Plain text logs, hard to query

**Solution:** Use structured logging (JSON)

```
âŒ Bad:
"2024-01-15 10:30:00 ERROR Database connection failed"
â†’ Hard to query, parse, filter

âœ… Good:
{"timestamp":"2024-01-15T10:30:00Z","level":"ERROR","message":"Database connection failed","service":"user-service"}
â†’ Easy to query, filter, analyze
```

---

## Trade-offs Summary

| Aspect                  | What You Gain                       | What You Sacrifice                        |
|-------------------------|-------------------------------------|-------------------------------------------|
| **Centralized Logging** | Single source of truth, easy search | Network overhead, single point of failure |
| **Full-Text Search**    | Powerful search capabilities        | Higher storage cost                       |
| **Real-Time Indexing**  | Immediate log availability          | Higher resource usage                     |
| **Long Retention**      | Compliance, historical analysis     | High storage costs                        |
| **Open Source**         | Free, customizable                  | Operational overhead                      |

---

## References

- **Elasticsearch Documentation:
  ** [https://www.elastic.co/guide/en/elasticsearch/reference/current/index.html](https://www.elastic.co/guide/en/elasticsearch/reference/current/index.html)
- **Logstash Documentation:
  ** [https://www.elastic.co/guide/en/logstash/current/index.html](https://www.elastic.co/guide/en/logstash/current/index.html)
- **Kibana Documentation:
  ** [https://www.elastic.co/guide/en/kibana/current/index.html](https://www.elastic.co/guide/en/kibana/current/index.html)
- **Loki Documentation:** [https://grafana.com/docs/loki/latest/](https://grafana.com/docs/loki/latest/)
- **Related Chapters:**
    - [2.4.2 Observability](./2.4.2-observability.md) - High-level logging concepts
    - [2.1.13 Elasticsearch Deep Dive](../2.1-databases/2.1.13-elasticsearch-deep-dive.md) - Elasticsearch deep dive

---

## âœï¸ Design Challenge

### Problem

You are designing a centralized logging system for a microservices platform with 50 services that must:

1. **Collect logs** from 50 services (10,000 service instances)
2. **Store logs** for 90 days (compliance requirement)
3. **Search logs** efficiently (full-text and structured queries)
4. **Handle 100M log entries per day** (high volume)
5. **Real-time indexing** (<30 seconds from log to searchable)
6. **Support correlation** (trace requests across services)

**Constraints:**

- Services run in Kubernetes
- Logs in JSON format (structured)
- Need to search by trace_id, service, level, timestamp
- Cost-sensitive (prefer open-source)

Design an ELK Stack strategy that:

- Handles log collection at scale
- Stores logs efficiently
- Enables fast search
- Supports real-time indexing
- Enables log correlation
- Optimizes costs

### Solution

#### ğŸ§© Scenario

- **Services:** 50 microservices
- **Instances:** 10,000 total (200 per service)
- **Log Entries:** 100M per day = 1,157 entries/second
- **Retention:** 90 days
- **Log Size:** ~500 bytes per entry (JSON)

**Calculations:**

- **Daily Log Volume:** 100M Ã— 500 bytes = 50 GB/day
- **90-Day Storage:** 50 GB Ã— 90 = 4.5 TB (raw)
- **With Replication:** 4.5 TB Ã— 2 (replicas) = 9 TB
- **With Compression:** ~2 TB (Elasticsearch compression)

#### âœ… Step 1: Architecture Choice

**Choice: Filebeat + Logstash + Elasticsearch + Kibana**

**Why:**

- **Filebeat:** Lightweight, Kubernetes-native
- **Logstash:** Rich processing capabilities
- **Elasticsearch:** Full-text search, scalability
- **Kibana:** Visualization and dashboards
- **Open Source:** Cost-effective

**Architecture:**

```
Kubernetes Pods â†’ Filebeat (sidecar) â†’ Kafka â†’ Logstash â†’ Elasticsearch â†’ Kibana
```

#### âœ… Step 2: Log Collection

**Filebeat as Sidecar:**

```
Kubernetes Pod:
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚ Service Containerâ”‚
  â”‚ (writes logs)   â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚ Filebeat        â”‚
  â”‚ (sidecar)       â”‚
  â”‚ - Tails log fileâ”‚
  â”‚ - Sends to Kafkaâ”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Filebeat Configuration:**

```yaml
filebeat.inputs:
  - type: log
    paths:
      - /var/log/app/*.log
    json.keys_under_root: true
    json.add_error_key: true
    fields:
      service: ${SERVICE_NAME}
      environment: production
      region: us-east-1
    fields_under_root: true

output.kafka:
  hosts: [ "kafka:9092" ]
  topic: "logs"
  partition.round_robin:
    reachable_only: false
```

**Benefits:**

- **Decoupled:** Service writes to file, Filebeat reads
- **Resilient:** Kafka buffer (if Elasticsearch down, logs buffered)
- **Scalable:** One Filebeat per pod (horizontal scaling)

#### âœ… Step 3: Kafka Buffer

**Kafka Configuration:**

```
Topic: logs
  - Partitions: 20 (for parallelism)
  - Replication: 3 (high availability)
  - Retention: 7 days (buffer for processing delays)

Throughput:
  - 1,157 entries/second
  - 20 partitions = ~58 entries/second per partition
  - Handles easily
```

**Benefits:**

- **Decoupling:** Logstash and Elasticsearch can be down
- **Durability:** Logs persisted in Kafka
- **Backpressure:** Handles traffic spikes

#### âœ… Step 4: Logstash Processing

**Logstash Pipeline:**

```
Input (Kafka):
  - Consume from Kafka topic
  - 20 consumers (one per partition)

Filter:
  - Parse JSON (already structured)
  - Add metadata (host, region, environment)
  - Enrich with service info
  - Normalize timestamps

Output (Elasticsearch):
  - Bulk indexing
  - Retry on failure
  - Index template management
```

**Logstash Configuration:**

```ruby
input {
  kafka {
    bootstrap_servers => "kafka:9092"
    topics => ["logs"]
    consumer_threads => 20
  }
}

filter {
  # Logs already JSON, just parse
  json {
    source => "message"
  }
  
  # Add correlation
  if [trace_id] {
    mutate {
      add_field => { "[@metadata][trace_id]" => "%{trace_id}" }
    }
  }
  
  # Normalize timestamp
  date {
    match => [ "timestamp", "ISO8601" ]
  }
}

output {
  elasticsearch {
    hosts => ["elasticsearch:9200"]
    index => "logs-%{+YYYY.MM.dd}"
    template_name => "logs"
    template => "/etc/logstash/templates/logs.json"
  }
}
```

#### âœ… Step 5: Elasticsearch Storage

**Elasticsearch Cluster:**

```
Cluster Configuration:
  - 6 Data Nodes (storage)
  - 3 Master Nodes (coordination)
  - 2 Coordinating Nodes (query routing)

Sharding:
  - Index per day: logs-2024-01-15
  - Shards per index: 5 (distributed across nodes)
  - Replicas: 1 (high availability)
```

**Index Template:**

```json
{
  "index_patterns": [
    "logs-*"
  ],
  "settings": {
    "number_of_shards": 5,
    "number_of_replicas": 1,
    "index.lifecycle.name": "logs-policy",
    "index.lifecycle.rollover_alias": "logs"
  },
  "mappings": {
    "properties": {
      "timestamp": {
        "type": "date"
      },
      "level": {
        "type": "keyword"
      },
      "service": {
        "type": "keyword"
      },
      "trace_id": {
        "type": "keyword"
      },
      "message": {
        "type": "text"
      },
      "error": {
        "type": "object"
      }
    }
  }
}
```

**Index Lifecycle Management (ILM):**

```json
{
  "policy": {
    "phases": {
      "hot": {
        "actions": {
          "rollover": {
            "max_size": "50GB",
            "max_age": "1d"
          }
        }
      },
      "warm": {
        "min_age": "7d",
        "actions": {
          "allocate": {
            "number_of_replicas": 0
          }
        }
      },
      "cold": {
        "min_age": "30d",
        "actions": {
          "allocate": {
            "number_of_replicas": 0
          }
        }
      },
      "delete": {
        "min_age": "90d"
      }
    }
  }
}
```

#### âœ… Step 6: Search and Correlation

**Trace Correlation:**

```
Search by trace_id:
  GET /logs-*/_search
  {
    "query": {
      "term": {
        "trace_id": "abc-123"
      }
    },
    "sort": [
      {"timestamp": "asc"}
    ]
  }

Result: All logs for request (across all services)
```

**Service Filtering:**

```
Search by service:
  GET /logs-*/_search
  {
    "query": {
      "bool": {
        "must": [
          {"term": {"service": "user-service"}},
          {"term": {"level": "ERROR"}}
        ]
      }
    }
  }
```

**Time Range Queries:**

```
Search by time range:
  GET /logs-*/_search
  {
    "query": {
      "range": {
        "timestamp": {
          "gte": "2024-01-15T00:00:00Z",
          "lte": "2024-01-15T23:59:59Z"
        }
      }
    }
  }
```

#### âœ… Step 7: Performance Optimization

**Bulk Indexing:**

```
Logstash Bulk Settings:
  - Bulk size: 1000 documents
  - Bulk interval: 5 seconds
  - Parallel workers: 4

Throughput:
  - 1,157 entries/second
  - Bulk: 1000 docs every 5s = 200 docs/second per bulk
  - 4 workers = 800 docs/second
  - Sufficient capacity
```

**Query Optimization:**

```
Index Patterns:
  - Use date-based indices (logs-2024-01-15)
  - Query only relevant indices (not all)
  - Faster queries (smaller indices)

Caching:
  - Elasticsearch query cache
  - Kibana dashboard caching
  - Frequently used queries cached
```

**Storage Optimization:**

```
Compression:
  - Elasticsearch compression (default)
  - Reduces storage by ~50%

ILM:
  - Hot: 7 days (fast storage)
  - Warm: 30 days (slower storage)
  - Cold: 90 days (archive storage)
  - Delete: >90 days
```

#### âœ… Complete Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚          Kubernetes Cluster (10,000 Pods)                â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ Pod 1        â”‚  â”‚ Pod 2        â”‚  â”‚ Pod N        â”‚  â”‚
â”‚  â”‚ - Service    â”‚  â”‚ - Service    â”‚  â”‚ - Service    â”‚  â”‚
â”‚  â”‚ - Filebeat   â”‚  â”‚ - Filebeat   â”‚  â”‚ - Filebeat   â”‚  â”‚
â”‚  â”‚   (sidecar)  â”‚  â”‚   (sidecar)  â”‚  â”‚   (sidecar)  â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚                  â”‚                  â”‚
          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚   Kafka Cluster                        â”‚
        â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
        â”‚   â”‚ Topic: logs                      â”‚ â”‚
        â”‚   â”‚ Partitions: 20                   â”‚ â”‚
        â”‚   â”‚ Retention: 7 days                â”‚ â”‚
        â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚   Logstash Cluster (3 instances)        â”‚
        â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
        â”‚   â”‚ - Kafka Input (20 consumers)     â”‚ â”‚
        â”‚   â”‚ - JSON Parsing                   â”‚ â”‚
        â”‚   â”‚ - Enrichment                     â”‚ â”‚
        â”‚   â”‚ - Elasticsearch Output           â”‚ â”‚
        â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚   Elasticsearch Cluster               â”‚
        â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
        â”‚   â”‚ - 6 Data Nodes                    â”‚ â”‚
        â”‚   â”‚ - 3 Master Nodes                  â”‚ â”‚
        â”‚   â”‚ - Daily Indices (logs-YYYY.MM.dd) â”‚ â”‚
        â”‚   â”‚ - ILM Policy (90-day retention)   â”‚ â”‚
        â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚   Kibana                               â”‚
        â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
        â”‚   â”‚ - Discover (log search)         â”‚ â”‚
        â”‚   â”‚ - Visualizations                 â”‚ â”‚
        â”‚   â”‚ - Dashboards                     â”‚ â”‚
        â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Log Flow:**

```
1. Service â†’ Log File: Writes JSON log
2. Filebeat â†’ Log File: Tails file
3. Filebeat â†’ Kafka: Publishes log to Kafka
4. Logstash â†’ Kafka: Consumes log
5. Logstash: Parses, enriches log
6. Logstash â†’ Elasticsearch: Indexes log
7. Elasticsearch: Stores in daily index
8. Kibana â†’ Elasticsearch: Queries logs
9. User â†’ Kibana: Views logs in dashboard
```

#### âš–ï¸ Trade-offs Summary

| Decision                   | What We Gain                | What We Sacrifice               |
|----------------------------|-----------------------------|---------------------------------|
| **Filebeat Sidecar**       | Decoupled, resilient        | Resource overhead (one per pod) |
| **Kafka Buffer**           | Durability, decoupling      | Additional infrastructure       |
| **Daily Indices**          | Easy retention, performance | More indices to manage          |
| **ILM Policy**             | Cost optimization           | Configuration complexity        |
| **Structured Logs (JSON)** | Easy parsing, querying      | Slightly larger log size        |

#### âœ… Final Summary

**ELK Stack Strategy:**

- **Collection:** Filebeat (sidecar, one per pod)
- **Buffer:** Kafka (20 partitions, 7-day retention)
- **Processing:** Logstash (3 instances, JSON parsing, enrichment)
- **Storage:** Elasticsearch (6 data nodes, daily indices, ILM)
- **Visualization:** Kibana (discover, visualizations, dashboards)
- **Retention:** 90 days (ILM policy)

**Performance:**

- **Collection:** 100M logs/day (handled by 10K Filebeat instances)
- **Processing:** 1,157 logs/second (handled by 3 Logstash instances)
- **Indexing:** <30 seconds (real-time, meets requirement)
- **Search:** <1 second (Elasticsearch full-text search)
- **Storage:** ~2 TB (90 days, compressed)

**Result:**

- âœ… Collects logs from 50 services (10K instances)
- âœ… Stores logs for 90 days (ILM policy)
- âœ… Fast search (full-text + structured queries)
- âœ… Handles 100M logs/day
- âœ… Real-time indexing (<30s)
- âœ… Trace correlation (trace_id search)
- âœ… Cost-optimized (open-source, ILM)

