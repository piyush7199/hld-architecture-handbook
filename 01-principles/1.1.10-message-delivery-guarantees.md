# 1.1.10 Message Delivery Guarantees: At-Most-Once, At-Least-Once, Exactly-Once

## Intuitive Explanation

Imagine you're sending a letter through the postal service:

1. **At-Most-Once Delivery:** The post office might lose your letter, but if it arrives, it arrives only once. You might
   not get confirmation it was delivered.
2. **At-Least-Once Delivery:** The post office guarantees your letter will arrive, but if there's any uncertainty (like
   a network glitch), they'll send it again. You might receive duplicates.
3. **Exactly-Once Delivery:** The post office guarantees your letter arrives exactly once‚Äîno loss, no duplicates. This
   is the hardest to achieve and requires coordination.

**Message Delivery Guarantees** in distributed messaging systems work the same way. They define what happens to messages
when systems fail, networks partition, or services restart.

---

## In-Depth Analysis

### Definition

**Message Delivery Guarantees** specify the behavior of a messaging system regarding message delivery in the presence of
failures:

1. **At-Most-Once:** Each message is delivered zero or one time (may be lost, never duplicated)
2. **At-Least-Once:** Each message is delivered one or more times (never lost, may be duplicated)
3. **Exactly-Once:** Each message is delivered exactly one time (never lost, never duplicated)

**Critical Trade-off:**

- **At-Most-Once:** Simple, fast, but may lose messages
- **At-Least-Once:** Reliable, but requires idempotency to handle duplicates
- **Exactly-Once:** Ideal, but complex and expensive

### Why Delivery Guarantees Matter

**Distributed System Failures:**

- **Network Failures:** Messages lost in transit
- **Service Crashes:** Messages lost before processing
- **Timeouts:** Uncertainty about delivery status
- **Retries:** Automatic retries cause duplicates

**Impact:**

- **Lost Messages:** Critical data never processed (orders, payments)
- **Duplicate Messages:** Double processing (duplicate charges, duplicate orders)
- **Incorrect State:** System state becomes inconsistent

---

## Key Concepts / Tradeoffs

### 1. At-Most-Once Delivery

**Definition:** Each message is delivered at most once. If delivery fails, the message is lost (not retried).

**How It Works:**

```
Producer ‚Üí Message Queue ‚Üí Consumer
         (if failure, message lost, no retry)
```

**Characteristics:**

- **No Retries:** Failed messages are discarded
- **Fast:** No retry overhead
- **Simple:** No duplicate handling needed
- **Data Loss Risk:** Messages can be lost

**Implementation:**

- **Fire-and-Forget:** Send message, don't wait for acknowledgment
- **No Persistence:** Messages not persisted (lost on crash)
- **No Retry Logic:** Failures result in message loss

**Use Cases:**

- **Non-Critical Data:** Metrics, logs, analytics
- **High-Volume, Low-Value:** When losing some messages is acceptable
- **Real-Time Feeds:** Live updates where missing one is okay

**Examples:**

- UDP-based messaging
- Fire-and-forget notifications
- Metrics collection (losing some metrics acceptable)

**Trade-offs:**

- ‚úÖ **Simple:** No retry or deduplication logic
- ‚úÖ **Fast:** No overhead from retries
- ‚ùå **Data Loss:** Messages can be lost
- ‚ùå **Unreliable:** Not suitable for critical operations

### 2. At-Least-Once Delivery

**Definition:** Each message is delivered one or more times. The system guarantees delivery but may deliver duplicates.

**How It Works:**

```
Producer ‚Üí Message Queue ‚Üí Consumer
         (if failure, retry until acknowledged)
         (consumer may receive same message multiple times)
```

**Characteristics:**

- **Retries:** Failed messages are retried until acknowledged
- **Persistence:** Messages persisted until acknowledged
- **Duplicates:** Consumer may receive same message multiple times
- **Reliable:** Messages never lost (if system is persistent)

**Implementation:**

- **Acknowledgment (ACK):** Consumer must acknowledge message receipt
- **Retry on Failure:** If no ACK received, message retried
- **Persistence:** Messages stored until ACK (survive crashes)
- **Idempotency Required:** Consumer must handle duplicates

**Flow:**

```
1. Producer sends message ‚Üí Queue stores message
2. Queue delivers to consumer
3. Consumer processes message
4. Consumer sends ACK ‚Üí Queue removes message
5. If ACK not received (timeout/crash):
   ‚Üí Queue retries message (duplicate delivery)
```

**Use Cases:**

- **Critical Operations:** Payments, orders, transactions
- **When Duplicates Acceptable:** With idempotency handling
- **Reliable Processing:** When losing messages is unacceptable

**Examples:**

- Kafka (at-least-once by default)
- RabbitMQ (with acknowledgments)
- Amazon SQS (standard queues)

**Trade-offs:**

- ‚úÖ **Reliable:** Messages never lost
- ‚úÖ **Simple:** Easier than exactly-once
- ‚ùå **Duplicates:** Must handle with idempotency
- ‚ùå **Retry Overhead:** May cause duplicate processing

### 3. Exactly-Once Delivery

**Definition:** Each message is delivered exactly once‚Äînever lost, never duplicated.

**How It Works:**

```
Producer ‚Üí Message Queue ‚Üí Consumer
         (idempotency + deduplication + transactions)
         (guarantees exactly one delivery)
```

**Characteristics:**

- **No Loss:** Messages never lost
- **No Duplicates:** Messages never delivered twice
- **Complex:** Requires coordination and state management
- **Expensive:** Higher latency and resource usage

**Implementation Strategies:**

**A. Idempotency Keys:**

- Producer includes unique idempotency key
- Queue deduplicates by key
- Consumer processes idempotently

**B. Distributed Transactions:**

- Two-Phase Commit (2PC)
- Atomic operations across producer, queue, consumer
- Expensive, high latency

**C. Transactional Outbox:**

- Write message to database transactionally
- Background job publishes to queue
- Ensures exactly-once publishing

**D. Idempotent Consumers:**

- Consumer tracks processed message IDs
- Skip if already processed
- Ensures exactly-once processing

**Use Cases:**

- **Financial Systems:** Payments, transactions (no duplicates allowed)
- **Critical State Changes:** When duplicates cause serious issues
- **When Cost Acceptable:** When complexity/performance cost is worth it

**Examples:**

- Kafka with idempotent producer + transactional consumer
- Google Pub/Sub (exactly-once delivery)
- Apache Pulsar (exactly-once semantics)

**Trade-offs:**

- ‚úÖ **Perfect:** No loss, no duplicates
- ‚úÖ **Correct:** Simplest for consumers (no duplicate handling)
- ‚ùå **Complex:** Requires coordination, state management
- ‚ùå **Expensive:** Higher latency, resource usage
- ‚ùå **Not Always Possible:** Some systems can't guarantee exactly-once

### 4. Delivery Guarantee Comparison

| Guarantee         | Message Loss | Duplicates | Complexity | Latency   | Use Case                         |
|-------------------|--------------|------------|------------|-----------|----------------------------------|
| **At-Most-Once**  | ‚úÖ Possible   | ‚ùå Never    | ‚úÖ Simple   | ‚úÖ Low     | Non-critical data                |
| **At-Least-Once** | ‚ùå Never      | ‚úÖ Possible | ‚ö†Ô∏è Medium  | ‚ö†Ô∏è Medium | Critical data (with idempotency) |
| **Exactly-Once**  | ‚ùå Never      | ‚ùå Never    | ‚ùå Complex  | ‚ùå High    | Financial, critical state        |

### 5. Achieving Exactly-Once Semantics

**Challenge:** Exactly-once is hard because:

- **Network Failures:** Can't distinguish between "message lost" and "slow delivery"
- **Service Crashes:** Can't know if message was processed before crash
- **Distributed State:** Coordinating across producer, queue, consumer is complex

**Practical Approach: At-Least-Once + Idempotency**

Most systems achieve "exactly-once semantics" by:

1. **At-Least-Once Delivery:** Guarantee message arrives
2. **Idempotent Processing:** Handle duplicates gracefully

**Result:** Effectively exactly-once (duplicates handled, no data loss)

**Example:**

```
Message Queue: At-least-once delivery
Consumer: Idempotent processing (check if already processed)
Result: Exactly-once semantics (duplicates handled)
```

---

## üí° Real-World Use Cases

### Payment Processing (Stripe)

**Guarantee:** At-Least-Once + Idempotency

**Why:**

- **Critical:** Can't lose payment requests
- **Idempotency:** Payment API uses idempotency keys
- **Result:** Effectively exactly-once (duplicates handled)

**Implementation:**

```
Payment Request ‚Üí Kafka (at-least-once)
                ‚Üí Payment Processor (idempotent with key)
                ‚Üí Result: Each payment processed exactly once
```

### Order Processing (E-commerce)

**Guarantee:** At-Least-Once + Idempotency

**Why:**

- **Critical:** Can't lose orders
- **Idempotency:** Order ID prevents duplicates
- **Result:** Each order created exactly once

**Implementation:**

```
Order Request ‚Üí RabbitMQ (at-least-once)
              ‚Üí Order Service (check if order_id exists)
              ‚Üí Result: Each order created exactly once
```

### Metrics Collection (Prometheus)

**Guarantee:** At-Most-Once

**Why:**

- **Non-Critical:** Losing some metrics is acceptable
- **High Volume:** Millions of metrics per second
- **Simple:** No retry overhead

**Implementation:**

```
Metrics ‚Üí UDP (fire-and-forget)
        ‚Üí Metrics Collector
        ‚Üí Result: Most metrics collected, some may be lost
```

### Event Sourcing (Banking)

**Guarantee:** Exactly-Once

**Why:**

- **Critical:** Financial transactions must be exact
- **State:** Event log must be perfect
- **Cost Acceptable:** Complexity worth it for correctness

**Implementation:**

```
Transaction Event ‚Üí Kafka (idempotent producer)
                  ‚Üí Event Store (transactional)
                  ‚Üí Result: Each event stored exactly once
```

---

## ‚úèÔ∏è Design Challenge

### Problem

You are designing a notification service that sends emails to users. The service receives notification requests from
multiple microservices over unreliable networks.

**Requirements:**

1. **Reliability:** Every notification must be sent (can't lose notifications)
2. **No Duplicates:** Users should not receive duplicate emails
3. **Scale:** Handle 100,000 notifications per second
4. **Latency:** Notifications sent within 5 seconds
5. **Failure Handling:** System must handle network failures, service crashes, email service outages

**Constraints:**

- Network is unreliable (frequent timeouts)
- Email service occasionally fails (requires retries)
- Services may crash and restart
- High volume (100k notifications/sec)

Design a message delivery system that:

- Guarantees every notification is sent
- Prevents duplicate emails
- Handles failures gracefully
- Meets latency requirements

### Solution

#### üß© Scenario

- **Service:** Email notification system
- **Scale:** 100,000 notifications/sec
- **Reliability:** Must send every notification (critical)
- **Duplicates:** Cannot send duplicate emails
- **Latency:** <5 seconds
- **Failures:** Network, service crashes, email service outages

**Requirements Analysis:**

- **Delivery Guarantee:** Exactly-Once (can't lose, can't duplicate)
- **Implementation:** At-Least-Once delivery + Idempotency

#### ‚úÖ Step 1: Choose Delivery Guarantee

**Choice: At-Least-Once Delivery + Idempotency**

**Why:**

- **Reliability:** At-least-once ensures no lost notifications
- **Idempotency:** Prevents duplicate emails
- **Practical:** Easier than true exactly-once, achieves same result
- **Performance:** Lower latency than distributed transactions

**Architecture:**

```
Microservices ‚Üí Kafka (at-least-once) ‚Üí Notification Workers (idempotent)
```

#### ‚úÖ Step 2: Message Queue Design

**Choice: Kafka with At-Least-Once Semantics**

**Configuration:**

- **Topic:** `notifications`
- **Partitions:** 100 (for parallelism)
- **Replication Factor:** 3 (durability)
- **Acks:** `all` (wait for all replicas)
- **Retries:** Infinite (until successful)

**Why Kafka:**

- **Durability:** Messages persisted to disk (survive crashes)
- **At-Least-Once:** Producer retries until acknowledged
- **Scalability:** 100 partitions = 100k messages/sec
- **Ordering:** Per-partition ordering (maintains order per user)

**Producer Configuration:**

```python
producer = KafkaProducer(
    acks='all',              # Wait for all replicas
    retries=float('inf'),    # Retry forever
    max_in_flight_requests=1,  # Ensure ordering
    idempotence=True         # Prevent duplicate sends
)
```

#### ‚úÖ Step 3: Idempotency Design

**Strategy: Idempotency Keys**

**Key Format:**

```
{service_name}:{notification_id}:{user_id}
Example: order_service:notif_abc123:user_456
```

**Why This Format:**

- **Service Name:** Scopes keys (different services can use same notification_id)
- **Notification ID:** Unique per notification (from source service)
- **User ID:** Ensures user-specific deduplication

**Idempotency Store: Redis**

**Data Structure:**

```
Key: idempotency:{service}:{notif_id}:{user_id}
Value: {
  "email_sent": true,
  "sent_at": 1699123456,
  "email_id": "email_xyz789"
}
TTL: 7 days (longer than retry window)
```

**Why Redis:**

- **Fast:** <1ms lookup (meets latency requirement)
- **TTL:** Automatic expiration
- **High Throughput:** 100k+ operations/sec

#### ‚úÖ Step 4: Notification Worker Design

**Consumer Group:**

- **Workers:** 100 workers (1 per partition)
- **Parallelism:** 100 partitions = 100k messages/sec capacity
- **Processing:** Each worker processes 1k messages/sec

**Idempotent Processing:**

```python
def process_notification(message):
    notification_id = message['notification_id']
    user_id = message['user_id']
    service = message['service']
    
    # Step 1: Check idempotency
    idempotency_key = f"{service}:{notification_id}:{user_id}"
    cached = redis.get(f"idempotency:{idempotency_key}")
    
    if cached:
        # Already processed, skip
        return cached['email_id']  # Return existing email ID
    
    # Step 2: Send email
    try:
        email_result = email_service.send(
            to=user_id,
            subject=message['subject'],
            body=message['body']
        )
        
        # Step 3: Store idempotency result
        redis.setex(
            f"idempotency:{idempotency_key}",
            604800,  # 7 days TTL
            json.dumps({
                "email_sent": True,
                "sent_at": time.now(),
                "email_id": email_result.id
            })
        )
        
        return email_result.id
        
    except EmailServiceError as e:
        # Email service failed, raise to trigger retry
        raise  # Kafka will retry message
```

#### ‚úÖ Step 5: Handling Email Service Failures

**Problem:** Email service fails ‚Üí notifications retried ‚Üí duplicate emails

**Solution: Idempotency Check Before Retry**

**Flow:**

```
1. Worker receives message
2. Check idempotency: Already sent? ‚Üí Skip
3. If not sent:
   a. Send email
   b. Store idempotency result
4. If email service fails:
   a. Raise exception (triggers Kafka retry)
   b. On retry: Check idempotency again
   c. If email was sent (race condition): Skip
   d. If not sent: Retry email send
```

**Race Condition Handling:**

```
Scenario: Two workers process same message simultaneously

Worker 1: Check idempotency ‚Üí Not found ‚Üí Send email ‚Üí Store result
Worker 2: Check idempotency ‚Üí Not found ‚Üí Send email ‚Üí Store result
Result: Duplicate email (both workers send)

Solution: Distributed Lock
```

**Distributed Lock:**

```python
def process_notification_with_lock(message):
    idempotency_key = f"{service}:{notification_id}:{user_id}"
    lock_key = f"lock:{idempotency_key}"
    
    # Acquire lock
    if not redis.setnx(lock_key, worker_id, ex=30):
        # Another worker is processing, wait and retry
        time.sleep(0.1)
        cached = redis.get(f"idempotency:{idempotency_key}")
        if cached:
            return cached['email_id']
    
    try:
        # Check idempotency (double-check after lock)
        cached = redis.get(f"idempotency:{idempotency_key}")
        if cached:
            return cached['email_id']
        
        # Send email
        email_result = email_service.send(...)
        
        # Store result
        redis.setex(f"idempotency:{idempotency_key}", 604800, ...)
        
        return email_result.id
        
    finally:
        # Release lock
        redis.delete(lock_key)
```

#### ‚úÖ Step 6: Handling Kafka Consumer Failures

**Problem:** Consumer crashes ‚Üí message not acknowledged ‚Üí Kafka retries ‚Üí duplicate

**Solution: Acknowledge After Processing**

**Kafka Consumer Configuration:**

```python
consumer = KafkaConsumer(
    'notifications',
    enable_auto_commit=False,  # Manual acknowledgment
    auto_offset_reset='earliest'
)

for message in consumer:
    try:
        # Process notification
        email_id = process_notification(message.value)
        
        # Acknowledge only after successful processing
        consumer.commit()
        
    except Exception as e:
        # Don't acknowledge, Kafka will retry
        log.error(f"Failed to process: {e}")
        # Message will be redelivered
```

**Failure Scenarios:**

**Scenario 1: Worker Crashes Before ACK**

```
Worker receives message ‚Üí Processes ‚Üí Crashes before ACK
‚Üí Kafka redelivers message ‚Üí Worker checks idempotency ‚Üí Already sent ‚Üí Skip
‚Üí Result: No duplicate email
```

**Scenario 2: Worker Crashes During Processing**

```
Worker receives message ‚Üí Starts processing ‚Üí Crashes
‚Üí Kafka redelivers message ‚Üí Worker retries ‚Üí Sends email
‚Üí Result: Email sent (no duplicate if idempotency works)
```

#### ‚úÖ Step 7: Performance Optimization

**Batching:**

- Batch idempotency checks (Redis MGET)
- Batch email sends (if email service supports)
- Reduces overhead

**Caching:**

- Cache email service responses
- Reduce email service load

**Monitoring:**

- Idempotency hit rate (should be low, ~1-2% for retries)
- Email send success rate
- Kafka consumer lag

#### ‚úÖ Complete Architecture

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ              Microservices (Producers)                   ‚îÇ
‚îÇ  Order Service, User Service, Payment Service            ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                       ‚îÇ
                       ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    Kafka Cluster                         ‚îÇ
‚îÇ  Topic: notifications (100 partitions, RF=3)           ‚îÇ
‚îÇ  Delivery: At-Least-Once                                ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                       ‚îÇ
        ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
        ‚îÇ              ‚îÇ              ‚îÇ
        ‚ñº              ‚ñº              ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Worker 1     ‚îÇ ‚îÇ Worker 2 ‚îÇ ‚îÇ ... Worker 100‚îÇ
‚îÇ (Partition 0)‚îÇ ‚îÇ (Part 1)  ‚îÇ ‚îÇ (Partition 99)‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
       ‚îÇ               ‚îÇ              ‚îÇ
       ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
               ‚îÇ              ‚îÇ
        ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
        ‚îÇ   Redis     ‚îÇ ‚îÇ   Email   ‚îÇ
        ‚îÇ (Idempotency‚îÇ ‚îÇ  Service  ‚îÇ
        ‚îÇ    Store)   ‚îÇ ‚îÇ           ‚îÇ
        ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

**Flow:**

```
1. Microservice ‚Üí Kafka: Send notification (at-least-once)
2. Kafka ‚Üí Worker: Deliver message
3. Worker ‚Üí Redis: Check idempotency
4. If not processed:
   a. Worker ‚Üí Email Service: Send email
   b. Worker ‚Üí Redis: Store idempotency result
   c. Worker ‚Üí Kafka: Acknowledge message
5. If already processed:
   a. Worker ‚Üí Skip (return cached email_id)
   b. Worker ‚Üí Kafka: Acknowledge message
```

#### ‚öñÔ∏è Trade-offs Summary

| Decision                        | What We Gain                  | What We Sacrifice                 |
|---------------------------------|-------------------------------|-----------------------------------|
| **At-Least-Once + Idempotency** | Reliability, no duplicates    | Complexity (idempotency logic)    |
| **Kafka**                       | Durability, scalability       | Requires idempotency handling     |
| **Redis Idempotency Store**     | Fast lookups (<1ms)           | Memory cost, eventual consistency |
| **Distributed Lock**            | Prevents race conditions      | Adds latency, complexity          |
| **Manual ACK**                  | Ensures processing before ACK | More complex than auto-commit     |

#### ‚úÖ Final Summary

**Delivery Guarantee:**

- **Message Queue:** At-Least-Once (Kafka with acks=all)
- **Processing:** Idempotent (Redis idempotency store)
- **Result:** Effectively Exactly-Once (duplicates handled, no loss)

**Performance:**

- **Throughput:** 100,000 notifications/sec (100 partitions √ó 1k/sec)
- **Latency:** <5 seconds (Kafka delivery + email send + idempotency check)
- **Idempotency Check:** <1ms (Redis lookup)

**Reliability:**

- **No Lost Messages:** At-least-once delivery + persistence
- **No Duplicates:** Idempotency keys prevent duplicate emails
- **Failure Handling:** Survives worker crashes, email service outages

**Result:**

- ‚úÖ Every notification sent (at-least-once)
- ‚úÖ No duplicate emails (idempotency)
- ‚úÖ Handles failures gracefully
- ‚úÖ Meets latency requirement (<5s)
- ‚úÖ Scales to 100k notifications/sec

